{"nick":"chridal","message":"What I am really happy about though is that yesterday I finished all the functionality of our websocket-server.","date":"2017-02-01T00:00:08.464Z","type":"message"}
{"nick":"publio","message":"hehe","date":"2017-02-01T00:00:18.956Z","type":"message"}
{"nick":"chridal","message":"Now I just have to move all the data which I'm storing in memory out into Redis :-P","date":"2017-02-01T00:00:20.507Z","type":"message"}
{"nick":"saigel__","reason":"Quit: Konversation terminated!","date":"2017-02-01T00:00:31.128Z","type":"quit"}
{"nick":"matthewbe","reason":"Ping timeout: 255 seconds","date":"2017-02-01T00:00:37.620Z","type":"quit"}
{"nick":"Emperor_Earth","reason":"Read error: Connection reset by peer","date":"2017-02-01T00:00:38.095Z","type":"quit"}
{"nick":"matthewbe","date":"2017-02-01T00:00:55.711Z","type":"join"}
{"nick":"publio","message":"chridal: Looks like you should have had an API for that, or at least a adapter","date":"2017-02-01T00:01:00.815Z","type":"message"}
{"nick":"GreenJello","message":"yeah, a lot of the example socket code stores everything in memory, it's pretty lame","date":"2017-02-01T00:01:01.460Z","type":"message"}
{"nick":"publio","message":"an*","date":"2017-02-01T00:01:03.252Z","type":"message"}
{"nick":"Masterphi","reason":"Quit: Bye","date":"2017-02-01T00:01:09.623Z","type":"quit"}
{"nick":"bbankes","reason":"Ping timeout: 256 seconds","date":"2017-02-01T00:01:29.813Z","type":"quit"}
{"nick":"chridal","message":"I put everything in memory because it was the easiest way to get everything up and running so the iOS developer could continue on his stuff","date":"2017-02-01T00:01:39.873Z","type":"message"}
{"nick":"chridal","message":"publio: What do you mean?","date":"2017-02-01T00:01:45.021Z","type":"message"}
{"nick":"GreenJello","message":"we have a chat app and we have to join users to rooms and they may be on different servers, so each socket connection is listening for a pubsub message on redis to join the user to the room","date":"2017-02-01T00:01:48.782Z","type":"message"}
{"nick":"GreenJello","message":"it's pretty terrible","date":"2017-02-01T00:02:03.932Z","type":"message"}
{"nick":"nomoney4u","message":"Is this correct thinking? https://gist.github.com/nomoney4me/ebe999a8284e06e6be513cd72c77acd8","date":"2017-02-01T00:02:07.449Z","type":"message"}
{"nick":"chridal","message":"GreenJello: Yepp, that's pretty close to what I was thinking about doing :-P","date":"2017-02-01T00:02:11.191Z","type":"message"}
{"nick":"chridal","message":"Do you have any other ideas?","date":"2017-02-01T00:02:15.073Z","type":"message"}
{"nick":"GreenJello","message":"chridal, that was the best I could come up with","date":"2017-02-01T00:02:24.517Z","type":"message"}
{"nick":"publio","message":"chridal: An API to access the storage object.. Or an adapter class, which can be changed on whim with another","date":"2017-02-01T00:02:26.984Z","type":"message"}
{"nick":"duderono_","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2017-02-01T00:02:38.574Z","type":"quit"}
{"nick":"GreenJello","message":"I really wonder how well we can scale with redis","date":"2017-02-01T00:02:52.059Z","type":"message"}
{"nick":"chridal","message":"publio: I'm not sure I fully understand. Do you mean like a module that I wrap around Redis?","date":"2017-02-01T00:02:52.311Z","type":"message"}
{"nick":"publio","message":"Honestly, I feel like there's an overlap between microservices and OOP..","date":"2017-02-01T00:02:52.732Z","type":"message"}
{"nick":"solenodic","date":"2017-02-01T00:03:00.670Z","type":"join"}
{"nick":"chridal","message":"Because the data we do persistence on I access via a Rails API that stores it in Postgres","date":"2017-02-01T00:03:19.157Z","type":"message"}
{"nick":"GreenJello","message":"seems like pubsub would have real limits, like number of connections and throughput","date":"2017-02-01T00:03:22.639Z","type":"message"}
{"nick":"matthewbe_","reason":"Ping timeout: 255 seconds","date":"2017-02-01T00:03:23.939Z","type":"quit"}
{"nick":"chridal","message":"the data in Redis will solely be a cache of users, the current rooms, and Pub/Sub for horizontally scaling","date":"2017-02-01T00:03:42.694Z","type":"message"}
{"nick":"GreenJello","message":"might have to make the chat a microservice so there are less servers connected to it","date":"2017-02-01T00:03:50.520Z","type":"message"}
{"nick":"publio","message":"chridal: No. A class which has functions independent of the underlying storage used. (Or an API declaring the functions)","date":"2017-02-01T00:03:59.788Z","type":"message"}
{"nick":"chridal","message":"GreenJello: I've been thinking about using a message queue instead","date":"2017-02-01T00:04:05.479Z","type":"message"}
{"nick":"matthewbe__","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:04:09.675Z","type":"quit"}
{"nick":"smccarthy","reason":"Remote host closed the connection","date":"2017-02-01T00:04:11.084Z","type":"quit"}
{"nick":"chridal","message":"publio: I just don't see why I'd need that, or I'm not sure if we understand one another.","date":"2017-02-01T00:04:28.407Z","type":"message"}
{"nick":"publio","message":"SocketStorage:read(),write()..","date":"2017-02-01T00:04:29.118Z","type":"message"}
{"nick":"GreenJello","message":"chridal, message queues are for when you need more reliability, but they're much less performant","date":"2017-02-01T00:04:35.952Z","type":"message"}
{"nick":"FruitieX","date":"2017-02-01T00:04:38.424Z","type":"join"}
{"nick":"chridal","message":"I won't be swapping Redis for something else.","date":"2017-02-01T00:04:42.973Z","type":"message"}
{"nick":"smccarthy","date":"2017-02-01T00:04:43.265Z","type":"join"}
{"nick":"modernpacifist","message":"You could just follow the RethinkDB method of scaling out realtime change feeds - proxies","date":"2017-02-01T00:04:53.803Z","type":"message"}
{"nick":"publio","message":"chridal: The idea is so that you can change between memory and redis w/o having to go through the app code. You just change the API endpoint","date":"2017-02-01T00:05:07.898Z","type":"message"}
{"nick":"chridal","message":"but now I'd have to change the app code to use the API though?","date":"2017-02-01T00:05:29.353Z","type":"message"}
{"nick":"chridal","message":"modernpacifist: Please elaborate","date":"2017-02-01T00:05:52.743Z","type":"message"}
{"nick":"EyePulp","date":"2017-02-01T00:05:59.611Z","type":"join"}
{"nick":"publio","message":"The API endpoint changes, but the functions stay the same, regardless of the storage engine. What you'd do is change the link in your conf or wherever","date":"2017-02-01T00:06:14.890Z","type":"message"}
{"nick":"chridal","message":"GreenJello: Also, how would number of connections be an issue with Pub/Sub? You only have one subscriber for each server, or?","date":"2017-02-01T00:06:20.961Z","type":"message"}
{"nick":"GreenJello","message":"chridal, well you have one subscriber per server instance, not per vps","date":"2017-02-01T00:06:39.197Z","type":"message"}
{"nick":"GreenJello","message":"and they'd all be receiving all of the messages","date":"2017-02-01T00:06:49.185Z","type":"message"}
{"nick":"chridal","message":"That's what I meant","date":"2017-02-01T00:06:53.053Z","type":"message"}
{"nick":"chridal","message":"But why are they receiving all of the messages?","date":"2017-02-01T00:06:58.921Z","type":"message"}
{"nick":"chridal","message":"Only subscribe to the \"queue\" for each server","date":"2017-02-01T00:07:06.397Z","type":"message"}
{"nick":"GreenJello","message":"hmm... that's a good idea","date":"2017-02-01T00:07:30.411Z","type":"message"}
{"nick":"chridal","message":"have a map of to which server each client is connected, and push it onto the \"queue\" for that server","date":"2017-02-01T00:07:30.719Z","type":"message"}
{"nick":"chridal","message":"That's the architecture we're doing","date":"2017-02-01T00:07:36.910Z","type":"message"}
{"nick":"modernpacifist","message":"chridal: Well RethinkDB supports arbitrary query based change feeds that endpoints can subscribe to. As data that matches the query changes it gets sent to any listening/interested clients. To handle the case of potentially lots of clients all listening for the same changes, they wrote a proxy that the clients connect to instead which in turn only counts as one connection back to the database clust","date":"2017-02-01T00:07:47.803Z","type":"message"}
{"nick":"publio","message":"GreenJello: I think there's ambiguity reg the queue. Sometimes your sub to all messages, other times they're only sent to 1 subscriber","date":"2017-02-01T00:07:48.484Z","type":"message"}
{"nick":"modernpacifist","message":"er. It then gets the change feed and sends copies to all the subscribe clients, lessening the load on the cluster","date":"2017-02-01T00:07:53.902Z","type":"message"}
{"nick":"publio","message":"you*","date":"2017-02-01T00:08:03.817Z","type":"message"}
{"nick":"smccarthy","reason":"Read error: Connection reset by peer","date":"2017-02-01T00:08:08.948Z","type":"quit"}
{"nick":"GreenJello","message":"yeah, we could have a pubsub channel for each socket room or user id","date":"2017-02-01T00:08:24.524Z","type":"message"}
{"nick":"GreenJello","message":"not sure if there are tradeoffs there","date":"2017-02-01T00:08:32.046Z","type":"message"}
{"nick":"fattuna","reason":"Remote host closed the connection","date":"2017-02-01T00:08:38.482Z","type":"quit"}
{"nick":"chridal","message":"modernpacifist: Cool!","date":"2017-02-01T00:08:43.903Z","type":"message"}
{"nick":"publio","message":"You'd need both for IRC","date":"2017-02-01T00:08:54.567Z","type":"message"}
{"nick":"GreenJello","message":"it'd certainly reduce traffic","date":"2017-02-01T00:08:55.417Z","type":"message"}
{"nick":"plutoniix","date":"2017-02-01T00:09:00.631Z","type":"join"}
{"nick":"publio","message":"Channel/PM","date":"2017-02-01T00:09:10.505Z","type":"message"}
{"nick":"chridal","message":"GreenJello: Why is that needed though? if there's one channel for every instance, that'll be just fine","date":"2017-02-01T00:09:16.957Z","type":"message"}
{"nick":"chridal","message":"no redundant data","date":"2017-02-01T00:09:19.726Z","type":"message"}
{"nick":"GreenJello","message":"the use case is chat rooms + notifications","date":"2017-02-01T00:09:22.232Z","type":"message"}
{"nick":"fattuna","date":"2017-02-01T00:09:30.524Z","type":"join"}
{"nick":"GreenJello","message":"chridal, because how do we know which instances we're sending messages to?","date":"2017-02-01T00:09:40.148Z","type":"message"}
{"nick":"GreenJello","message":"there could be 3 users connected to 3 different socket servers, and a message needs to go to the other two users","date":"2017-02-01T00:10:06.716Z","type":"message"}
{"nick":"modernpacifist","message":"chridal: Following your use case, the fundamental goal would be to generate as little traffic as possible until you absolutely have to. That would mean something like those proxies actually subscribing to your pub/sub (fewer direct pub/sub connections) and the proxy duplicates messages off to the connected clients as needed. This is similar to the problem that multicast tries to solve in networking","date":"2017-02-01T00:10:13.976Z","type":"message"}
{"nick":"EyePulp","reason":"Ping timeout: 252 seconds","date":"2017-02-01T00:10:15.685Z","type":"quit"}
{"nick":"chridal","message":"GreenJello: You store where the users are connected to.","date":"2017-02-01T00:10:27.876Z","type":"message"}
{"nick":"chridal","message":"And then you push it onto the queue for that instance","date":"2017-02-01T00:10:37.259Z","type":"message"}
{"nick":"nomoney4u","message":"zsoc: so this whole project is pretty much done.  Thank you! :)  question: If I wanted to now add in functions, such as reporting and such - am I still modifying this primary index.js or would there be other methods to \"add-on\" stuffs after your project is done?","date":"2017-02-01T00:11:00.422Z","type":"message"}
{"nick":"GreenJello","message":"that'd require a read from redis for each user in the channel on every message","date":"2017-02-01T00:11:00.596Z","type":"message"}
{"nick":"chridal","message":"When you have a message adressed to a user on another server you fetch the server he's on from REdis, and put it on that channel for that specific server","date":"2017-02-01T00:11:06.918Z","type":"message"}
{"nick":"chridal","message":"GreenJello: No, you can cache it in memory on the server itself.","date":"2017-02-01T00:11:24.544Z","type":"message"}
{"nick":"chridal","message":"Just cache it for the ones you're in room with.","date":"2017-02-01T00:11:39.685Z","type":"message"}
{"nick":"zsoc","message":"nomoney4u: i'm flabberghasted this is all in 1 app.js :p","date":"2017-02-01T00:11:44.385Z","type":"message"}
{"nick":"p4trix","reason":"Ping timeout: 252 seconds","date":"2017-02-01T00:11:54.665Z","type":"quit"}
{"nick":"nomoney4u","message":"zsoc, it shouldn't be? :'(","date":"2017-02-01T00:11:59.922Z","type":"message"}
{"nick":"nostrora","date":"2017-02-01T00:12:31.809Z","type":"join"}
{"nick":"zsoc","message":"nomoney4u: although that's probably my personal thing... i usually mount routes as 'sub apps' to keep files smallish~ and break up models/services from routes etc etc but there's more than 1 way to skin a cat","date":"2017-02-01T00:12:32.326Z","type":"message"}
{"nick":"eldritchideen","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T00:12:39.642Z","type":"quit"}
{"nick":"Masterphi","date":"2017-02-01T00:13:17.683Z","type":"join"}
{"nick":"trcm","reason":"Ping timeout: 260 seconds","date":"2017-02-01T00:13:24.354Z","type":"quit"}
{"nick":"chridal","message":"modernpacifist: I don't know if that would be needed here though. As the subscribers will be extremely few.","date":"2017-02-01T00:13:45.336Z","type":"message"}
{"nick":"chridal","message":"Each Pub/Sub channel will only have one subscriber","date":"2017-02-01T00:13:57.499Z","type":"message"}
{"nick":"NomadJim","message":"Anyone know the proper way to import a package like botkit into an ionic 2 app? my bot.ts file looks like - https://dpaste.de/FBTk - I got lodash and slack modules working, but botkit comes up with \"Runtime Error","date":"2017-02-01T00:14:14.703Z","type":"message"}
{"nick":"NomadJim","message":"Cannot read property 'prototype' of undefined\" when I try a simple console.log(Botkit);","date":"2017-02-01T00:14:14.876Z","type":"message"}
{"nick":"nomoney4u","message":"zsoc, so since it's a single-page app, no routes are needed. however, I guess now I am introducing routes since the ui for reporting will go to another html page.","date":"2017-02-01T00:14:21.436Z","type":"message"}
{"nick":"siba","date":"2017-02-01T00:14:32.011Z","type":"join"}
{"nick":"noraatepernos","date":"2017-02-01T00:14:43.683Z","type":"join"}
{"nick":"chridal","message":"GreenJello: Let me know if you see any obvious short-comings with that strategy, because I'm going to start implementing it tomorrow :-P","date":"2017-02-01T00:15:21.010Z","type":"message"}
{"nick":"chridal","message":"(and any one else for that matter)","date":"2017-02-01T00:15:27.423Z","type":"message"}
{"nick":"NomadJim","message":"actually I didn't try the \"declare\" workaround yet gonna do that now","date":"2017-02-01T00:15:34.209Z","type":"message"}
{"nick":"chridal","message":"any input at all as to why this sucks would be greatly appreciated.","date":"2017-02-01T00:15:37.472Z","type":"message"}
{"nick":"macabre","reason":"Remote host closed the connection","date":"2017-02-01T00:15:42.606Z","type":"quit"}
{"nick":"wtr","date":"2017-02-01T00:16:35.527Z","type":"join"}
{"nick":"saslam","date":"2017-02-01T00:16:51.256Z","type":"join"}
{"nick":"trcm","date":"2017-02-01T00:18:18.522Z","type":"join"}
{"nick":"eldritchideen","date":"2017-02-01T00:18:28.728Z","type":"join"}
{"nick":"wtrocki","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:18:47.453Z","type":"quit"}
{"nick":"ozette","reason":"\"WeeChat 1.0.1\"","date":"2017-02-01T00:18:59.427Z","type":"part"}
{"nick":"rho","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:19:06.472Z","type":"quit"}
{"nick":"fattuna","reason":"Ping timeout: 276 seconds","date":"2017-02-01T00:19:15.523Z","type":"quit"}
{"nick":"ThePendulum","reason":"Quit: leaving","date":"2017-02-01T00:19:55.852Z","type":"quit"}
{"nick":"zsoc","message":"nomoney4u: this is a relatively common pattern in express for detached routers/subapps: https://gist.github.com/jkantr/2cb7a145332c67f981a2bb6a2337e45a","date":"2017-02-01T00:20:38.211Z","type":"message"}
{"nick":"GreenJello","message":"chridal, thanks for the advice, I'm passing this info on to my coworker who is writing the chat code","date":"2017-02-01T00:21:11.045Z","type":"message"}
{"nick":"zhodge_","reason":"Ping timeout: 256 seconds","date":"2017-02-01T00:21:19.788Z","type":"quit"}
{"nick":"chridal","message":"GreenJello: Glad to be of help. Let me know if you have any success/errors in implementing it","date":"2017-02-01T00:22:32.571Z","type":"message"}
{"nick":"noethics","date":"2017-02-01T00:22:48.016Z","type":"join"}
{"nick":"zxc","date":"2017-02-01T00:23:11.693Z","type":"join"}
{"nick":"eldritchideen","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2017-02-01T00:24:48.856Z","type":"quit"}
{"nick":"zhodge","date":"2017-02-01T00:24:55.586Z","type":"join"}
{"nick":"JohnBeales","date":"2017-02-01T00:27:47.279Z","type":"join"}
{"nick":"joyee","reason":"Read error: Connection reset by peer","date":"2017-02-01T00:30:18.809Z","type":"quit"}
{"nick":"joyee","date":"2017-02-01T00:31:01.432Z","type":"join"}
{"nick":"FIFOd","date":"2017-02-01T00:34:38.090Z","type":"join"}
{"nick":"PuterDude","date":"2017-02-01T00:34:44.515Z","type":"join"}
{"nick":"scippio","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:36:27.456Z","type":"quit"}
{"nick":"Ergo","reason":"Quit: WeeChat 1.4","date":"2017-02-01T00:38:35.897Z","type":"quit"}
{"nick":"Hrtlnd","date":"2017-02-01T00:38:56.501Z","type":"join"}
{"nick":"kaicataldo","date":"2017-02-01T00:39:23.529Z","type":"join"}
{"nick":"Hrtln","reason":"Ping timeout: 252 seconds","date":"2017-02-01T00:41:03.677Z","type":"quit"}
{"nick":"xaturn","date":"2017-02-01T00:41:13.087Z","type":"join"}
{"nick":"joyee","reason":"Read error: Connection reset by peer","date":"2017-02-01T00:41:13.328Z","type":"quit"}
{"nick":"nomoney4u","message":"zsoc, and where do people usually put their report.html file? in the public folder?","date":"2017-02-01T00:41:57.910Z","type":"message"}
{"nick":"joyee","date":"2017-02-01T00:42:07.429Z","type":"join"}
{"nick":"noffle","date":"2017-02-01T00:42:07.892Z","type":"join"}
{"nick":"nomoney4u","message":"reason I ask is because it seems __dirname would be in the /routes if run in routes.js (which makes sense).  I would then res.sendFile(__dirname+'/../public/reports.html') ?","date":"2017-02-01T00:43:21.486Z","type":"message"}
{"nick":"matthewbe","reason":"Quit: Leaving","date":"2017-02-01T00:43:28.260Z","type":"quit"}
{"nick":"GreenJello","message":"nomoney4u, that looks right","date":"2017-02-01T00:43:59.281Z","type":"message"}
{"nick":"nomoney4u","message":"GreenJello, further reasoning why I brought that up was because I got an error: ForbiddenError: Forbidden","date":"2017-02-01T00:44:46.767Z","type":"message"}
{"nick":"GreenJello","message":"maybe it doesn't like the ..","date":"2017-02-01T00:45:01.455Z","type":"message"}
{"nick":"GreenJello","message":"try path.join(__dirname, '..', 'public/reports.html')","date":"2017-02-01T00:45:15.120Z","type":"message"}
{"nick":"zsoc","message":"usually it goes in their views and they use a view engine and just res.render('reports', {}) :p","date":"2017-02-01T00:47:50.265Z","type":"message"}
{"nick":"modlin","reason":"Quit: modlin","date":"2017-02-01T00:48:19.882Z","type":"quit"}
{"nick":"zsoc","message":"generally there's some middleware for static serving like app.use(express.static(path.join(__dirname, 'public')))","date":"2017-02-01T00:48:36.310Z","type":"message"}
{"nick":"solenodic","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:48:49.672Z","type":"quit"}
{"nick":"nomoney4u","message":"Well, this is what I have in my app.js: app.use(express.static(__dirname+'/public'));","date":"2017-02-01T00:49:49.285Z","type":"message"}
{"nick":"nomoney4u","message":"Would that line replaces what GreenJello suggests?","date":"2017-02-01T00:50:51.194Z","type":"message"}
{"nick":"GreenJello","message":"nomoney4u, that'd also work","date":"2017-02-01T00:51:34.202Z","type":"message"}
{"nick":"noodman","date":"2017-02-01T00:51:39.809Z","type":"join"}
{"nick":"GreenJello","message":" if you open /report.html in the browser","date":"2017-02-01T00:51:42.741Z","type":"message"}
{"nick":"a_thakur","date":"2017-02-01T00:51:44.485Z","type":"join"}
{"nick":"GreenJello","message":"reports*","date":"2017-02-01T00:51:51.146Z","type":"message"}
{"nick":"zhodge","reason":"Ping timeout: 255 seconds","date":"2017-02-01T00:51:55.581Z","type":"quit"}
{"nick":"captbiz","date":"2017-02-01T00:52:43.923Z","type":"join"}
{"nick":"nomoney4u","message":"ah I see :)","date":"2017-02-01T00:53:00.723Z","type":"message"}
{"nick":"nomoney4u","message":"idk why I thought /reports by itself would work...","date":"2017-02-01T00:53:13.620Z","type":"message"}
{"nick":"GreenJello","message":"nomoney4u, if you want that, make public/reports/index.html","date":"2017-02-01T00:53:29.981Z","type":"message"}
{"nick":"GreenJello","message":"or do the sendFile","date":"2017-02-01T00:53:40.526Z","type":"message"}
{"nick":"saigel","date":"2017-02-01T00:54:58.227Z","type":"join"}
{"nick":"nomoney4u","message":"GreenJello, thank you","date":"2017-02-01T00:55:13.841Z","type":"message"}
{"nick":"oaao","reason":"Quit: Leaving","date":"2017-02-01T00:55:38.230Z","type":"quit"}
{"nick":"Hrtlnd","reason":"Ping timeout: 240 seconds","date":"2017-02-01T00:58:27.478Z","type":"quit"}
{"nick":"diazepan","date":"2017-02-01T00:58:34.017Z","type":"join"}
{"nick":"gothicsouth","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2017-02-01T00:58:45.300Z","type":"quit"}
{"nick":"lithie","date":"2017-02-01T00:59:05.456Z","type":"join"}
{"nick":"saigel","reason":"Ping timeout: 245 seconds","date":"2017-02-01T00:59:28.248Z","type":"quit"}
{"nick":"kus_","date":"2017-02-01T01:00:36.842Z","type":"join"}
{"nick":"Dovener","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:00:57.915Z","type":"quit"}
{"nick":"zumba_addict","date":"2017-02-01T01:01:07.823Z","type":"join"}
{"nick":"ReimuHakurei","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:01:08.677Z","type":"quit"}
{"nick":"zxc","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:01:09.841Z","type":"quit"}
{"nick":"zumba_addict","message":"I was searching a topic about rest and this was one of the results. What are your thoughts about this? http://koajs.com/","date":"2017-02-01T01:01:36.032Z","type":"message"}
{"nick":"solenodic","date":"2017-02-01T01:01:49.143Z","type":"join"}
{"nick":"joepie91","message":"ow: https://twitter.com/gitlabstatus/status/826591961444384768","date":"2017-02-01T01:01:50.383Z","type":"message"}
{"nick":"joepie91","message":"live-updated trainwreck","date":"2017-02-01T01:01:54.679Z","type":"message"}
{"nick":"Hrtln","date":"2017-02-01T01:02:03.484Z","type":"join"}
{"nick":"gwozt","reason":"Quit: This computer has gone to sleep","date":"2017-02-01T01:02:16.023Z","type":"quit"}
{"nick":"joyee","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:02:30.475Z","type":"quit"}
{"nick":"modernpacifist","message":"docker rm (docker ps -a -q) <enter> ...... wait, was that to prod?","date":"2017-02-01T01:02:37.096Z","type":"message"}
{"nick":"ljharb","message":"lol","date":"2017-02-01T01:02:44.176Z","type":"message"}
{"nick":"joepie91","message":"lol","date":"2017-02-01T01:02:46.089Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: that seems to be roughly what happened, yes","date":"2017-02-01T01:02:54.117Z","type":"message"}
{"nick":"ljharb","message":"willy_wonka.gif \"tell me again about not using github\"","date":"2017-02-01T01:02:54.794Z","type":"message"}
{"nick":"joyee","date":"2017-02-01T01:03:02.655Z","type":"join"}
{"nick":"joepie91","message":"ljharb: iirc github has had a prod data loss issue in the past as well :P","date":"2017-02-01T01:03:13.725Z","type":"message"}
{"nick":"ReimuHakurei","date":"2017-02-01T01:03:15.503Z","type":"join"}
{"nick":"Moonlight-Angel","reason":"Ping timeout: 256 seconds","date":"2017-02-01T01:03:15.904Z","type":"quit"}
{"nick":"joepie91","message":"been a good while though","date":"2017-02-01T01:03:27.098Z","type":"message"}
{"nick":"nya_","reason":"Remote host closed the connection","date":"2017-02-01T01:04:10.500Z","type":"quit"}
{"nick":"nya_","date":"2017-02-01T01:04:29.519Z","type":"join"}
{"nick":"nya_","reason":"Remote host closed the connection","date":"2017-02-01T01:04:31.825Z","type":"quit"}
{"nick":"nya_","date":"2017-02-01T01:04:58.500Z","type":"join"}
{"nick":"schm0","date":"2017-02-01T01:05:41.068Z","type":"join"}
{"nick":"modernpacifist","message":"Oh the problems encountered section just reads like a horror novel","date":"2017-02-01T01:06:11.722Z","type":"message"}
{"nick":"modernpacifist","message":"Imagine being the people that one-by-one discovered those points","date":"2017-02-01T01:06:22.289Z","type":"message"}
{"nick":"earendel","date":"2017-02-01T01:06:33.844Z","type":"join"}
{"nick":"joepie91","message":"yeah :/","date":"2017-02-01T01:06:45.394Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: I'm imagining that the \"who buys the next round\" list is going to be filled for a while","date":"2017-02-01T01:07:03.615Z","type":"message"}
{"nick":"joepie91","message":"to put it mildly","date":"2017-02-01T01:07:12.702Z","type":"message"}
{"nick":"tocka","date":"2017-02-01T01:07:14.351Z","type":"quit"}
{"nick":"miklb","date":"2017-02-01T01:07:22.172Z","type":"join"}
{"nick":"nya_","reason":"Ping timeout: 240 seconds","date":"2017-02-01T01:09:06.486Z","type":"quit"}
{"nick":"Havvy","message":"\"So in other words, out of 5 backup/replication techniques deployed none are working reliably or set up in the first place.\" -- GitLab","date":"2017-02-01T01:10:16.190Z","type":"message"}
{"nick":"joepie91","message":"good ol' \"until you've verified that you can restore them, you don't have backups\"","date":"2017-02-01T01:10:41.687Z","type":"message"}
{"nick":"noraatepernos","reason":"Quit: noraatepernos","date":"2017-02-01T01:11:50.372Z","type":"quit"}
{"nick":"chridal","message":"joepie91: What do you think about doing horizontal scaling via one Pub/Sub channel for each server instance, and then keeping track of which server users are connected to in Redis, and then publish messages on the respective channels?","date":"2017-02-01T01:12:30.388Z","type":"message"}
{"nick":"chridal","message":"For horizontally scaling a websocket server","date":"2017-02-01T01:12:35.387Z","type":"message"}
{"nick":"nomoney4u","message":"#3 on that problems encountered list seems questionable...why not on the DB?","date":"2017-02-01T01:12:48.641Z","type":"message"}
{"nick":"modernpacifist","message":"nomoney4u: Forgot to tick the box?","date":"2017-02-01T01:13:00.840Z","type":"message"}
{"nick":"nomoney4u","message":"#6 as well....","date":"2017-02-01T01:13:11.199Z","type":"message"}
{"nick":"joepie91","message":"chridal: my #1 advice for horizontal scaling is \"don't, distributed systems are really hard to get right\"","date":"2017-02-01T01:13:18.653Z","type":"message"}
{"nick":"joepie91","message":"chridal: but if you must, then it depends on the exact usecase","date":"2017-02-01T01:13:24.314Z","type":"message"}
{"nick":"joepie91","message":"and what guarantees are needed","date":"2017-02-01T01:13:28.212Z","type":"message"}
{"nick":"chridal","message":"joepie91: Well, I sort of have to do it any way for redundancy","date":"2017-02-01T01:13:35.143Z","type":"message"}
{"nick":"chridal","message":"even if it wasn't for scale","date":"2017-02-01T01:13:41.539Z","type":"message"}
{"nick":"joepie91","message":"in what sense? availability?","date":"2017-02-01T01:13:48.067Z","type":"message"}
{"nick":"chridal","message":"I still need to be able to drain connections and then update etc.","date":"2017-02-01T01:13:49.631Z","type":"message"}
{"nick":"nomoney4u","message":"modernpacifist, oh man if that was the reason...","date":"2017-02-01T01:13:50.130Z","type":"message"}
{"nick":"chridal","message":"joepie91: Yes, availability while deploying updates for instance","date":"2017-02-01T01:13:59.202Z","type":"message"}
{"nick":"chridal","message":"and also general availability","date":"2017-02-01T01:14:06.704Z","type":"message"}
{"nick":"kaicataldo","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T01:14:13.490Z","type":"quit"}
{"nick":"joepie91","message":"chridal: update migration is actually a really difficult problem","date":"2017-02-01T01:14:19.857Z","type":"message"}
{"nick":"chridal","message":"Yea, the draining is going to be really painful","date":"2017-02-01T01:14:32.624Z","type":"message"}
{"nick":"joepie91","message":"chridal: if you don't want service interruption, you need to design your updates such that they are always backwards-compatible towards the oldest version running in your cluster","date":"2017-02-01T01:14:39.212Z","type":"message"}
{"nick":"chridal","message":"but I thought about telling the clients that they need to connect to another server as well, and then terminate the first one once they connect to the other one","date":"2017-02-01T01:14:51.157Z","type":"message"}
{"nick":"chridal","message":"sort of migrating the connection","date":"2017-02-01T01:14:55.392Z","type":"message"}
{"nick":"joepie91","message":"sure, but that's the easy part","date":"2017-02-01T01:14:59.417Z","type":"message"}
{"nick":"joepie91","message":"the hard part is making old and new servers talk","date":"2017-02-01T01:15:04.745Z","type":"message"}
{"nick":"joepie91","message":":p","date":"2017-02-01T01:15:06.211Z","type":"message"}
{"nick":"chridal","message":"Oh, darn. Yes.","date":"2017-02-01T01:15:07.452Z","type":"message"}
{"nick":"joepie91","message":"without breaking shit in the process","date":"2017-02-01T01:15:10.302Z","type":"message"}
{"nick":"chridal","message":"Haven't thought about that","date":"2017-02-01T01:15:11.522Z","type":"message"}
{"nick":"SwiftMatt","date":"2017-02-01T01:15:15.915Z","type":"join"}
{"nick":"joepie91","message":"because if you have protocol v1 and v2, and v2 is not compatible with v1... you effectively have a netsplit at best","date":"2017-02-01T01:15:21.585Z","type":"message"}
{"nick":"joepie91","message":"or silent data corruption at worst","date":"2017-02-01T01:15:25.439Z","type":"message"}
{"nick":"joepie91","message":"this is why the easy solution is \"just restart the entire cluster at once, and deal with the few seconds of downtime\"","date":"2017-02-01T01:15:46.260Z","type":"message"}
{"nick":"joepie91","message":"this is honestly probably what most messaging systems do","date":"2017-02-01T01:15:56.793Z","type":"message"}
{"nick":"joepie91","message":"and they just mask it on the client side","date":"2017-02-01T01:16:01.114Z","type":"message"}
{"nick":"modernpacifist","message":"Most users are willing to accept a 5 minute downtime once every few months (assuming your not making API breaking changes every other day)","date":"2017-02-01T01:16:17.406Z","type":"message"}
{"nick":"joepie91","message":"for example, by sending an \"expected downtime for up to 1 minute\" message ahead of time, and then restarting the cluster, and the clients will pretend to be online for up to one minute","date":"2017-02-01T01:16:36.310Z","type":"message"}
{"nick":"joepie91","message":"and queue up messages locally and such","date":"2017-02-01T01:16:42.156Z","type":"message"}
{"nick":"joepie91","message":"then to the user it looks like \"oh, a few messages were delayed by a minute\"","date":"2017-02-01T01:16:50.370Z","type":"message"}
{"nick":"chridal","message":"But it's not chat. It's VoIP","date":"2017-02-01T01:17:02.641Z","type":"message"}
{"nick":"joepie91","message":"that's harder :)","date":"2017-02-01T01:17:09.199Z","type":"message"}
{"nick":"modernpacifist","message":"Oh god","date":"2017-02-01T01:17:14.637Z","type":"message"}
{"nick":"joepie91","message":"chridal: p2p voip or server-based?","date":"2017-02-01T01:17:19.893Z","type":"message"}
{"nick":"chridal","message":"It's P2P, so that part is fine. It's just that people clicking join will expect to be able to connect etc.","date":"2017-02-01T01:17:35.630Z","type":"message"}
{"nick":"joepie91","message":"chridal: right, then you can probably just restart the 'matchmaking' cluster all at once and mask it with some clever UX","date":"2017-02-01T01:18:04.374Z","type":"message"}
{"nick":"joepie91","message":"a spinner or something","date":"2017-02-01T01:18:10.244Z","type":"message"}
{"nick":"chridal","message":"The issue is that they are also able to send each other images/videos, or rather the links to images/photos, as well.","date":"2017-02-01T01:18:10.899Z","type":"message"}
{"nick":"joepie91","message":"that then occasionally takes 5 seconds instead of 1","date":"2017-02-01T01:18:16.723Z","type":"message"}
{"nick":"joepie91","message":"yeah, but those can be fairly easily delaye","date":"2017-02-01T01:18:28.170Z","type":"message"}
{"nick":"joepie91","message":"delayed*","date":"2017-02-01T01:18:30.725Z","type":"message"}
{"nick":"chridal","message":"But redeploying the cluster won't take 5 sec","date":"2017-02-01T01:18:35.122Z","type":"message"}
{"nick":"joepie91","message":"like, the trick here is to turn \"unavailable\" into \"delayed\" from the user's perception","date":"2017-02-01T01:18:39.763Z","type":"message"}
{"nick":"joepie91","message":"chridal: redeploying might not","date":"2017-02-01T01:18:46.360Z","type":"message"}
{"nick":"joepie91","message":"but restarting might","date":"2017-02-01T01:18:49.479Z","type":"message"}
{"nick":"macabre","date":"2017-02-01T01:18:56.476Z","type":"join"}
{"nick":"modernpacifist","message":"Its not too hard in the scheme of things to have the new cluster members on warm standby","date":"2017-02-01T01:19:00.508Z","type":"message"}
{"nick":"joepie91","message":"basically, you do all the deployment steps except for actually replacing the daemon","date":"2017-02-01T01:19:04.504Z","type":"message"}
{"nick":"chridal","message":"yea, that's what we need modernpacifist","date":"2017-02-01T01:19:09.175Z","type":"message"}
{"nick":"modernpacifist","message":"Then you can just 'reload' the load balancer","date":"2017-02-01T01:19:10.295Z","type":"message"}
{"nick":"joepie91","message":"and the daemon replacement is a coordinated restart","date":"2017-02-01T01:19:12.611Z","type":"message"}
{"nick":"joepie91","message":"if you have a centralized load balancer, then yes, that's also possible","date":"2017-02-01T01:19:23.246Z","type":"message"}
{"nick":"claytonzaugg","date":"2017-02-01T01:19:28.558Z","type":"join"}
{"nick":"modernpacifist","message":"Or even a HA balancer","date":"2017-02-01T01:19:32.426Z","type":"message"}
{"nick":"chridal","message":"yeapp, every thing is going through ELB","date":"2017-02-01T01:19:35.982Z","type":"message"}
{"nick":"Scarecr0w","date":"2017-02-01T01:19:43.778Z","type":"join"}
{"nick":"ed209","reason":"Remote host closed the connection","date":"2017-02-01T01:20:01.694Z","type":"quit"}
{"nick":"ed209","date":"2017-02-01T01:20:08.246Z","type":"join"}
{"nick":"chridal","message":"So we should probably just sever the connections then for a few seconds, and have them queue up their messages and resend once their on the new servers","date":"2017-02-01T01:20:45.494Z","type":"message"}
{"nick":"modernpacifist","message":"That would be ideal","date":"2017-02-01T01:20:58.129Z","type":"message"}
{"nick":"zhodge","date":"2017-02-01T01:21:05.732Z","type":"join"}
{"nick":"a_thakur","reason":"Remote host closed the connection","date":"2017-02-01T01:21:06.795Z","type":"quit"}
{"nick":"chridal","message":"But what about using Redis` Pub/Sub for talking between the servers?","date":"2017-02-01T01:21:07.055Z","type":"message"}
{"nick":"kus_","reason":"Remote host closed the connection","date":"2017-02-01T01:21:35.887Z","type":"quit"}
{"nick":"kus_","date":"2017-02-01T01:21:54.908Z","type":"join"}
{"nick":"joepie91","message":"chridal: not sure I'd use Redis for that personally unless I had a concrete reason","date":"2017-02-01T01:22:29.538Z","type":"message"}
{"nick":"chjj","reason":"Ping timeout: 255 seconds","date":"2017-02-01T01:22:31.478Z","type":"quit"}
{"nick":"joepie91","message":"chridal: pubsub is a trivial concept to implement if you have long-running processes and it can be more practical to roll your own","date":"2017-02-01T01:22:41.696Z","type":"message"}
{"nick":"chridal","message":"it's mostly just because we have to use Redis for storing room/user data","date":"2017-02-01T01:22:47.251Z","type":"message"}
{"nick":"OMSQ","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2017-02-01T01:22:50.806Z","type":"quit"}
{"nick":"chridal","message":"joepie91: That would give us another server to maintain and scale though","date":"2017-02-01T01:23:05.067Z","type":"message"}
{"nick":"d10n-work","reason":"Quit: Connection closed for inactivity","date":"2017-02-01T01:23:06.252Z","type":"quit"}
{"nick":"joepie91","message":"chridal: right, if you're already using Redis, it may be worth it","date":"2017-02-01T01:23:17.536Z","type":"message"}
{"nick":"asteele","message":"chridal im coming in late, but for huge distributed stuff like that, i think you generally want to distribute *all* messages to the edge of each cluster, then that edge finds any receiving users connected","date":"2017-02-01T01:23:19.995Z","type":"message"}
{"nick":"macabre","reason":"Ping timeout: 255 seconds","date":"2017-02-01T01:23:25.474Z","type":"quit"}
{"nick":"joepie91","message":"[02:20] <chridal> So we should probably just sever the connections then for a few seconds, and have them queue up their messages and resend once their on the new servers","date":"2017-02-01T01:23:29.342Z","type":"message"}
{"nick":"joepie91","message":"yes :P","date":"2017-02-01T01:23:30.857Z","type":"message"}
{"nick":"joepie91","message":"and most importantly, don't present it to the user as \"offline\"","date":"2017-02-01T01:23:40.194Z","type":"message"}
{"nick":"joepie91","message":"because that will make users complain just because it says offline","date":"2017-02-01T01:23:52.108Z","type":"message"}
{"nick":"whathappens","reason":"Quit: Leaving...","date":"2017-02-01T01:23:56.491Z","type":"quit"}
{"nick":"joepie91","message":"even if it doesn't cause them any issues","date":"2017-02-01T01:23:56.721Z","type":"message"}
{"nick":"chridal","message":"spinners all over the place :-P","date":"2017-02-01T01:23:58.850Z","type":"message"}
{"nick":"modernpacifist","message":"I would present the server status as \"currently ephemeral","date":"2017-02-01T01:24:00.203Z","type":"message"}
{"nick":"asteele","message":"at least thats kind of how Twitch explained they scaled their chat system","date":"2017-02-01T01:24:06.880Z","type":"message"}
{"nick":"joepie91","message":"(this is a part of why XMPP utterly fails UX-wise)","date":"2017-02-01T01:24:15.112Z","type":"message"}
{"nick":"modernpacifist","message":"And the time it takes the user to look up ephemeral should be enough for your servers to come bac konline","date":"2017-02-01T01:24:21.768Z","type":"message"}
{"nick":"chridal","message":"asteele: hm, why are they doing it like that?","date":"2017-02-01T01:24:28.933Z","type":"message"}
{"nick":"chridal","message":"Is there an article?","date":"2017-02-01T01:24:31.134Z","type":"message"}
{"nick":"joepie91","message":"haha","date":"2017-02-01T01:24:32.327Z","type":"message"}
{"nick":"chridal","message":"modernpacifist: clever :-D","date":"2017-02-01T01:24:47.593Z","type":"message"}
{"nick":"modernpacifist","message":"chridal: :P or \"something something Schrödinger cat\"","date":"2017-02-01T01:25:12.413Z","type":"message"}
{"nick":"Scarecr0w","reason":"Quit: http://quassel-irc.org - Chat comfortably. Anywhere.","date":"2017-02-01T01:25:14.168Z","type":"quit"}
{"nick":"chridal","message":"that would screw them over indeed","date":"2017-02-01T01:25:27.865Z","type":"message"}
{"nick":"chridal","message":":-D","date":"2017-02-01T01:25:32.208Z","type":"message"}
{"nick":"chridal","message":"asteele: You're pushing a lot more data if you're pushing everything to every node","date":"2017-02-01T01:26:14.617Z","type":"message"}
{"nick":"chridal","message":"So I am curious as to what is the benefit over keeping one channel per node","date":"2017-02-01T01:26:32.252Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: there should be an \"impractically clever\" blog for solutions like yours that are utterly useless but that you still can't really argue against","date":"2017-02-01T01:26:42.054Z","type":"message"}
{"nick":"joepie91","message":":p","date":"2017-02-01T01:26:43.553Z","type":"message"}
{"nick":"chridal","message":"I guess you could argue against it from the point of user hostility","date":"2017-02-01T01:27:05.980Z","type":"message"}
{"nick":"chridal","message":"But who says user hostility can't be healthy at times :-P","date":"2017-02-01T01:27:14.717Z","type":"message"}
{"nick":"Scarecr0w","date":"2017-02-01T01:27:36.976Z","type":"join"}
{"nick":"joepie91","message":"we have a BOFH here!","date":"2017-02-01T01:27:38.597Z","type":"message"}
{"nick":"joepie91","message":":p","date":"2017-02-01T01:27:40.079Z","type":"message"}
{"nick":"chridal","message":":-D","date":"2017-02-01T01:28:12.984Z","type":"message"}
{"nick":"asteele","message":"chridal because its the only way to actually scale it, otherwise you need a central look up of every connected user anywhere","date":"2017-02-01T01:28:47.326Z","type":"message"}
{"nick":"nomoney4u","message":"weird: res.sendFile('../public/reports.html', {root: __dirname}) gives me the \"forbidden\" error as well.","date":"2017-02-01T01:28:56.655Z","type":"message"}
{"nick":"asteele","message":"which will start to fail on you once you hit a few million people online","date":"2017-02-01T01:29:00.290Z","type":"message"}
{"nick":"asteele","message":"(or much much sooner)","date":"2017-02-01T01:29:06.157Z","type":"message"}
{"nick":"Havvy","message":"BOFH?","date":"2017-02-01T01:29:18.622Z","type":"message"}
{"nick":"modernpacifist","message":"joepie91: I would support such a blog, if only to see some of them deployed en masse","date":"2017-02-01T01:29:24.486Z","type":"message"}
{"nick":"asteele","message":"chridal not just who is connected, but what type of messages they should receive, and what cluster they are actually connected to","date":"2017-02-01T01:29:31.060Z","type":"message"}
{"nick":"joepie91","message":"Havvy: https://en.wikipedia.org/wiki/Bastard_Operator_From_Hell","date":"2017-02-01T01:29:32.264Z","type":"message"}
{"nick":"GreenJello","message":"nomoney4u, use path.join like I said","date":"2017-02-01T01:29:38.302Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: :(","date":"2017-02-01T01:29:45.350Z","type":"message"}
{"nick":"dirtyroshi","reason":"Quit: Leaving","date":"2017-02-01T01:29:51.772Z","type":"quit"}
{"nick":"modernpacifist","message":"joepie91: I said I support it! :)","date":"2017-02-01T01:30:05.199Z","type":"message"}
{"nick":"asteele","message":"chridal they dont have any articles on it, i was there in person and also watched all of their VODs from TwitchCon where their tech teams explain it in pieces, you have to watch multiple different talks/panels to get the full picture","date":"2017-02-01T01:30:27.833Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: yes, it was the prospect of people actually deploying this that made me sadface :P","date":"2017-02-01T01:30:50.070Z","type":"message"}
{"nick":"nomoney4u","message":"GreenJello, is that an additional npm that I need to grab? is it this one? https://www.npmjs.com/package/path.join","date":"2017-02-01T01:31:24.763Z","type":"message"}
{"nick":"rorro","reason":"Ping timeout: 255 seconds","date":"2017-02-01T01:31:35.962Z","type":"quit"}
{"nick":"modernpacifist","message":"joepie91: Surely it could be written off as a psychological experiment and a paper could come out of it","date":"2017-02-01T01:31:36.137Z","type":"message"}
{"nick":"GreenJello","message":"nomoney4u, just var path = require('path')","date":"2017-02-01T01:32:11.080Z","type":"message"}
{"nick":"modernpacifist","message":"Here in australia we could probably even get a tax refund for it being under R&D","date":"2017-02-01T01:32:14.506Z","type":"message"}
{"nick":"GreenJello","message":"nomoney4u, it's a node core module","date":"2017-02-01T01:32:15.408Z","type":"message"}
{"nick":"GreenJello","message":"don't need to install anything","date":"2017-02-01T01:32:20.111Z","type":"message"}
{"nick":"nomoney4u","message":"GreenJello, got it :) thank you.","date":"2017-02-01T01:32:30.089Z","type":"message"}
{"nick":"joepie91","message":"modernpacifist: I hereby voluntell you to write that blog :D","date":"2017-02-01T01:32:31.268Z","type":"message"}
{"nick":"joepie91","message":"hehe","date":"2017-02-01T01:32:35.736Z","type":"message"}
{"nick":"zumba_addict","reason":"Read error: Connection timed out","date":"2017-02-01T01:32:56.994Z","type":"quit"}
{"nick":"modernpacifist","message":"We should have some interns soon so thats easily...delegated","date":"2017-02-01T01:32:57.895Z","type":"message"}
{"nick":"joepie91","message":"lol","date":"2017-02-01T01:33:04.460Z","type":"message"}
{"nick":"chridal","message":"asteele: What types of messages they should receive is decided by the node sending the message.","date":"2017-02-01T01:33:14.462Z","type":"message"}
{"nick":"chridal","message":"And looking up which node the user is connected to only needs to be done once, and can then be cached on the node sending the message","date":"2017-02-01T01:33:31.773Z","type":"message"}
{"nick":"asteele","message":"chridal but at a high level it looked like this: ingest point -> massive filter -> fan out messages to a hub in each cluster -> hub determines if anyone in the cluster should receive the message -> sends the message to proper server in the cluster","date":"2017-02-01T01:33:41.231Z","type":"message"}
{"nick":"modernpacifist","message":"Although that might be setting the wrong example - as your first project in the industry I want you to describe ways to impart subtle confusion onto our user base","date":"2017-02-01T01:33:47.614Z","type":"message"}
{"nick":"miklb","reason":"\"Textual IRC Client: www.textualapp.com\"","date":"2017-02-01T01:33:53.422Z","type":"part"}
{"nick":"modernpacifist","message":"While fires are put out behind the scenes","date":"2017-02-01T01:33:56.534Z","type":"message"}
{"nick":"asteele","message":"i didnt get the full details on your situations o sorry if the solution isnt applicable","date":"2017-02-01T01:34:06.147Z","type":"message"}
{"nick":"chridal","message":"So there's a hub in each cluster that actually will send the message to a node then?","date":"2017-02-01T01:34:45.228Z","type":"message"}
{"nick":"asteele","message":"yes","date":"2017-02-01T01:34:49.223Z","type":"message"}
{"nick":"chridal","message":"I was thinking more of pulling it off a channel","date":"2017-02-01T01:35:20.040Z","type":"message"}
{"nick":"asteele","message":"they have named for all this but its been like 6 months since i watched it all and wrote it down, would have to go look in my notes","date":"2017-02-01T01:35:27.441Z","type":"message"}
{"nick":"chridal","message":"I am really curious why they decided on this architecture.. Hm","date":"2017-02-01T01:35:44.112Z","type":"message"}
{"nick":"knob","reason":"Quit: Leaving","date":"2017-02-01T01:35:45.117Z","type":"quit"}
{"nick":"joepie91","message":"asteele: chridal: if I had to take a guess, the goal here is to split the computational work","date":"2017-02-01T01:35:50.481Z","type":"message"}
{"nick":"chridal","message":"how many videos did you have to watch?","date":"2017-02-01T01:35:51.787Z","type":"message"}
{"nick":"wtr","reason":"Quit: I will be back! ^^","date":"2017-02-01T01:35:53.986Z","type":"quit"}
{"nick":"asteele","message":"it has to do with their specific goal, and their actual scale","date":"2017-02-01T01:35:56.953Z","type":"message"}
{"nick":"chridal","message":"Which year? Were they on YouTube?","date":"2017-02-01T01:36:00.130Z","type":"message"}
{"nick":"asteele","message":"not youtube, i can find you some links, you can get most the info from 2-4 vids","date":"2017-02-01T01:36:14.811Z","type":"message"}
{"nick":"joepie91","message":"asteele: chridal: that is, each hub only needs to care about its own cluster of users, whereas the ingest point only needs to care about distributing to hubs... which means you can scale further","date":"2017-02-01T01:36:18.598Z","type":"message"}
{"nick":"asteele","message":"it was this past year in september","date":"2017-02-01T01:36:21.978Z","type":"message"}
{"nick":"chjj","date":"2017-02-01T01:36:23.270Z","type":"join"}
{"nick":"joepie91","message":"as compared to distributing to *all* users from a single hub","date":"2017-02-01T01:36:28.713Z","type":"message"}
{"nick":"asteele","message":"right joepie91","date":"2017-02-01T01:36:33.470Z","type":"message"}
{"nick":"chridal","message":"It's just that I can't see how that would necessarily scale any further than what I am proposing","date":"2017-02-01T01:36:51.897Z","type":"message"}
{"nick":"asteele","message":"then to scale you just add more clusters, and ideally you can scale to infinity*","date":"2017-02-01T01:36:54.582Z","type":"message"}
{"nick":"chridal","message":"though I might be wrong","date":"2017-02-01T01:36:55.968Z","type":"message"}
{"nick":"joepie91","message":"asteele: well, sort of","date":"2017-02-01T01:37:01.112Z","type":"message"}
{"nick":"joepie91","message":"asteele: you're still limited by the bandwidth of the ingest point","date":"2017-02-01T01:37:08.289Z","type":"message"}
{"nick":"asteele","message":"yea","date":"2017-02-01T01:37:14.474Z","type":"message"}
{"nick":"joepie91","message":"chridal: one sec","date":"2017-02-01T01:37:22.272Z","type":"message"}
{"nick":"asteele","message":"theres still some limitations, but it does open you up for a lot of room","date":"2017-02-01T01:37:29.422Z","type":"message"}
{"nick":"chridal","message":"But the system I am proposing the computation would also be split, since the node sending the message decide which channel it needs to go into, and then the receiving node will pull it off and forward it onto the socket","date":"2017-02-01T01:37:36.444Z","type":"message"}
{"nick":"joepie91","message":"chridal: pull it off where?","date":"2017-02-01T01:37:54.787Z","type":"message"}
{"nick":"chridal","message":"Pub/Sub channel","date":"2017-02-01T01:37:59.757Z","type":"message"}
{"nick":"chridal","message":"one for each node","date":"2017-02-01T01:38:04.643Z","type":"message"}
{"nick":"joepie91","message":"yes, but that's an abstract concept","date":"2017-02-01T01:38:07.056Z","type":"message"}
{"nick":"joepie91","message":"pull it off what server?","date":"2017-02-01T01:38:12.541Z","type":"message"}
{"nick":"chridal","message":"Redis","date":"2017-02-01T01:38:15.581Z","type":"message"}
{"nick":"joepie91","message":"which has which responsibilities?","date":"2017-02-01T01:38:15.755Z","type":"message"}
{"nick":"chridal","message":"You could also use a MQ","date":"2017-02-01T01:38:22.886Z","type":"message"}
{"nick":"joepie91","message":"chridal: so your Redis server is your bottleneck, yes?","date":"2017-02-01T01:38:30.908Z","type":"message"}
{"nick":"joepie91","message":"as in, everything passes through there","date":"2017-02-01T01:38:41.422Z","type":"message"}
{"nick":"chridal","message":"Right","date":"2017-02-01T01:38:45.607Z","type":"message"}
{"nick":"sqram","message":"joepie91: implemented your version, thank you. do have a question though","date":"2017-02-01T01:38:50.485Z","type":"message"}
{"nick":"asteele","message":"brb 10 min, i can find the vids for you if you want when im back chridal","date":"2017-02-01T01:39:11.882Z","type":"message"}
{"nick":"joepie91","message":"chridal: now your Redis server has to do multiple things: 1) storing messages, 2) accepting queries, and 3) filtering the stored messages","date":"2017-02-01T01:39:15.261Z","type":"message"}
{"nick":"chridal","message":"asteele: Thanks","date":"2017-02-01T01:39:19.016Z","type":"message"}
{"nick":"chridal","message":"joepie91: Why does it have to acecpt queries and filter stored messages?","date":"2017-02-01T01:39:36.505Z","type":"message"}
{"nick":"nomoney4u","message":"since I can't serve json+html, my reading/researching brings me to a conclusion that I need a template system, is that correct? if so, what is the popular ones nowaday? SO shows answers from 2015","date":"2017-02-01T01:39:42.291Z","type":"message"}
{"nick":"joepie91","message":"chridal: in the Twitch model, the bottleneck (ingestion point) has to do less: it only has to 1) store messages, 2) send out those messages (which is a cheaper operation than accepting queries and filtering)","date":"2017-02-01T01:39:44.455Z","type":"message"}
{"nick":"chridal","message":"Once you publish a message it instantly pops up on the subscribers end","date":"2017-02-01T01:39:52.156Z","type":"message"}
{"nick":"chridal","message":"That's exactly what Redis will do.","date":"2017-02-01T01:40:04.627Z","type":"message"}
{"nick":"joepie91","message":"chridal: \"and then the receiving node will pull it off and forward it onto the socket\"","date":"2017-02-01T01:40:09.061Z","type":"message"}
{"nick":"joepie91","message":"this involves a query","date":"2017-02-01T01:40:12.906Z","type":"message"}
{"nick":"joepie91","message":"of some variety","date":"2017-02-01T01:40:17.269Z","type":"message"}
{"nick":"chridal","message":"That's not how Pub/Sub in Redis works","date":"2017-02-01T01:40:23.303Z","type":"message"}
{"nick":"chridal","message":"You subscribe to a channel","date":"2017-02-01T01:40:26.915Z","type":"message"}
{"nick":"joepie91","message":"I feel like you're thinking of this too high-level","date":"2017-02-01T01:40:27.283Z","type":"message"}
{"nick":"arpu","reason":"Ping timeout: 240 seconds","date":"2017-02-01T01:40:27.507Z","type":"quit"}
{"nick":"chridal","message":"and you receive data","date":"2017-02-01T01:40:30.447Z","type":"message"}
{"nick":"joepie91","message":"yes, I know how it works","date":"2017-02-01T01:40:32.764Z","type":"message"}
{"nick":"joepie91","message":"it's still a query","date":"2017-02-01T01:40:35.438Z","type":"message"}
{"nick":"joepie91","message":"internally","date":"2017-02-01T01:40:36.945Z","type":"message"}
{"nick":"joepie91","message":"you need to think lower-level","date":"2017-02-01T01:40:39.621Z","type":"message"}
{"nick":"joepie91","message":"the amount of computational work involved","date":"2017-02-01T01:40:43.507Z","type":"message"}
{"nick":"joepie91","message":"in your model, Redis needs to care about which messages go where","date":"2017-02-01T01:41:00.624Z","type":"message"}
{"nick":"joepie91","message":"in the Twitch model, the bottleneck server doesn't","date":"2017-02-01T01:41:08.217Z","type":"message"}
{"nick":"joepie91","message":"it just blasts it everywhere and lets the hub servers figure out that part","date":"2017-02-01T01:41:14.933Z","type":"message"}
{"nick":"joepie91","message":"this reduces the load on the bottleneck server","date":"2017-02-01T01:41:22.568Z","type":"message"}
{"nick":"joepie91","message":"which is the single most important thing in scaling horizontally - reduce the load on your bottlenecks to an absolute minimum","date":"2017-02-01T01:41:34.233Z","type":"message"}
{"nick":"chridal","message":"but then that wouldn't be their bottleneck, would it?","date":"2017-02-01T01:41:35.857Z","type":"message"}
{"nick":"joepie91","message":"what do you mean?","date":"2017-02-01T01:41:42.801Z","type":"message"}
{"nick":"chridal","message":"I mean that their bottleneck would then be the hub?","date":"2017-02-01T01:41:56.675Z","type":"message"}
{"nick":"chridal","message":"Or?","date":"2017-02-01T01:41:58.982Z","type":"message"}
{"nick":"joepie91","message":"no","date":"2017-02-01T01:42:03.324Z","type":"message"}
{"nick":"joepie91","message":"because you can add any amount of hubs","date":"2017-02-01T01:42:06.644Z","type":"message"}
{"nick":"joepie91","message":"until your ingestion point runs out of bandwidth","date":"2017-02-01T01:42:11.191Z","type":"message"}
{"nick":"joepie91","message":"that's the trick","date":"2017-02-01T01:42:17.059Z","type":"message"}
{"nick":"joepie91","message":"there's not one hub","date":"2017-02-01T01:42:19.361Z","type":"message"}
{"nick":"chridal","message":"Isn't there only one hub per cluster?","date":"2017-02-01T01:42:22.485Z","type":"message"}
{"nick":"joepie91","message":"there's as many hubs as you need","date":"2017-02-01T01:42:23.991Z","type":"message"}
{"nick":"SwiftMatt","reason":"Quit: My MacBook Pro has gone to sleep. ZZZzzz…","date":"2017-02-01T01:42:28.449Z","type":"quit"}
{"nick":"joepie91","message":"yes, so you add clusters as necessary","date":"2017-02-01T01:42:29.631Z","type":"message"}
{"nick":"chridal","message":"Aha.","date":"2017-02-01T01:42:29.805Z","type":"message"}
{"nick":"karmahacker","date":"2017-02-01T01:42:33.633Z","type":"join"}
{"nick":"joepie91","message":"if your clusters get too many users, you create new clusters","date":"2017-02-01T01:42:36.703Z","type":"message"}
{"nick":"chridal","message":"But then that makes the hub the bottleneck for the cluster?","date":"2017-02-01T01:42:42.076Z","type":"message"}
{"nick":"chridal","message":"because the nodes might be able to handle more","date":"2017-02-01T01:42:50.236Z","type":"message"}
{"nick":"chridal","message":"but the hub can't push more","date":"2017-02-01T01:42:52.878Z","type":"message"}
{"nick":"joepie91","message":"yep, which is why it's important that you can arbitrarily create new clusters","date":"2017-02-01T01:42:57.187Z","type":"message"}
{"nick":"joepie91","message":"without consistency issues","date":"2017-02-01T01:43:00.943Z","type":"message"}
{"nick":"chridal","message":"That still makes the hub the bottleneck","date":"2017-02-01T01:43:05.653Z","type":"message"}
{"nick":"joepie91","message":"which is what the Twitch model allows for","date":"2017-02-01T01:43:05.827Z","type":"message"}
{"nick":"joepie91","message":"no","date":"2017-02-01T01:43:08.122Z","type":"message"}
{"nick":"joepie91","message":"chridal: the bottleneck is the thing you can't upgrade or add more of","date":"2017-02-01T01:43:24.829Z","type":"message"}
{"nick":"joepie91","message":"simply put","date":"2017-02-01T01:43:29.441Z","type":"message"}
{"nick":"superlou","date":"2017-02-01T01:43:35.847Z","type":"join"}
{"nick":"joepie91","message":"that's not the hub (since you can create more of those), that's the ingestion point","date":"2017-02-01T01:43:37.655Z","type":"message"}
{"nick":"joepie91","message":"which is the \"point of authority\" for what messages are processed","date":"2017-02-01T01:43:45.707Z","type":"message"}
{"nick":"chridal","message":"But you could also horizontally scale Redis, so I don't see your point","date":"2017-02-01T01:43:51.148Z","type":"message"}
{"nick":"joepie91","message":"not without losing consistency or adopting a similar architecture on Redis' end","date":"2017-02-01T01:44:07.481Z","type":"message"}
{"nick":"joepie91","message":"you're treating Redis like a magic tool","date":"2017-02-01T01:44:11.884Z","type":"message"}
{"nick":"joepie91","message":"this doesn't work when you need to scale a lot","date":"2017-02-01T01:44:20.810Z","type":"message"}
{"nick":"joepie91","message":"you need to actually understand how your tools work and why","date":"2017-02-01T01:44:26.447Z","type":"message"}
{"nick":"chridal","message":"not saying it's magic, just saying that I'm struggling to see how the hub is not a bottleneck","date":"2017-02-01T01:44:31.913Z","type":"message"}
{"nick":"chridal","message":"If the nodes behind the hub would be able to process more, and you have to add a new cluster because the hub can't handle more messages","date":"2017-02-01T01:44:56.083Z","type":"message"}
{"nick":"joepie91","message":"what I'm describing is just a fundamental solution to distributed systems, and if you want consistency in a horizontally scalable environment, that kind of model is what you need - whether you implement it yourself or whether you let a tool like Redis (or whatever else) do it","date":"2017-02-01T01:44:57.767Z","type":"message"}
{"nick":"chridal","message":"then that would make that hub a bottleneck","date":"2017-02-01T01:45:02.442Z","type":"message"}
{"nick":"joepie91","message":"chridal: you're misinterpreting \"bottleneck\"","date":"2017-02-01T01:45:15.990Z","type":"message"}
{"nick":"joepie91","message":"\"bottleneck\" doesn't mean \"thing that's currently overloaded\" in this context","date":"2017-02-01T01:45:25.486Z","type":"message"}
{"nick":"joepie91","message":"think of it in the sense of a bottleneck on a road, where three roads come together and go through one point","date":"2017-02-01T01:45:43.377Z","type":"message"}
{"nick":"jon_x114","reason":"Ping timeout: 256 seconds","date":"2017-02-01T01:45:45.860Z","type":"quit"}
{"nick":"joepie91","message":"it's not a bottleneck because it's busy, it's a bottleneck because it tries to squeeze three roads together","date":"2017-02-01T01:45:55.552Z","type":"message"}
{"nick":"joepie91","message":"I'm using it in the same sense here; it's the central 'hub' that all your traffic goes through","date":"2017-02-01T01:46:09.486Z","type":"message"}
{"nick":"joepie91","message":"that you cannot easily split up into multiple systems","date":"2017-02-01T01:46:17.551Z","type":"message"}
{"nick":"ekkis","date":"2017-02-01T01:46:23.297Z","type":"join"}
{"nick":"chridal","message":"So basically you arrange clusters so that hubs maximum processing ability matches that of the rest of the cluster","date":"2017-02-01T01:46:27.739Z","type":"message"}
{"nick":"tinyfrox","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:46:31.111Z","type":"quit"}
{"nick":"chridal","message":"so that they won't be limited by the hub?","date":"2017-02-01T01:46:33.519Z","type":"message"}
{"nick":"joepie91","message":"yeah","date":"2017-02-01T01:46:36.043Z","type":"message"}
{"nick":"joepie91","message":"and if you run out of total capacity, you create new clusters with new hubs","date":"2017-02-01T01:46:47.006Z","type":"message"}
{"nick":"joepie91","message":"to expand that capacity","date":"2017-02-01T01:46:50.292Z","type":"message"}
{"nick":"chridal","message":"and you blast all messages to all the hubs?","date":"2017-02-01T01:46:57.318Z","type":"message"}
{"nick":"rchavik","date":"2017-02-01T01:47:06.931Z","type":"join"}
{"nick":"karmahacker","reason":"Ping timeout: 240 seconds","date":"2017-02-01T01:47:11.636Z","type":"quit"}
{"nick":"joepie91","message":"which has relatively little impact on the ingestion point (central hub) since it's just a dumb message forwarder that doesn't care about what's being forwarded and doesn';t have to do any computation on it","date":"2017-02-01T01:47:13.957Z","type":"message"}
{"nick":"saigel","date":"2017-02-01T01:47:17.804Z","type":"join"}
{"nick":"joepie91","message":"it just sends it to One More Place","date":"2017-02-01T01:47:21.303Z","type":"message"}
{"nick":"joepie91","message":"chridal: yep","date":"2017-02-01T01:47:22.848Z","type":"message"}
{"nick":"chridal","message":"so it's a router","date":"2017-02-01T01:47:25.578Z","type":"message"}
{"nick":"joepie91","message":"a \"router\" still has logic about what goes where","date":"2017-02-01T01:47:40.013Z","type":"message"}
{"nick":"joepie91","message":"that's the routing part","date":"2017-02-01T01:47:43.051Z","type":"message"}
{"nick":"joepie91","message":"this wouldn't even necessarily do that :P","date":"2017-02-01T01:47:49.022Z","type":"message"}
{"nick":"the_ant","reason":"Quit: the_ant","date":"2017-02-01T01:48:10.556Z","type":"quit"}
{"nick":"chridal","message":"Hm. So the central hub then receives all messages from all nodes, and pushes them to all other hubs?","date":"2017-02-01T01:48:13.450Z","type":"message"}
{"nick":"joepie91","message":"think more powerstrip than ethernet switch; if it's plugged in, it gets stuff","date":"2017-02-01T01:48:14.806Z","type":"message"}
{"nick":"chridal","message":"So all messages constantly flow to all hubs?","date":"2017-02-01T01:48:19.698Z","type":"message"}
{"nick":"joepie91","message":"power isn't just sent to specific sockets","date":"2017-02-01T01:48:22.836Z","type":"message"}
{"nick":"joepie91","message":"yeah","date":"2017-02-01T01:48:27.614Z","type":"message"}
{"nick":"joepie91","message":"that's the model as I understand it","date":"2017-02-01T01:48:31.687Z","type":"message"}
{"nick":"chridal","message":"so it's a hub :-P","date":"2017-02-01T01:48:33.507Z","type":"message"}
{"nick":"chridal","message":"rather than a switch","date":"2017-02-01T01:48:36.855Z","type":"message"}
{"nick":"chridal","message":"hehe","date":"2017-02-01T01:48:39.054Z","type":"message"}
{"nick":"joepie91","message":"yes, I'm just adopting the terminology that asteele introduced :)","date":"2017-02-01T01:48:46.272Z","type":"message"}
{"nick":"joepie91","message":"I would probably call the central-most thing the \"hub\" as well","date":"2017-02-01T01:49:01.043Z","type":"message"}
{"nick":"joepie91","message":"and maybe call the 'hubs' in the clusters a \"router\" or something","date":"2017-02-01T01:49:11.820Z","type":"message"}
{"nick":"chridal","message":"What I'm struggling to see is just why it would be more beneficial to send every single message to every single hub","date":"2017-02-01T01:49:14.572Z","type":"message"}
{"nick":"chridal","message":"There must be a better way","date":"2017-02-01T01:49:16.952Z","type":"message"}
{"nick":"joepie91","message":"chridal: let's switch to hub/router as terminology, like I just described?","date":"2017-02-01T01:49:29.172Z","type":"message"}
{"nick":"joepie91","message":"hub is the central-most thing, router the thing that does stuff for a cluster","date":"2017-02-01T01:49:40.488Z","type":"message"}
{"nick":"joepie91","message":"might clear up the confusion a bit","date":"2017-02-01T01:49:47.932Z","type":"message"}
{"nick":"chridal","message":"Yeapp, that part is quite fine now","date":"2017-02-01T01:49:55.287Z","type":"message"}
{"nick":"asteele","message":"re ;p","date":"2017-02-01T01:50:06.936Z","type":"message"}
{"nick":"chridal","message":"I just don't see why you have to blast every message every where. Can't you optimize that?","date":"2017-02-01T01:50:09.583Z","type":"message"}
{"nick":"joepie91","message":"chridal: right. so the reason is that the hub now doesn't have to care about the content of the messages, and so isn't limited by computational capacity","date":"2017-02-01T01:50:14.566Z","type":"message"}
{"nick":"asteele","message":"yeah my terminology wasnt super proper, just random words from my brain","date":"2017-02-01T01:50:18.213Z","type":"message"}
{"nick":"joepie91","message":"chridal: that *is* the optimization","date":"2017-02-01T01:50:20.781Z","type":"message"}
{"nick":"joepie91","message":"chridal: you're trading bandwidth capacity for CPU capacity","date":"2017-02-01T01:50:29.076Z","type":"message"}
{"nick":"joepie91","message":"bandwidth is much easier to scale","date":"2017-02-01T01:50:33.134Z","type":"message"}
{"nick":"chridal","message":"but it leads to tons of data being sent that you don't have to send?","date":"2017-02-01T01:50:35.432Z","type":"message"}
{"nick":"joepie91","message":"yes","date":"2017-02-01T01:50:39.092Z","type":"message"}
{"nick":"chridal","message":"Aha.","date":"2017-02-01T01:50:40.151Z","type":"message"}
{"nick":"joepie91","message":"but in return for that, you can process more messages with the same CPU power on your bottleneck","date":"2017-02-01T01:50:52.872Z","type":"message"}
{"nick":"Romen","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:51:01.023Z","type":"quit"}
{"nick":"chridal","message":"The computation here isn't super complex though. You could just do proper adressing.","date":"2017-02-01T01:51:04.932Z","type":"message"}
{"nick":"chridal","message":"if you did hierarchical adressing like IP does","date":"2017-02-01T01:51:20.562Z","type":"message"}
{"nick":"joepie91","message":"chridal: \"simple routing\" can be orders of magnitude more expensive than just forwarding bytes","date":"2017-02-01T01:51:25.206Z","type":"message"}
{"nick":"chridal","message":"yes, it would be more expensive","date":"2017-02-01T01:51:34.369Z","type":"message"}
{"nick":"joepie91","message":"right, but that's the problem","date":"2017-02-01T01:51:39.024Z","type":"message"}
{"nick":"chridal","message":"but it kills my heart to think about all that bandwidth","date":"2017-02-01T01:51:42.952Z","type":"message"}
{"nick":"JohnBeal_","date":"2017-02-01T01:51:43.125Z","type":"join"}
{"nick":"chridal","message":":-P","date":"2017-02-01T01:51:45.065Z","type":"message"}
{"nick":"joepie91","message":"chridal: keep in mind that scaling horizontally virtually always means more overhead","date":"2017-02-01T01:51:54.471Z","type":"message"}
{"nick":"joepie91","message":"same for any distributed system","date":"2017-02-01T01:51:58.109Z","type":"message"}
{"nick":"JohnBeales","reason":"Ping timeout: 245 seconds","date":"2017-02-01T01:51:58.282Z","type":"quit"}
{"nick":"joepie91","message":"yet another reason I say 'avoid distributed systems if you can'","date":"2017-02-01T01:52:12.778Z","type":"message"}
{"nick":"joepie91","message":":P","date":"2017-02-01T01:52:14.307Z","type":"message"}
{"nick":"asteele","message":"joepie91 i saw you say earlier you rcommend against horizontal scaling? what are you meaning then, you should try and scale vertically first?","date":"2017-02-01T01:52:23.367Z","type":"message"}
{"nick":"asteele","message":"chridal you can get most of that bandwidth for free if youre sending it between your aws servers","date":"2017-02-01T01:52:44.663Z","type":"message"}
{"nick":"joepie91","message":"asteele: yes","date":"2017-02-01T01:52:48.226Z","type":"message"}
{"nick":"asteele","message":"and twitch is owned by amazon so","date":"2017-02-01T01:52:51.977Z","type":"message"}
{"nick":"chridal","message":"That's true. Bandwidth doesn't matter at all for them.","date":"2017-02-01T01:53:08.374Z","type":"message"}
{"nick":"joepie91","message":"asteele: it's much less complex to scale vertically, it's much less error-prone, it's generally cheaper (in terms of resources, not necessarily in cost, that depends), and you have to make less consistency tradeoffs","date":"2017-02-01T01:53:23.312Z","type":"message"}
{"nick":"chridal","message":"I guess the only way to say anything about this is to do both, measure, and see the pricing difference.","date":"2017-02-01T01:53:32.829Z","type":"message"}
{"nick":"jon_x114","date":"2017-02-01T01:53:39.241Z","type":"join"}
{"nick":"asteele","message":"joepie91 but how do you scale your node app vertically?","date":"2017-02-01T01:53:43.463Z","type":"message"}
{"nick":"joepie91","message":"asteele: It Depends(tm)","date":"2017-02-01T01:53:56.613Z","type":"message"}
{"nick":"joepie91","message":"most of vertical scaling is \"run it on beefier hardware\"","date":"2017-02-01T01:54:03.419Z","type":"message"}
{"nick":"arpu","date":"2017-02-01T01:54:15.702Z","type":"join"}
{"nick":"joepie91","message":"in the case of Node specifically, it being single-threaded can be a problem","date":"2017-02-01T01:54:16.947Z","type":"message"}
{"nick":"chridal","message":"you have no availability though","date":"2017-02-01T01:54:21.805Z","type":"message"}
{"nick":"joepie91","message":"but there's a few possible solutions for that","date":"2017-02-01T01:54:22.242Z","type":"message"}
{"nick":"chridal","message":"joepie91: Won't you need multiple instances just to get it to run on multiple cores?","date":"2017-02-01T01:54:42.008Z","type":"message"}
{"nick":"Romen","date":"2017-02-01T01:54:45.920Z","type":"join"}
{"nick":"joepie91","message":"including multi-process (less tradeoffs than scaling horizontally between machines, but nonzero), outsourcing work to processes in other languages, compiled modules, etc.","date":"2017-02-01T01:54:51.806Z","type":"message"}
{"nick":"joepie91","message":"chridal: Node itself, yes","date":"2017-02-01T01:54:55.822Z","type":"message"}
{"nick":"joepie91","message":"all of your application, not necessarily","date":"2017-02-01T01:55:03.843Z","type":"message"}
{"nick":"chridal","message":"so you'd have to \"horizontally\" scale any way","date":"2017-02-01T01:55:09.888Z","type":"message"}
{"nick":"joepie91","message":"as for availability: you can scale vertically and still replicate","date":"2017-02-01T01:55:11.755Z","type":"message"}
{"nick":"chridal","message":"there would be more instances","date":"2017-02-01T01:55:14.754Z","type":"message"}
{"nick":"joepie91","message":"no, not necessarily","date":"2017-02-01T01:55:18.503Z","type":"message"}
{"nick":"chridal","message":"of the application","date":"2017-02-01T01:55:19.562Z","type":"message"}
{"nick":"chridal","message":"please elaborate","date":"2017-02-01T01:55:24.406Z","type":"message"}
{"nick":"joepie91","message":"chridal: if I write a Rust or C++ addon that I use in my Node application and 90% of the work happens in that addon, I'll be maxing out all my 8 cores even though my Node process only runs on one core, because the addon can use threads to consume the other 7","date":"2017-02-01T01:56:04.883Z","type":"message"}
{"nick":"claytonzaugg","date":"2017-02-01T01:56:32.520Z","type":"quit"}
{"nick":"chridal","message":"that's a very specific use-case though","date":"2017-02-01T01:56:37.871Z","type":"message"}
{"nick":"joepie91","message":"chridal: sure, but scaling beyond a single process is a pretty rare to happen","date":"2017-02-01T01:56:53.449Z","type":"message"}
{"nick":"joepie91","message":"rare thing*","date":"2017-02-01T01:56:56.741Z","type":"message"}
{"nick":"joyee","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:56:58.095Z","type":"quit"}
{"nick":"joepie91","message":"there are two orders of magnitude more people who *think* they need to scale than there are people who *actually* need to scale ;)","date":"2017-02-01T01:57:13.517Z","type":"message"}
{"nick":"chridal","message":"how so? Why not run multiple instances of your server on the same host?","date":"2017-02-01T01:57:15.528Z","type":"message"}
{"nick":"joyee","date":"2017-02-01T01:57:20.742Z","type":"join"}
{"nick":"chridal","message":"Yes, obv, but for the sake of ragument","date":"2017-02-01T01:57:28.562Z","type":"message"}
{"nick":"asteele","message":"joepie91 so is your argument is mainly that *most people* should scale vertically until they are running everything on 16gb/8core (or related) servers?  and only at that point should you consider scaling horizontally?  Or are you saying vertical scaling can go even further than horizontal","date":"2017-02-01T01:57:31.426Z","type":"message"}
{"nick":"joepie91","message":"asteele: the former","date":"2017-02-01T01:57:43.032Z","type":"message"}
{"nick":"asteele","message":"gotcha","date":"2017-02-01T01:57:46.516Z","type":"message"}
{"nick":"joepie91","message":"horizontal has higher upper bounds but at the cost of consistency, usually","date":"2017-02-01T01:57:57.655Z","type":"message"}
{"nick":"chridal","message":"that still leaves you with zero availability","date":"2017-02-01T01:58:00.399Z","type":"message"}
{"nick":"joepie91","message":"chridal: availability is a separate problem","date":"2017-02-01T01:58:13.050Z","type":"message"}
{"nick":"ploop","reason":"Ping timeout: 258 seconds","date":"2017-02-01T01:58:16.293Z","type":"quit"}
{"nick":"joepie91","message":"[02:57] <chridal> how so? Why not run multiple instances of your server on the same host?","date":"2017-02-01T01:58:17.301Z","type":"message"}
{"nick":"joepie91","message":"because now you have to make sure that you maintain consistency between the processes, and *if* 90% of your work can be outsourced to an add-on and you wouldn't have to deal with this, why wouldn't you pick that option?","date":"2017-02-01T01:58:41.420Z","type":"message"}
{"nick":"chridal","message":"That sort of wasn't a counter argument to the vertical scaling","date":"2017-02-01T01:59:03.870Z","type":"message"}
{"nick":"joepie91","message":"chridal: as for availability, think of it in the simplest way: literally mirror every operation on a second server","date":"2017-02-01T01:59:15.922Z","type":"message"}
{"nick":"chridal","message":"but more if you're doing horizontal scaling, you can run multiple instances on the same host","date":"2017-02-01T01:59:17.871Z","type":"message"}
{"nick":"joepie91","message":"you're still scaling vertically, you're just doing the same work twice","date":"2017-02-01T01:59:23.034Z","type":"message"}
{"nick":"chridal","message":"Good luck doing that with a websocket-server","date":"2017-02-01T01:59:34.932Z","type":"message"}
{"nick":"joepie91","message":"chridal: what do you mean?","date":"2017-02-01T01:59:42.222Z","type":"message"}
{"nick":"stoneburner","reason":"Read error: Connection reset by peer","date":"2017-02-01T01:59:44.816Z","type":"quit"}
{"nick":"chridal","message":"I mean it's going to be just as painful","date":"2017-02-01T01:59:48.458Z","type":"message"}
{"nick":"joepie91","message":"you're making a very vague argument, there's not really anything concrete I can respond to here...","date":"2017-02-01T02:00:08.052Z","type":"message"}
{"nick":"chridal","message":"Rather, it's going to be painful. I don't know if it's going to be AS painful","date":"2017-02-01T02:00:10.038Z","type":"message"}
{"nick":"joepie91","message":"this is like saying \"there are problems\"","date":"2017-02-01T02:00:25.318Z","type":"message"}
{"nick":"nya_","date":"2017-02-01T02:00:25.947Z","type":"join"}
{"nick":"chridal","message":"What I'm saying is; if you're going to be doing that work twice: how are you going to be doing that?}","date":"2017-02-01T02:00:26.323Z","type":"message"}
{"nick":"asteele","message":"yeah not sure the relation for your websocket example","date":"2017-02-01T02:00:28.687Z","type":"message"}
{"nick":"joepie91","message":"okay, what _are_ those problems?","date":"2017-02-01T02:00:29.799Z","type":"message"}
{"nick":"joepie91","message":"chridal: this is not a question that has a generic answer","date":"2017-02-01T02:00:44.167Z","type":"message"}
{"nick":"asteele","message":"websocket servers actually should scale vertically first, regardless, because they are all about state","date":"2017-02-01T02:00:45.318Z","type":"message"}
{"nick":"joepie91","message":"it depends on your usecase","date":"2017-02-01T02:00:46.493Z","type":"message"}
{"nick":"atatsu","date":"2017-02-01T02:00:53.690Z","type":"join"}
{"nick":"joepie91","message":"chridal: there is no one universal answer to scalability, anybody who says there is is either lying, trying to sell you something, or both","date":"2017-02-01T02:01:01.615Z","type":"message"}
{"nick":"nya_","reason":"Read error: Connection reset by peer","date":"2017-02-01T02:01:08.660Z","type":"quit"}
{"nick":"ploop","date":"2017-02-01T02:01:09.605Z","type":"join"}
{"nick":"stoneburner","date":"2017-02-01T02:01:13.070Z","type":"join"}
{"nick":"chridal","message":"Not saying there's a universal answer","date":"2017-02-01T02:01:15.354Z","type":"message"}
{"nick":"joepie91","message":"you need to understand the principles behind it, the tradeoffs it introduces, and figure out the right solution for your specific scaling issue with your specific requirements","date":"2017-02-01T02:01:23.312Z","type":"message"}
{"nick":"chridal","message":"But say you are doing HA for a webscoket-server","date":"2017-02-01T02:01:38.210Z","type":"message"}
{"nick":"chridal","message":"doing vertical scaling","date":"2017-02-01T02:01:41.772Z","type":"message"}
{"nick":"chridal","message":"how are you going to do that?","date":"2017-02-01T02:01:45.376Z","type":"message"}
{"nick":"chridal","message":"just for the sake of argument","date":"2017-02-01T02:01:51.103Z","type":"message"}
{"nick":"noodman","date":"2017-02-01T02:01:52.969Z","type":"quit"}
{"nick":"asteele","message":"HA? haproxy?","date":"2017-02-01T02:01:56.427Z","type":"message"}
{"nick":"chridal","message":"high availability","date":"2017-02-01T02:02:02.136Z","type":"message"}
{"nick":"nya_","date":"2017-02-01T02:02:02.524Z","type":"join"}
{"nick":"kus_","reason":"Remote host closed the connection","date":"2017-02-01T02:02:38.993Z","type":"quit"}
{"nick":"joepie91","message":"chridal: you haven't specified anywhere near enough details for me to give a meaningful answer here that I haven't already given","date":"2017-02-01T02:02:39.973Z","type":"message"}
{"nick":"joyee_","date":"2017-02-01T02:02:54.417Z","type":"join"}
{"nick":"joepie91","message":"it's dependent on what you're building, what kind of data you're working with, the requirements (consistency etc) for each of those kinds of data","date":"2017-02-01T02:03:03.812Z","type":"message"}
{"nick":"chridal","message":"You said that you would mirror everything happening on the main server on a second server","date":"2017-02-01T02:03:06.477Z","type":"message"}
{"nick":"joepie91","message":"what kind of clients are being used","date":"2017-02-01T02:03:10.271Z","type":"message"}
{"nick":"joepie91","message":"etc etc etc","date":"2017-02-01T02:03:11.938Z","type":"message"}
{"nick":"BlueProtoman","date":"2017-02-01T02:03:16.715Z","type":"join"}
{"nick":"joepie91","message":"no, this was a simplified example","date":"2017-02-01T02:03:22.213Z","type":"message"}
{"nick":"chridal","message":"and the nswap it with DNS or something?","date":"2017-02-01T02:03:26.812Z","type":"message"}
{"nick":"chridal","message":"I just want to know how you were planning on doing it.","date":"2017-02-01T02:03:33.744Z","type":"message"}
{"nick":"joepie91","message":"to demonstrate that scalability and availability are two separate problems","date":"2017-02-01T02:03:34.438Z","type":"message"}
{"nick":"chridal","message":"Because I don't see it as being plausible","date":"2017-02-01T02:03:39.452Z","type":"message"}
{"nick":"joepie91","message":"chridal: I wasn't planning anything, because *I don't have a concrete case*","date":"2017-02-01T02:03:48.713Z","type":"message"}
{"nick":"joepie91","message":"again: it was an example for illustrative purposes","date":"2017-02-01T02:03:57.423Z","type":"message"}
{"nick":"asteele","message":"chridal what part of it do you not see as plausible","date":"2017-02-01T02:04:03.500Z","type":"message"}
{"nick":"miklb","date":"2017-02-01T02:04:36.409Z","type":"join"}
{"nick":"chridal","message":"The second server, you can't failover to it.","date":"2017-02-01T02:04:43.008Z","type":"message"}
{"nick":"asteele","message":"node itself will limit you because 1 core and process memory limit (1.5g or something?), but that doesnt change the principle of vertical first","date":"2017-02-01T02:04:52.368Z","type":"message"}
{"nick":"chridal","message":"Also, you're not going to be mirroring anything on it. What should you be mirroring? Sockets? Just didn't make any sense.","date":"2017-02-01T02:04:58.698Z","type":"message"}
{"nick":"publio","reason":"Quit: Bye.","date":"2017-02-01T02:05:07.753Z","type":"quit"}
{"nick":"chridal","message":"But ok, we might've been talking past one another","date":"2017-02-01T02:05:27.483Z","type":"message"}
{"nick":"joepie91","message":"chridal: again: I cannot give any meaningful answers here without a more concrete scaling case","date":"2017-02-01T02:05:28.717Z","type":"message"}
{"nick":"chridal","message":"So it doesn't matter","date":"2017-02-01T02:05:30.068Z","type":"message"}
{"nick":"chridal","message":"a lot get lost in transit","date":"2017-02-01T02:05:44.985Z","type":"message"}
{"nick":"joepie91","message":"my example was not specifically about websockets","date":"2017-02-01T02:05:45.329Z","type":"message"}
{"nick":"miklb","reason":"Remote host closed the connection","date":"2017-02-01T02:05:45.765Z","type":"quit"}
{"nick":"asteele","message":"chridal maybe explain an example case of your app, what it would be doing, if 100k people were on it","date":"2017-02-01T02:05:54.723Z","type":"message"}
{"nick":"chridal","message":"yeapp, but mine is.","date":"2017-02-01T02:05:54.897Z","type":"message"}
{"nick":"mezod","reason":"Remote host closed the connection","date":"2017-02-01T02:05:56.005Z","type":"quit"}
{"nick":"SwiftMatt","date":"2017-02-01T02:06:00.355Z","type":"join"}
{"nick":"asteele","message":"and where you anticipate problems","date":"2017-02-01T02:06:24.090Z","type":"message"}
{"nick":"chridal","message":"well, I want to do horizontal scaling through Pub/Sub, or maybe using the strategy that you proposed earlier","date":"2017-02-01T02:06:32.259Z","type":"message"}
{"nick":"joyee","reason":"Ping timeout: 240 seconds","date":"2017-02-01T02:06:41.593Z","type":"quit"}
{"nick":"asteele","message":"start with the problem not the solution","date":"2017-02-01T02:06:47.165Z","type":"message"}
{"nick":"saigel","reason":"Ping timeout: 248 seconds","date":"2017-02-01T02:06:58.799Z","type":"quit"}
{"nick":"chridal","message":"The problem is for instance; what if one of your servers go down.","date":"2017-02-01T02:07:01.058Z","type":"message"}
{"nick":"chridal","message":"You're going to have to be able to reconnect to another server instantly, and have it pick up where you were.","date":"2017-02-01T02:07:20.166Z","type":"message"}
{"nick":"sdgsdg","date":"2017-02-01T02:07:31.973Z","type":"join"}
{"nick":"chridal","message":"I don't believe in trusting one server. What do you do if there's an issue in AWS' region?","date":"2017-02-01T02:07:53.567Z","type":"message"}
{"nick":"ironfroggy","date":"2017-02-01T02:07:53.990Z","type":"join"}
{"nick":"chridal","message":"Just take the downtime?","date":"2017-02-01T02:07:59.846Z","type":"message"}
{"nick":"asteele","message":"websockets automatically failing over requires its own solution that is outside of the realm of horizontal vs vertical scaling, i would think","date":"2017-02-01T02:08:02.947Z","type":"message"}
{"nick":"chridal","message":"You're going to have to have nodes in multiple regions.","date":"2017-02-01T02:08:08.469Z","type":"message"}
{"nick":"sdgsdg","reason":"Client Quit","date":"2017-02-01T02:08:21.352Z","type":"quit"}
{"nick":"joepie91","message":"chridal: you haven't yet specified what your application *is*","date":"2017-02-01T02:08:22.336Z","type":"message"}
{"nick":"chridal","message":"asteele: Not really, because you could maintain two connections.","date":"2017-02-01T02:08:22.834Z","type":"message"}
{"nick":"asteele","message":"you are kind of assuming that, if you use horizontal, failover is built in","date":"2017-02-01T02:08:30.034Z","type":"message"}
{"nick":"chridal","message":"It's a VoIP service with possibility of sending video/images as well.","date":"2017-02-01T02:08:40.440Z","type":"message"}
{"nick":"harai","date":"2017-02-01T02:08:42.549Z","type":"join"}
{"nick":"chridal","message":"asteele: What makes you say that I'm assuming that?","date":"2017-02-01T02:08:56.586Z","type":"message"}
{"nick":"chridal","message":"VoIP is WebRTC","date":"2017-02-01T02:09:06.799Z","type":"message"}
{"nick":"joepie91","message":"okay, but that's very vague","date":"2017-02-01T02:09:17.390Z","type":"message"}
{"nick":"joepie91","message":"what *kind* of voip service?","date":"2017-02-01T02:09:23.959Z","type":"message"}
{"nick":"joepie91","message":"you need to apparently connect everybody to everybody","date":"2017-02-01T02:09:29.609Z","type":"message"}
{"nick":"joepie91","message":"judging from your descriptions so far","date":"2017-02-01T02:09:32.791Z","type":"message"}
{"nick":"asteele","message":"chridal because you are positing horizontal scaling as the solution for server downtime","date":"2017-02-01T02:09:33.854Z","type":"message"}
{"nick":"joepie91","message":"which is not typical for a voip service","date":"2017-02-01T02:09:36.152Z","type":"message"}
{"nick":"asteele","message":"or that is my understanding, sorry if i misunderstand","date":"2017-02-01T02:09:46.824Z","type":"message"}
{"nick":"zumba_addict","date":"2017-02-01T02:09:51.129Z","type":"join"}
{"nick":"chridal","message":"joepie91: That's just with the current design using WebRTC's P2P","date":"2017-02-01T02:10:01.012Z","type":"message"}
{"nick":"chridal","message":"we'll be using an SFU once we get everything up and running","date":"2017-02-01T02:10:08.424Z","type":"message"}
{"nick":"chridal","message":"once there's more than 3 clients","date":"2017-02-01T02:10:11.270Z","type":"message"}
{"nick":"chridal","message":"more than 2 clients **","date":"2017-02-01T02:10:19.912Z","type":"message"}
{"nick":"joepie91","message":"chridal: but this goes into implementation again","date":"2017-02-01T02:10:20.087Z","type":"message"}
{"nick":"asteele","message":"something still needs to know, hey server a is down, we need to send traffic to somewhere else, and that is not built in","date":"2017-02-01T02:10:23.311Z","type":"message"}
{"nick":"joepie91","message":"chridal: okay, let me ask this differently","date":"2017-02-01T02:10:28.322Z","type":"message"}
{"nick":"chridal","message":"asteele: The client knows the server is down, because it's not getting a ping.","date":"2017-02-01T02:10:36.615Z","type":"message"}
{"nick":"joepie91","message":"chridal: if I were an investor, and you had two minutes to pitch your idea to me, how would you describe it?","date":"2017-02-01T02:10:39.327Z","type":"message"}
{"nick":"chridal","message":"joepie91: I'm not pitching it.","date":"2017-02-01T02:10:51.653Z","type":"message"}
{"nick":"asteele","message":"chridal if only the client knows, then horizontal scaling wont help you at all - your architecture needs to know the server is down, so it can route requests away from it and to healthy instances","date":"2017-02-01T02:11:12.055Z","type":"message"}
{"nick":"chridal","message":"We're keeping this under the radar until launch.","date":"2017-02-01T02:11:14.166Z","type":"message"}
{"nick":"asteele","message":"discord already does eeverything you said","date":"2017-02-01T02:11:27.572Z","type":"message"}
{"nick":"asteele","message":"so is it really that secretive?","date":"2017-02-01T02:11:32.594Z","type":"message"}
{"nick":"joepie91","message":"chridal: then I can't really give any meaningful answers because I don't have a high-level understanding of what the project is for, and thus I cannot infer requirements from it","date":"2017-02-01T02:11:34.818Z","type":"message"}
{"nick":"chridal","message":"asteele: Sure. :-)","date":"2017-02-01T02:11:36.216Z","type":"message"}
{"nick":"polydo_s","date":"2017-02-01T02:11:39.507Z","type":"join"}
{"nick":"ab-rex","reason":"Remote host closed the connection","date":"2017-02-01T02:11:51.738Z","type":"quit"}
{"nick":"chridal","message":"This is just way too messy any way.","date":"2017-02-01T02:11:54.567Z","type":"message"}
{"nick":"asteele","message":"what is","date":"2017-02-01T02:12:01.550Z","type":"message"}
{"nick":"joepie91","message":"(I also strongly doubt that it's as secret as you are presenting it to be, because ideas are generally worthless without execution, but eh)","date":"2017-02-01T02:12:03.407Z","type":"message"}
{"nick":"chridal","message":"Impossible to do a discussion like this.","date":"2017-02-01T02:12:04.186Z","type":"message"}
{"nick":"asteele","message":"really, i think you are getting some pretty good info","date":"2017-02-01T02:12:12.639Z","type":"message"}
{"nick":"chridal","message":"Two people ascing differnting questions, with differing opinions, and differing points of view etc.","date":"2017-02-01T02:12:17.983Z","type":"message"}
{"nick":"asteele","message":"and both of us are trying to help","date":"2017-02-01T02:12:18.246Z","type":"message"}
{"nick":"asteele","message":"well okay then :/","date":"2017-02-01T02:12:27.613Z","type":"message"}
{"nick":"chridal","message":"I really appreciate it. That's not what I mean.","date":"2017-02-01T02:12:36.054Z","type":"message"}
{"nick":"chridal","message":"I'm just saying I can't keep you both happy.","date":"2017-02-01T02:12:41.845Z","type":"message"}
{"nick":"joepie91","message":"chridal: I'm just trying to obtain enough information about your project to give a non-misleading answer","date":"2017-02-01T02:12:46.394Z","type":"message"}
{"nick":"joepie91","message":"I'd rather give no answer than one that I expect to be wrong","date":"2017-02-01T02:12:53.535Z","type":"message"}
{"nick":"asteele","message":"you wont find the answer to this in any articles","date":"2017-02-01T02:13:02.005Z","type":"message"}
{"nick":"chridal","message":"Well, we need more STRUCTURE here.","date":"2017-02-01T02:13:06.540Z","type":"message"}
{"nick":"chridal","message":"Let me explain the case, and the requirements.","date":"2017-02-01T02:13:14.150Z","type":"message"}
{"nick":"joepie91","message":"scalability is a super-specialized topic so you can't really say or advise anything meaningful about it without knowing all the details of the problem to be solved","date":"2017-02-01T02:13:16.671Z","type":"message"}
{"nick":"asteele","message":"because it really does depend on your use case.  Twitch built their whole setup i explained, knowing the problem and hard parts","date":"2017-02-01T02:13:24.589Z","type":"message"}
{"nick":"chridal","message":"sure, but we're just pumping tons of info and no one is reading anything.","date":"2017-02-01T02:13:35.545Z","type":"message"}
{"nick":"chridal","message":"I'll have to read up on it. It's fine. It's 03:30 AM atm :-P","date":"2017-02-01T02:13:46.187Z","type":"message"}
{"nick":"chridal","message":"I'm not doing this. It's too much talking past one another etc.","date":"2017-02-01T02:13:56.128Z","type":"message"}
{"nick":"chridal","message":"I'll properly describe everything in a Gist, and then post it tomorrow or something.","date":"2017-02-01T02:14:12.915Z","type":"message"}
{"nick":"chridal","message":"Anyway, I think I'll just go for the forwarding everything to everyone.","date":"2017-02-01T02:15:28.399Z","type":"message"}
{"nick":"jlipps","reason":"Ping timeout: 240 seconds","date":"2017-02-01T02:15:41.624Z","type":"quit"}
{"nick":"chridal","message":"Just because it solves another issue that I wasn't liking: having to maintain the sockets state in Redis.","date":"2017-02-01T02:15:42.385Z","type":"message"}
{"nick":"saslam","reason":"Ping timeout: 245 seconds","date":"2017-02-01T02:15:43.251Z","type":"quit"}
{"nick":"polydo_s","reason":"Remote host closed the connection","date":"2017-02-01T02:15:56.668Z","type":"quit"}
{"nick":"joyee_","reason":"Remote host closed the connection","date":"2017-02-01T02:16:03.851Z","type":"quit"}
{"nick":"chridal","message":"I'd have to constantly expire the keys for which user is where based on ping","date":"2017-02-01T02:16:08.450Z","type":"message"}
{"nick":"joepie91","message":"chridal: I've read everything you've said btw :p","date":"2017-02-01T02:16:14.046Z","type":"message"}
{"nick":"asteele","message":"same, besides when i was gone or wasnt here yet","date":"2017-02-01T02:16:27.060Z","type":"message"}
{"nick":"ecuanaso","date":"2017-02-01T02:16:27.399Z","type":"join"}
{"nick":"chridal","message":"joepie91: I meant when there's 3 people having a discussion with differing view points, different angles etc. Talking at the same time etc.","date":"2017-02-01T02:16:36.952Z","type":"message"}
{"nick":"chridal","message":"I can't maintain and answer to everything at the same time.","date":"2017-02-01T02:16:52.030Z","type":"message"}
{"nick":"chridal","message":"It's just impossible.","date":"2017-02-01T02:16:55.990Z","type":"message"}
{"nick":"chridal","message":"By the time I've answered, you've conjured some other issue :-P","date":"2017-02-01T02:17:04.588Z","type":"message"}
{"nick":"joepie91","message":"chridal: keep in mind that I don't expect instant answers :P","date":"2017-02-01T02:17:30.677Z","type":"message"}
{"nick":"mcollina","date":"2017-02-01T02:17:36.576Z","type":"join"}
{"nick":"joepie91","message":"if it takes a while to think things over and write a long response, that's fine","date":"2017-02-01T02:17:37.203Z","type":"message"}
{"nick":"chridal","message":"Yea, that's why I said I'd write a proper Gist instead.","date":"2017-02-01T02:17:47.997Z","type":"message"}
{"nick":"joepie91","message":"right :P","date":"2017-02-01T02:17:56.706Z","type":"message"}
{"nick":"chridal","message":"It's too much back and forth, and I never get to lay it out in the proper way.","date":"2017-02-01T02:18:01.311Z","type":"message"}
{"nick":"jkridner","reason":"Read error: Connection reset by peer","date":"2017-02-01T02:18:09.668Z","type":"quit"}
{"nick":"asteele","message":"i dont mind not typing anything","date":"2017-02-01T02:18:11.171Z","type":"message"}
{"nick":"BlueProtoman","reason":"\"Leaving\"","date":"2017-02-01T02:18:12.360Z","type":"part"}
{"nick":"joepie91","action":"shall await that gist","date":"2017-02-01T02:18:15.572Z","type":"action"}
{"nick":"asteele","message":"if you want to go ahead and lay it all out","date":"2017-02-01T02:18:16.554Z","type":"message"}
{"nick":"chridal","message":"That's not what I meant. I'll do a proper Gist tomorrow. It's 03:30.","date":"2017-02-01T02:18:33.946Z","type":"message"}
{"nick":"chridal","message":"I'd rather just talk more about scaling in the general sense or whatever.","date":"2017-02-01T02:18:43.757Z","type":"message"}
{"nick":"asteele","message":"ok","date":"2017-02-01T02:18:44.564Z","type":"message"}
{"nick":"jkridner","date":"2017-02-01T02:18:48.374Z","type":"join"}
{"nick":"joepie91","message":"chridal: \"await\" in the sense of \"whenever it comes around\",  not in the sense of \"it better be done in 30 mins\" :P","date":"2017-02-01T02:18:53.354Z","type":"message"}
{"nick":"chridal","message":":-D","date":"2017-02-01T02:19:02.509Z","type":"message"}
{"nick":"joepie91","message":"if that's in two days, that's fine too","date":"2017-02-01T02:19:09.111Z","type":"message"}
{"nick":"asteele","message":"chridal worth noting though, it is common to get multiple opinions in public channels, sometimes youll get much more than 2.  i think its best to see this as getting many different informed opinions at once, you need to kind of think through for yourself which is the best answer for your situation","date":"2017-02-01T02:19:44.927Z","type":"message"}
{"nick":"jeffreylevesque_","date":"2017-02-01T02:20:45.287Z","type":"join"}
{"nick":"asteele","message":"some topics have a very 1 or 0 answer, some have no correct answer","date":"2017-02-01T02:21:07.296Z","type":"message"}
{"nick":"trcm","reason":"Ping timeout: 276 seconds","date":"2017-02-01T02:21:27.523Z","type":"quit"}
{"nick":"chridal","message":"Sure, and getting multiple answers are great. It's just that I sort of struggle talking to multiple people at once.","date":"2017-02-01T02:21:59.723Z","type":"message"}
{"nick":"Somatt_","date":"2017-02-01T02:22:07.504Z","type":"join"}
{"nick":"mcollina","reason":"Ping timeout: 240 seconds","date":"2017-02-01T02:22:11.575Z","type":"quit"}
{"nick":"chridal","message":"I have sort of ADD-ish tendencies, and my brain just flies off","date":"2017-02-01T02:22:18.906Z","type":"message"}
{"nick":"chridal","message":"one person is usually enough to send my head spinning :-P","date":"2017-02-01T02:22:26.897Z","type":"message"}
{"nick":"asteele","message":"and to be fair, hearing 'scale vertically first!' is counter intuitive to most of the articles about scale you will read","date":"2017-02-01T02:23:12.754Z","type":"message"}
{"nick":"asteele","message":"but i dont disagree with joepie91 , its a simple argument about premature optimization","date":"2017-02-01T02:23:25.736Z","type":"message"}
{"nick":"chridal","message":"I guess I just also put HA into the bin with scaling","date":"2017-02-01T02:23:49.096Z","type":"message"}
{"nick":"joepie91","message":"asteele: this is probably because vertical scaling isn't usually recognized as scaling at all","date":"2017-02-01T02:24:05.992Z","type":"message"}
{"nick":"joepie91","message":"in the current \"scale all the things!\" hype","date":"2017-02-01T02:24:10.239Z","type":"message"}
{"nick":"joepie91","message":"so either you scale horizontally or you don't say anything about scaling at all because buying a larger instance is *just what you do*","date":"2017-02-01T02:24:31.200Z","type":"message"}
{"nick":"asteele","message":"lol yea that is true","date":"2017-02-01T02:24:40.239Z","type":"message"}
{"nick":"joepie91","message":"result: all scaling stuff seems to be about horizontal scaling","date":"2017-02-01T02:24:43.639Z","type":"message"}
{"nick":"chridal","message":"But shouldn't every service have a server in at least two different regions?","date":"2017-02-01T02:25:18.457Z","type":"message"}
{"nick":"chridal","message":"Let me correct that","date":"2017-02-01T02:25:24.195Z","type":"message"}
{"nick":"chridal","message":"in two different datacenters?","date":"2017-02-01T02:25:27.870Z","type":"message"}
{"nick":"asteele","message":"sure but thats availability, not scale","date":"2017-02-01T02:25:34.797Z","type":"message"}
{"nick":"chridal","message":"Yea, I'm mixing too much of this stuff together. Because I'm tying it up to my specific use case.","date":"2017-02-01T02:26:13.383Z","type":"message"}
{"nick":"asteele","message":"i understand the confusion","date":"2017-02-01T02:26:34.319Z","type":"message"}
{"nick":"chridal","message":"which leaves you stranded, because you don't know the use case, and so it doesn't make any sense :-P","date":"2017-02-01T02:26:35.007Z","type":"message"}
{"nick":"Somatt_","reason":"Ping timeout: 240 seconds","date":"2017-02-01T02:26:36.519Z","type":"quit"}
{"nick":"joepie91","message":"[03:25] <chridal> But shouldn't every service have a server in at least two different regions?","date":"2017-02-01T02:26:54.799Z","type":"message"}
{"nick":"joepie91","message":"no","date":"2017-02-01T02:26:56.275Z","type":"message"}
{"nick":"Scarecr0w","message":"Good evening gentlemen & gentlewomen, I was wondering if it is a good idea to use simple HTML+CSS+JS to request info from REST API or is there a better approach?","date":"2017-02-01T02:27:02.175Z","type":"message"}
{"nick":"chridal","message":"it's not actually confusion, it's me taking shortcuts in my brain","date":"2017-02-01T02:27:04.125Z","type":"message"}
{"nick":"joepie91","message":"for the majority of projects, being down for an hour a month is absolutely not a big deal","date":"2017-02-01T02:27:12.569Z","type":"message"}
{"nick":"joepie91","message":"if you're running a business off it, sure, look for some availability","date":"2017-02-01T02:27:23.384Z","type":"message"}
{"nick":"joepie91","message":"but even then you can often get away with a lot","date":"2017-02-01T02:27:27.008Z","type":"message"}
{"nick":"joepie91","message":"it's absolutely not a given that you need a redundant setup","date":"2017-02-01T02:27:34.200Z","type":"message"}
{"nick":"chridal","message":"joepie91: I was assuming a business use-case","date":"2017-02-01T02:27:40.545Z","type":"message"}
{"nick":"asteele","message":"well the confusion would be: if you are scaling vertically, but you also have built in failovers in another region - it *seems* like you are horizontally scaling","date":"2017-02-01T02:27:48.746Z","type":"message"}
{"nick":"joepie91","message":"it depends on the business","date":"2017-02-01T02:27:48.920Z","type":"message"}
{"nick":"chridal","message":"but I guess that boils down to requirements","date":"2017-02-01T02:27:53.255Z","type":"message"}
{"nick":"chridal","message":"given that you require 100% presence, you'd need it.","date":"2017-02-01T02:28:06.652Z","type":"message"}
{"nick":"joepie91","message":"chridal: but my core point here is: you only need redundancy (for availability purposes) if you can motivate why you do","date":"2017-02-01T02:28:12.139Z","type":"message"}
{"nick":"joepie91","message":"and many people and companies *can* motivate why they do, don't get me wrong","date":"2017-02-01T02:28:24.010Z","type":"message"}
{"nick":"joepie91","message":"it's just not a fact of development life :P","date":"2017-02-01T02:28:29.503Z","type":"message"}
{"nick":"chridal","message":"asteele: You sort of could be though.","date":"2017-02-01T02:28:50.819Z","type":"message"}
{"nick":"chridal","message":"If you put both of those instances between a load-balancer, and they're REST APIs for instance","date":"2017-02-01T02:29:00.399Z","type":"message"}
{"nick":"chridal","message":"then you're effectively doing some horizontal scaling :-D","date":"2017-02-01T02:29:07.183Z","type":"message"}
{"nick":"chridal","message":"behind **","date":"2017-02-01T02:29:11.954Z","type":"message"}
{"nick":"joepie91","message":"Scarecr0w: your question isn't really clear. what are you trying to build?","date":"2017-02-01T02:29:14.976Z","type":"message"}
{"nick":"chridal","message":"joepie91: A SPA, it seems","date":"2017-02-01T02:29:28.017Z","type":"message"}
{"nick":"joepie91","message":"chridal: having multiple servers doesn't make it scaling horizontally :P","date":"2017-02-01T02:29:42.460Z","type":"message"}
{"nick":"joepie91","message":"depends on implementation","date":"2017-02-01T02:29:50.393Z","type":"message"}
{"nick":"chridal","message":"If they are REST APIs behind a load-balancer doing round-robin, you are.","date":"2017-02-01T02:30:04.014Z","type":"message"}
{"nick":"joepie91","message":"for example, if you use a replicate-everything model like I described, your effective server capacity of the two combined servers is the same as that of one server","date":"2017-02-01T02:30:12.453Z","type":"message"}
{"nick":"joepie91","message":"so you're not scaling at all","date":"2017-02-01T02:30:15.001Z","type":"message"}
{"nick":"kaicataldo","date":"2017-02-01T02:30:17.333Z","type":"join"}
{"nick":"joepie91","message":"no, see above example :P","date":"2017-02-01T02:30:19.015Z","type":"message"}
{"nick":"joepie91","message":"your capacity doesn't increase","date":"2017-02-01T02:30:26.079Z","type":"message"}
{"nick":"joepie91","message":"because each operation still has to happen on both servers","date":"2017-02-01T02:30:35.824Z","type":"message"}
{"nick":"asteele","message":"chridal but, if you are not actively sending requests to your failover, it isnt really horizontal scaling at all.  If you are sending traffic to the other one, then yes it would be considered horizontal scaling, but that doesnt necessarily solve HA","date":"2017-02-01T02:30:38.593Z","type":"message"}
{"nick":"chridal","message":"why does it not solve HA?","date":"2017-02-01T02:31:12.248Z","type":"message"}
{"nick":"asteele","message":"because what is both servers drop off","date":"2017-02-01T02:31:27.722Z","type":"message"}
{"nick":"asteele","message":"you have nothing in place to boot new servers up, your load balancer doenst know what to do","date":"2017-02-01T02:31:39.587Z","type":"message"}
{"nick":"chridal","message":"You could say that about anything.","date":"2017-02-01T02:31:40.196Z","type":"message"}
{"nick":"Scarecr0w","message":"@joepie91 A private authentication (login) system, it's a group based. Nothing commercial.","date":"2017-02-01T02:31:40.914Z","type":"message"}
{"nick":"joepie91","message":"chridal: HA != redundancy","date":"2017-02-01T02:32:11.714Z","type":"message"}
{"nick":"joepie91","message":"chridal: an important part of HA is the ability to deploy new failover services","date":"2017-02-01T02:32:24.421Z","type":"message"}
{"nick":"chridal","message":"Ah!","date":"2017-02-01T02:32:40.127Z","type":"message"}
{"nick":"joepie91","message":"99.999% uptime is much more expensive than 99.99% uptime which is much more expensive than 99.9% etc","date":"2017-02-01T02:33:35.683Z","type":"message"}
{"nick":"chridal","message":"If I was in the right mood now I'd say that that's not exponential","date":"2017-02-01T02:34:03.677Z","type":"message"}
{"nick":"joepie91","message":"chridal: my mental math is a bit fuzzy right now but I think that qualifies as exponential given that you're adding more precision?","date":"2017-02-01T02:34:25.743Z","type":"message"}
{"nick":"asteele","message":"chridal AWS also provides infrastructure for it.  At least for detecting fails, you have to write the stuff to boot up a new instance and have it ready for receiving traffic in your own AMI's","date":"2017-02-01T02:34:34.402Z","type":"message"}
{"nick":"chridal","message":"joepie91: Is it really exponential, though?","date":"2017-02-01T02:34:45.663Z","type":"message"}
{"nick":"chridal","message":"asteele: Yea, that's not really too big of an issue.","date":"2017-02-01T02:34:58.996Z","type":"message"}
{"nick":"chridal","message":"You can do it with ELB and some simple scripts.","date":"2017-02-01T02:35:09.952Z","type":"message"}
{"nick":"joepie91","message":"Scarecr0w: but where do the REST API come in, and if you consider \"HTML+CSS+JS\" one of the options, then what are the other options?","date":"2017-02-01T02:35:14.167Z","type":"message"}
{"nick":"chridal","message":"ELB will ping and remove unhealthy hosts","date":"2017-02-01T02:35:25.451Z","type":"message"}
{"nick":"joepie91","message":"chridal: I believe it is? I'd have to double-check but I recall reading an actual analysis of the average costs for more nines and iirc it was exponential","date":"2017-02-01T02:35:43.793Z","type":"message"}
{"nick":"chridal","message":"I'm sure you can set up auto-scaling to monitor the number of unhealthy hosts as well","date":"2017-02-01T02:35:45.889Z","type":"message"}
{"nick":"asteele","message":"chridal so its all about, when an unhealthy host is detected, firing off something to boot a new instance and add it into the elb rotation","date":"2017-02-01T02:35:51.850Z","type":"message"}
{"nick":"asteele","message":"yes if you set up an autoscale group with the right AMI, it will handle lots of this for you","date":"2017-02-01T02:36:04.828Z","type":"message"}
{"nick":"chridal","message":"joepie91: It's fine though. It was mostly a joke since you did that long-winded argument some time back about how it was not exponential. So I was really just poking fun :-)","date":"2017-02-01T02:36:17.075Z","type":"message"}
{"nick":"joepie91","message":"aside: of course, if you let AWS handle your HA, you're still relying on Amazon as a company","date":"2017-02-01T02:36:21.128Z","type":"message"}
{"nick":"joepie91","message":"chridal: hey, it's a valid concern :P","date":"2017-02-01T02:36:30.502Z","type":"message"}
{"nick":"asteele","message":"indeed","date":"2017-02-01T02:36:31.611Z","type":"message"}
{"nick":"chridal","message":"It is.","date":"2017-02-01T02:36:41.965Z","type":"message"}
{"nick":"kaicataldo","date":"2017-02-01T02:37:29.343Z","type":"join"}
{"nick":"chridal","message":"I should get to bed, though. Good talk. Cya!","date":"2017-02-01T02:37:59.466Z","type":"message"}
{"nick":"kaicataldo","reason":"Client Quit","date":"2017-02-01T02:38:10.669Z","type":"quit"}
{"nick":"chridal","message":"Thanks for good pointers etc.","date":"2017-02-01T02:38:22.230Z","type":"message"}
{"nick":"polydo_s","date":"2017-02-01T02:38:25.348Z","type":"join"}
{"nick":"asteele","message":"good night o/","date":"2017-02-01T02:38:28.167Z","type":"message"}
{"nick":"joepie91","message":"chridal: night :)","date":"2017-02-01T02:38:33.515Z","type":"message"}
{"nick":"chridal","message":"\\o","date":"2017-02-01T02:38:36.882Z","type":"message"}
{"nick":"jereee","date":"2017-02-01T02:38:37.301Z","type":"join"}
{"nick":"kiran_","reason":"Remote host closed the connection","date":"2017-02-01T02:40:44.179Z","type":"quit"}
{"nick":"ispn","reason":"Quit: fgsfds","date":"2017-02-01T02:40:46.136Z","type":"quit"}
{"nick":"zsoc","message":"hmm... where is the tcp connection limitation for `http`? I imagine it's somewhere in the c/ares~ level but lord if i know how to figure it out","date":"2017-02-01T02:40:52.387Z","type":"message"}
{"nick":"zsoc","message":"but heck, concurrency: 6 works so i'll leave it at 6... only scraping 1500 pages, won't be too long :p","date":"2017-02-01T02:41:17.997Z","type":"message"}
{"nick":"joepie91","message":"zsoc: there... shouldn't be one?","date":"2017-02-01T02:41:20.627Z","type":"message"}
{"nick":"joepie91","message":"not since 0.12 anyway","date":"2017-02-01T02:41:26.658Z","type":"message"}
{"nick":"zsoc","message":"well eventually you run out of sockets somewhere","date":"2017-02-01T02:41:30.342Z","type":"message"}
{"nick":"joepie91","message":"well yes but not on Node's level","date":"2017-02-01T02:41:39.192Z","type":"message"}
{"nick":"zsoc","message":"right","date":"2017-02-01T02:41:41.784Z","type":"message"}
{"nick":"joepie91","message":"that'd be affected by ulimit and such","date":"2017-02-01T02:41:45.952Z","type":"message"}
{"nick":"zsoc","message":"well, maybe somewhere deep in c/ares, but more likely at the OS i guess","date":"2017-02-01T02:41:57.437Z","type":"message"}
{"nick":"joepie91","message":"yes","date":"2017-02-01T02:42:04.096Z","type":"message"}
{"nick":"joepie91","message":"the kernel will just tell you \"no piss off you've exceeded your max sockets\"","date":"2017-02-01T02:42:14.534Z","type":"message"}
{"nick":"joepie91","message":":P","date":"2017-02-01T02:42:15.649Z","type":"message"}
{"nick":"joepie91","message":"or well","date":"2017-02-01T02:42:36.730Z","type":"message"}
{"nick":"joepie91","message":"file descriptors I guess? not sure how this is counted","date":"2017-02-01T02:42:46.521Z","type":"message"}
{"nick":"zsoc","message":"well i got 'connection resets' back in the stack","date":"2017-02-01T02:42:58.257Z","type":"message"}
{"nick":"joepie91","message":"not likely to be caused by that","date":"2017-02-01T02:43:14.111Z","type":"message"}
{"nick":"moonythedwarf","reason":"Ping timeout: 240 seconds","date":"2017-02-01T02:43:27.546Z","type":"quit"}
{"nick":"zsoc","message":"ack i blew my stack","date":"2017-02-01T02:43:33.319Z","type":"message"}
{"nick":"zsoc","message":"how the heck...","date":"2017-02-01T02:43:49.389Z","type":"message"}
{"nick":"joepie91","message":"zsoc: https://julielnsauer.files.wordpress.com/2013/09/jenga-falling-for-web.jpg","date":"2017-02-01T02:44:06.566Z","type":"message"}
{"nick":"zsoc","message":"lol","date":"2017-02-01T02:44:17.013Z","type":"message"}
{"nick":"zsoc","message":"oooo knex timeouts","date":"2017-02-01T02:44:19.729Z","type":"message"}
{"nick":"zsoc","message":"this... isn't a stream.. i don't actually know how to manage this lol.. in theory won't Promise#map concurrency wait for bookshelf's .save() to return?","date":"2017-02-01T02:45:05.987Z","type":"message"}
{"nick":"Scarecr0w","reason":"Remote host closed the connection","date":"2017-02-01T02:45:31.623Z","type":"quit"}
{"nick":"polydo_s","reason":"Remote host closed the connection","date":"2017-02-01T02:45:34.968Z","type":"quit"}
{"nick":"zsoc","message":"well, it's just a knex insert in the end.. hmmm","date":"2017-02-01T02:46:04.435Z","type":"message"}
{"nick":"zsoc","message":"i wonder if i should have each of the concurrent stuffs on like.. 1 transaction per","date":"2017-02-01T02:46:44.501Z","type":"message"}
{"nick":"zsoc","message":"prolly 1500 inserts per transaction","date":"2017-02-01T02:46:56.924Z","type":"message"}
{"nick":"Siegfried","date":"2017-02-01T02:47:52.635Z","type":"join"}
{"nick":"Limes","date":"2017-02-01T02:49:43.319Z","type":"join"}
{"nick":"miklb","date":"2017-02-01T02:51:21.916Z","type":"join"}
{"nick":"superlou","reason":"Quit: Leaving","date":"2017-02-01T02:51:42.400Z","type":"quit"}
{"nick":"trcm","date":"2017-02-01T02:51:48.307Z","type":"join"}
{"nick":"schm0","reason":"Remote host closed the connection","date":"2017-02-01T02:53:59.215Z","type":"quit"}
{"nick":"duderonomy","date":"2017-02-01T02:55:39.005Z","type":"join"}
{"nick":"diamonds","date":"2017-02-01T02:55:56.692Z","type":"join"}
{"nick":"_2E0PGS","reason":"Quit: Leaving","date":"2017-02-01T02:57:38.971Z","type":"quit"}
{"nick":"smccarthy","date":"2017-02-01T02:59:16.191Z","type":"join"}
{"nick":"boneskull","reason":"Ping timeout: 264 seconds","date":"2017-02-01T02:59:47.277Z","type":"quit"}
{"nick":"boneskull","date":"2017-02-01T03:00:27.240Z","type":"join"}
{"nick":"phutchins","reason":"Ping timeout: 255 seconds","date":"2017-02-01T03:02:02.979Z","type":"quit"}
{"nick":"fattuna","date":"2017-02-01T03:03:00.683Z","type":"join"}
{"nick":"mihok","date":"2017-02-01T03:03:18.612Z","type":"join"}
{"nick":"kaicataldo","date":"2017-02-01T03:03:54.310Z","type":"join"}
{"nick":"kaicataldo","reason":"Client Quit","date":"2017-02-01T03:03:56.093Z","type":"quit"}
{"nick":"jereee","reason":"Quit: http://www.kiwiirc.com/ - A hand crafted IRC client","date":"2017-02-01T03:04:16.273Z","type":"quit"}
{"nick":"aet_zombie","date":"2017-02-01T03:04:54.680Z","type":"join"}
{"nick":"nicojuicy","reason":"Ping timeout: 258 seconds","date":"2017-02-01T03:04:57.969Z","type":"quit"}
{"nick":"fattuna","reason":"Remote host closed the connection","date":"2017-02-01T03:05:30.371Z","type":"quit"}
{"nick":"zsoc","message":"ok higher concurrency and bigger pool is significantly slower >.>","date":"2017-02-01T03:06:20.566Z","type":"message"}
{"nick":"aet_rogue","reason":"Ping timeout: 276 seconds","date":"2017-02-01T03:06:57.576Z","type":"quit"}
{"nick":"aet_zombie","new_nick":"aet_rogue","date":"2017-02-01T03:07:24.869Z","type":"nick"}
{"nick":"smccarthy","reason":"Remote host closed the connection","date":"2017-02-01T03:10:23.204Z","type":"quit"}
{"nick":"smccarthy","date":"2017-02-01T03:10:57.625Z","type":"join"}
{"nick":"oojacoboo","reason":"Quit: Computer has gone to sleep.","date":"2017-02-01T03:11:24.359Z","type":"quit"}
{"nick":"fattuna","date":"2017-02-01T03:13:54.889Z","type":"join"}
{"nick":"fattuna","reason":"Read error: Connection reset by peer","date":"2017-02-01T03:14:46.800Z","type":"quit"}
{"nick":"zumba_addict","reason":"Ping timeout: 240 seconds","date":"2017-02-01T03:14:49.685Z","type":"quit"}
{"nick":"fattuna","date":"2017-02-01T03:14:58.980Z","type":"join"}
{"nick":"zsoc","message":"what happens if i have a map without concurrency limits chained from a map /with/ concurrency limits? i guess it depends on if it's job is easier or harder","date":"2017-02-01T03:15:00.678Z","type":"message"}
{"nick":"Cohedrin_","reason":"Read error: Connection reset by peer","date":"2017-02-01T03:15:20.459Z","type":"quit"}
{"nick":"Cohedrin_","date":"2017-02-01T03:15:40.217Z","type":"join"}
{"nick":"cocomo","date":"2017-02-01T03:16:36.393Z","type":"join"}
{"nick":"jaawerth","message":"zsoc: well, the second step wouldn't start until the first finished, so it would possibly be faster than capping both depending on how well the second step handles concurrency","date":"2017-02-01T03:17:22.038Z","type":"message"}
{"nick":"jaawerth","message":"zsoc: sounds like you might be better off with streams, though, so you can use backpressure","date":"2017-02-01T03:17:49.593Z","type":"message"}
{"nick":"plutoniix","reason":"Quit: Leaving","date":"2017-02-01T03:17:56.819Z","type":"quit"}
{"nick":"cocomo","message":"hello how do i change the path where global packages are saved and also where executes are saved? I want to change the package directory from /usr/lib/node_modules to ~/.node_modules and executable's directry from /usr/bin to ~/.bin","date":"2017-02-01T03:18:16.148Z","type":"message"}
{"nick":"cocomo","message":"can i do that?","date":"2017-02-01T03:18:20.138Z","type":"message"}
{"nick":"zsoc","message":"mmm back pressure","date":"2017-02-01T03:18:37.750Z","type":"message"}
{"nick":"Limes","reason":"Ping timeout: 245 seconds","date":"2017-02-01T03:18:38.286Z","type":"quit"}
{"nick":"joepie91","message":"cocomo: you *can* change the directory where global modules are installed, but the first question is \"why?\"","date":"2017-02-01T03:18:57.225Z","type":"message"}
{"nick":"rakesh1988","date":"2017-02-01T03:19:05.054Z","type":"join"}
{"nick":"kiki`","date":"2017-02-01T03:19:36.920Z","type":"join"}
{"nick":"captbiz","reason":"Quit: Leaving","date":"2017-02-01T03:19:39.198Z","type":"quit"}
{"nick":"jaawerth","message":"cocomo: you only even really install modules globally for cli tools, and even then for cli tools that aren't relied on by a specific project (since those should still be local deps, usually devdeps)","date":"2017-02-01T03:19:43.799Z","type":"message"}
{"nick":"zsoc","message":"streams were my first thought but i have 1500 sources.. i'm not sure how that would work... like map a handful at a time and merge the response bodies into 1 readstream?","date":"2017-02-01T03:19:45.758Z","type":"message"}
{"nick":"cocomo","message":"jaawerth: because i get errors if i use sudo npm -g elm.","date":"2017-02-01T03:20:11.286Z","type":"message"}
{"nick":"cocomo","message":"elm-make packages gives me permission errors wheni run it.","date":"2017-02-01T03:20:21.553Z","type":"message"}
{"nick":"jaawerth","message":"why are you using sudo?","date":"2017-02-01T03:20:26.879Z","type":"message"}
{"nick":"jaawerth","message":"oh wait, /usr/lib.. did you install using an OS package manager?","date":"2017-02-01T03:20:43.648Z","type":"message"}
{"nick":"joepie91","message":"cocomo: this sounds like a number of different issues","date":"2017-02-01T03:20:48.151Z","type":"message"}
{"nick":"cocomo","message":"because root is the owner of /usr/lib/node_modules and /usr/bin","date":"2017-02-01T03:20:53.471Z","type":"message"}
{"nick":"joepie91","message":"cocomo: first of all, that command is invalid - you'","date":"2017-02-01T03:20:54.518Z","type":"message"}
{"nick":"joepie91","message":"cocomo: first of all, that command is invalid - you're missing the \"install\" part *","date":"2017-02-01T03:20:59.120Z","type":"message"}
{"nick":"jaawerth","message":"!nvm @cocomo","date":"2017-02-01T03:21:02.926Z","type":"message"}
{"nick":"ecmabot","message":"cocomo: nvm ( http://nvm.sh / #nvm ) lets you change node versions per-user/per-shell. nave ( https://www.npmjs.com/package/nave ) is for per-user/per-SUBshell. n ( https://www.npmjs.com/package/n ) is for a single, global, system-wide node.","date":"2017-02-01T03:21:03.108Z","type":"message"}
{"nick":"JamesKZO1","date":"2017-02-01T03:21:08.721Z","type":"join"}
{"nick":"joepie91","message":"cocomo: second, where the binaries are installed shouldn't affect what elm-make outputs","date":"2017-02-01T03:21:12.206Z","type":"message"}
{"nick":"joepie91","message":"or does","date":"2017-02-01T03:21:15.733Z","type":"message"}
{"nick":"jaawerth","message":"cocomo: if you use nvm you can install a local node and switch between versions at will","date":"2017-02-01T03:21:18.135Z","type":"message"}
{"nick":"cocomo","message":"jaawerth: am using archlinux's pacman.","date":"2017-02-01T03:21:38.126Z","type":"message"}
{"nick":"jaawerth","message":"ah. for node it's typically not recommended to use a distro's package manager- that version tends to be relatively ancient, plus it gives you problems like the one you're experiencing (among others)","date":"2017-02-01T03:22:09.071Z","type":"message"}
{"nick":"cocomo","message":"hmm jaawerth will it install packages in my user directory?","date":"2017-02-01T03:22:10.029Z","type":"message"}
{"nick":"kaicataldo","date":"2017-02-01T03:22:21.269Z","type":"join"}
{"nick":"jaawerth","message":"yep, and in a way such that they won't conflict with one another between node versions","date":"2017-02-01T03:22:36.088Z","type":"message"}
{"nick":"cocomo","message":"jaawerth: so how do i install it?","date":"2017-02-01T03:22:41.432Z","type":"message"}
{"nick":"cocomo","message":"without OS package manager?","date":"2017-02-01T03:22:52.480Z","type":"message"}
{"nick":"cocomo","message":"jaawerth: can i have just one version which is local","date":"2017-02-01T03:23:20.545Z","type":"message"}
{"nick":"jaawerth","message":"http://nvm.sh has instructions. it's basically a magic bash/zsh script/function so you it can shell-install itself","date":"2017-02-01T03:23:44.930Z","type":"message"}
{"nick":"munch_","reason":"Remote host closed the connection","date":"2017-02-01T03:23:47.589Z","type":"quit"}
{"nick":"JamesKZOO","reason":"Ping timeout: 276 seconds","date":"2017-02-01T03:23:51.631Z","type":"quit"}
{"nick":"jaawerth","message":"cocomo: if you want just one global local version, use the \"n\" package mentioned in the both thing I sent you rather than nvm","date":"2017-02-01T03:24:09.448Z","type":"message"}
{"nick":"diazepan","reason":"Quit: diazepan","date":"2017-02-01T03:24:18.409Z","type":"quit"}
{"nick":"jaawerth","message":"same idea, it will install locally, but only one active at a time on the user level","date":"2017-02-01T03:24:25.893Z","type":"message"}
{"nick":"cocomo","message":"jaawerth: thank you very much.","date":"2017-02-01T03:24:34.088Z","type":"message"}
{"nick":"jaawerth","message":"sure","date":"2017-02-01T03:24:36.200Z","type":"message"}
{"nick":"jaawerth","message":"personally I just always use nvm and have a default version - that way if a project relies on a specific version, I can automatically switch to it when working with it","date":"2017-02-01T03:25:02.746Z","type":"message"}
{"nick":"kaicataldo","reason":"Client Quit","date":"2017-02-01T03:25:27.195Z","type":"quit"}
{"nick":"ironfroggy","reason":"Quit: Leaving...","date":"2017-02-01T03:25:43.749Z","type":"quit"}
{"nick":"nya__","date":"2017-02-01T03:25:50.305Z","type":"join"}
{"nick":"jaawerth","message":"cocomo: you could also install directly from the node website's downloads, but IMO a version manager is much nicer","date":"2017-02-01T03:25:56.279Z","type":"message"}
{"nick":"jaawerth","message":"zsoc: yeah that merging could get messy in that case","date":"2017-02-01T03:26:18.864Z","type":"message"}
{"nick":"jaawerth","message":"zsoc: doable, but not necessarily in a clean manner depending on whether you've got to keep them as separate channels, etc","date":"2017-02-01T03:26:38.389Z","type":"message"}
{"nick":"pilne","reason":"Quit: Quitting!","date":"2017-02-01T03:27:40.168Z","type":"quit"}
{"nick":"jaawerth","message":"zsoc: but as for \"map a handful at a time\", you could do that, or you could use one stream with a highWaterMark set to your first concurrency limit, and have it .push the \"chunks\" on - the \"chunks\" being each request, and then the second stream would simply handle the backpressure","date":"2017-02-01T03:27:47.586Z","type":"message"}
{"nick":"nya_","reason":"Read error: Connection reset by peer","date":"2017-02-01T03:27:51.299Z","type":"quit"}
{"nick":"rakesh1988","reason":"Ping timeout: 256 seconds","date":"2017-02-01T03:28:20.009Z","type":"quit"}
{"nick":"jaawerth","message":"zsoc: so you'd have a Readable stream with the highwatermark, and then a second either writable or duplex/transform stream into which you'd pipe it","date":"2017-02-01T03:29:01.170Z","type":"message"}
{"nick":"zsoc","message":"i know 92% of the words you just used... i shall google, excuse me lol","date":"2017-02-01T03:29:37.201Z","type":"message"}
{"nick":"fattuna","reason":"Remote host closed the connection","date":"2017-02-01T03:30:05.872Z","type":"quit"}
{"nick":"kbck","reason":"Read error: Connection reset by peer","date":"2017-02-01T03:30:12.743Z","type":"quit"}
{"nick":"diamonds","reason":"Ping timeout: 240 seconds","date":"2017-02-01T03:30:49.667Z","type":"quit"}
{"nick":"trcm","reason":"Ping timeout: 264 seconds","date":"2017-02-01T03:31:35.716Z","type":"quit"}
{"nick":"bq_","reason":"Ping timeout: 255 seconds","date":"2017-02-01T03:32:38.961Z","type":"quit"}
{"nick":"Siegfried","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T03:32:41.782Z","type":"quit"}
{"nick":"bradfordli123","reason":"Remote host closed the connection","date":"2017-02-01T03:33:57.890Z","type":"quit"}
{"nick":"bradfordli123","date":"2017-02-01T03:34:34.308Z","type":"join"}
{"nick":"a_thakur","date":"2017-02-01T03:34:37.876Z","type":"join"}
{"nick":"sagerdearia","date":"2017-02-01T03:35:09.315Z","type":"join"}
{"nick":"trcm","date":"2017-02-01T03:35:41.875Z","type":"join"}
{"nick":"a_thakur","reason":"Client Quit","date":"2017-02-01T03:35:43.928Z","type":"quit"}
{"nick":"miklb","message":"anyone have cycles to help a beginner? I'm trying to put a node/express app on an ubuntu server with nginx reverse proxy and am running into a wall","date":"2017-02-01T03:35:57.431Z","type":"message"}
{"nick":"zsoc","message":"yeah no matter what the knex pool eventually has a seizure.. hmmm","date":"2017-02-01T03:36:08.220Z","type":"message"}
{"nick":"joepie91","message":"miklb: what color is the wall? :)","date":"2017-02-01T03:37:06.611Z","type":"message"}
{"nick":"joepie91","message":"(or more seriously: what's the issue?)","date":"2017-02-01T03:37:10.745Z","type":"message"}
{"nick":"miklb","message":"its red from me banging my head against it last 4 hours :-)","date":"2017-02-01T03:37:35.556Z","type":"message"}
{"nick":"Gazooo","reason":"Remote host closed the connection","date":"2017-02-01T03:37:44.068Z","type":"quit"}
{"nick":"jaawerth","message":"zsoc: I know for some of my high-volume writing on postgres with knex I've had to find a balance between batching and backpressure","date":"2017-02-01T03:37:47.586Z","type":"message"}
{"nick":"miklb","message":"https://gist.github.com/miklb/f1877f84b393c4f8c351c022779773a4 this is the simple app. It works fine locally","date":"2017-02-01T03:37:50.505Z","type":"message"}
{"nick":"joepie91","message":"heh","date":"2017-02-01T03:37:58.343Z","type":"message"}
{"nick":"Gazooo","date":"2017-02-01T03:38:10.507Z","type":"join"}
{"nick":"jaawerth","message":"zsoc: since doing write, then write, then write for everything will still cause a memory buildup/freakout, iff not on the node side then on the postgres side","date":"2017-02-01T03:38:15.010Z","type":"message"}
{"nick":"zsoc","message":"jaawerth: yeah i do something similar to this but with 1 source and it's extremely stable.. it's the weird concurrency thing i got going on","date":"2017-02-01T03:38:21.349Z","type":"message"}
{"nick":"bradfordli123","reason":"Ping timeout: 245 seconds","date":"2017-02-01T03:38:38.297Z","type":"quit"}
{"nick":"jaawerth","message":"are you running out of memory or..?","date":"2017-02-01T03:38:45.568Z","type":"message"}
{"nick":"zsoc","message":"i... don't actually know how batching works in knex, i have to look into it","date":"2017-02-01T03:38:52.795Z","type":"message"}
{"nick":"miklb","message":"joepie91 the gist is you pass a font to /static and it subsets the font and serves the fonts/css, ala Google Fonts","date":"2017-02-01T03:38:56.022Z","type":"message"}
{"nick":"Gazooo","reason":"Remote host closed the connection","date":"2017-02-01T03:38:57.811Z","type":"quit"}
{"nick":"zsoc","message":"jaawerth: pool timeouts","date":"2017-02-01T03:39:03.133Z","type":"message"}
{"nick":"jaawerth","message":"hm","date":"2017-02-01T03:39:37.023Z","type":"message"}
{"nick":"miklb","message":"joepie91 if I visit the root URL of the server, I see the \"this font. is for you\"","date":"2017-02-01T03:39:40.472Z","type":"message"}
{"nick":"Gazooo","date":"2017-02-01T03:39:46.770Z","type":"join"}
{"nick":"jaawerth","message":"zsoc: have you made sure your database has a concurrency setting that's friendly to your pool concurrency?","date":"2017-02-01T03:40:44.208Z","type":"message"}
{"nick":"zsoc","message":"uh.. n... no","date":"2017-02-01T03:40:53.392Z","type":"message"}
{"nick":"jaawerth","message":"like for pg you can set the number of workers, etc","date":"2017-02-01T03:40:59.562Z","type":"message"}
{"nick":"zsoc","message":"o","date":"2017-02-01T03:41:04.009Z","type":"message"}
{"nick":"zsoc","message":"if i batch tho.. can i make sure it doesn't roll back on a single constraint rejection? i guess there's prolly a way","date":"2017-02-01T03:42:03.197Z","type":"message"}
{"nick":"zsoc","message":"that's likely the simplest answer","date":"2017-02-01T03:42:06.397Z","type":"message"}
{"nick":"joepie91","message":"miklb: okay... so what isn't working?","date":"2017-02-01T03:43:15.966Z","type":"message"}
{"nick":"karmahacker","date":"2017-02-01T03:43:22.105Z","type":"join"}
{"nick":"miklb","message":"joepie91 I'm getting a 404 on the .css file that it's supposed to serve, and the app isn't firing and creating the subset, as if it's not firing for a lack of a better term","date":"2017-02-01T03:44:36.321Z","type":"message"}
{"nick":"mihok","reason":"Ping timeout: 276 seconds","date":"2017-02-01T03:44:39.674Z","type":"quit"}
{"nick":"a_thakur","date":"2017-02-01T03:45:03.827Z","type":"join"}
{"nick":"joepie91","message":"miklb: does / work?","date":"2017-02-01T03:45:15.018Z","type":"message"}
{"nick":"joepie91","message":"and are you getting an actual 404 on the .css? or some other kind of error?","date":"2017-02-01T03:45:40.852Z","type":"message"}
{"nick":"miklb","message":"joepie91 yes, I see the message \"this font is for you\"","date":"2017-02-01T03:45:41.639Z","type":"message"}
{"nick":"bq_","date":"2017-02-01T03:46:00.881Z","type":"join"}
{"nick":"d4rklit3","reason":"Ping timeout: 240 seconds","date":"2017-02-01T03:46:11.524Z","type":"quit"}
{"nick":"miklb","message":"joepie91 browser is showing a 404","date":"2017-02-01T03:46:12.223Z","type":"message"}
{"nick":"joepie91","message":"miklb: right. can you gist your nginx config?","date":"2017-02-01T03:46:20.132Z","type":"message"}
{"nick":"miklb","message":"joepie91 reload that gist, I just added it","date":"2017-02-01T03:46:38.683Z","type":"message"}
{"nick":"a_thakur","reason":"Read error: Connection reset by peer","date":"2017-02-01T03:46:38.956Z","type":"quit"}
{"nick":"a_thakur","date":"2017-02-01T03:46:49.721Z","type":"join"}
{"nick":"joepie91","message":"miklb: I'm not seeing it :P","date":"2017-02-01T03:47:05.386Z","type":"message"}
{"nick":"jaawerth","message":"zsoc: yeah not sure about that one","date":"2017-02-01T03:47:09.763Z","type":"message"}
{"nick":"zsoc","message":"sa'll good, thank you for the help","date":"2017-02-01T03:47:43.869Z","type":"message"}
{"nick":"jaawerth","message":"np","date":"2017-02-01T03:47:54.163Z","type":"message"}
{"nick":"karmahacker","reason":"Ping timeout: 256 seconds","date":"2017-02-01T03:48:10.495Z","type":"quit"}
{"nick":"joepie91","message":"miklb: you might've added it to the wrong gist? it's not showing up","date":"2017-02-01T03:48:10.495Z","type":"message"}
{"nick":"joepie91","message":"(either that or github is really delayed)","date":"2017-02-01T03:48:15.457Z","type":"message"}
{"nick":"miklb","message":"trying again","date":"2017-02-01T03:48:18.072Z","type":"message"}
{"nick":"miklb","message":"joepie91 I think it stuck this time","date":"2017-02-01T03:48:45.381Z","type":"message"}
{"nick":"joepie91","message":"yeah, I see it now","date":"2017-02-01T03:48:56.728Z","type":"message"}
{"nick":"joepie91","message":"miklb: hmm. why the http://nodejs? rather than just specifying localhost:8080 directly","date":"2017-02-01T03:49:50.846Z","type":"message"}
{"nick":"miklb","message":"joepie91 I've been looking and reading so many examples, one suggested setting an upstream and using that","date":"2017-02-01T03:50:26.251Z","type":"message"}
{"nick":"KnownSyntax","date":"2017-02-01T03:50:33.691Z","type":"join"}
{"nick":"joepie91","message":"hm. bit strange, but I doubt it's the culprit","date":"2017-02-01T03:50:45.074Z","type":"message"}
{"nick":"joepie91","message":"miklb: fwiw, if you want easier setup and you're not particularly tied to nginx, I recommend trying Caddy instead","date":"2017-02-01T03:50:59.208Z","type":"message"}
{"nick":"joepie91","message":"miklb: ref https://caddyserver.com/","date":"2017-02-01T03:51:18.615Z","type":"message"}
{"nick":"joepie91","message":"(it's pretty much 4 lines of config there)","date":"2017-02-01T03:51:30.719Z","type":"message"}
{"nick":"Industrial","date":"2017-02-01T03:51:38.366Z","type":"join"}
{"nick":"joepie91","message":"miklb: I don't see anything obviously wrong. have you verified that accessing the CSS path at localhost:8080 *on the server* works correctly?","date":"2017-02-01T03:52:17.572Z","type":"message"}
{"nick":"Industrial","message":"Hi. I've found https://stdlib.com/. It requires a sign-up. Can I just use the NPM library and deploy to production myself with this or is it a paid thing?","date":"2017-02-01T03:52:22.205Z","type":"message"}
{"nick":"miklb","message":"joepie91 I've seen reference to caddy before, but have never tried it. I've been using nginx with php and static files for awhile now","date":"2017-02-01T03:52:31.467Z","type":"message"}
{"nick":"mx8manger","date":"2017-02-01T03:52:58.869Z","type":"join"}
{"nick":"miklb","message":"joepie91 honestly, I haven't recently","date":"2017-02-01T03:53:02.461Z","type":"message"}
{"nick":"Industrial","message":"yeah ok it's all managed, never mind.","date":"2017-02-01T03:53:16.726Z","type":"message"}
{"nick":"joepie91","message":"miklb: an unpublished guide of mine: https://gist.github.com/joepie91/2b02afe2dfa65ef1d2b9975ca2d0ece3","date":"2017-02-01T03:53:21.434Z","type":"message"}
{"nick":"smccarth_","date":"2017-02-01T03:53:32.612Z","type":"join"}
{"nick":"joepie91","message":"Industrial: stdlib is a bunch of nonsense","date":"2017-02-01T03:53:46.855Z","type":"message"}
{"nick":"joepie91","message":"it tries to be like aws lambda but with 100% more hype","date":"2017-02-01T03:53:58.242Z","type":"message"}
{"nick":"kaicataldo","date":"2017-02-01T03:53:59.188Z","type":"join"}
{"nick":"joepie91","action":"has had several discussions with the creator","date":"2017-02-01T03:54:14.369Z","type":"action"}
{"nick":"miklb","message":"joepie91 I don't think it's actually creating the file because the subsetted font isn't being created, so I think it's more with the app/express","date":"2017-02-01T03:54:39.989Z","type":"message"}
{"nick":"EyePulp","date":"2017-02-01T03:54:52.156Z","type":"join"}
{"nick":"siba","reason":"Quit: My Mac has gone to sleep. ZZZzzz…","date":"2017-02-01T03:55:04.977Z","type":"quit"}
{"nick":"joepie91","message":"miklb: can you try to reproduce on localhost:8080 on the server?","date":"2017-02-01T03:55:08.190Z","type":"message"}
{"nick":"Gazooo","reason":"Remote host closed the connection","date":"2017-02-01T03:55:21.393Z","type":"quit"}
{"nick":"saslam","date":"2017-02-01T03:55:43.226Z","type":"join"}
{"nick":"the_ant","date":"2017-02-01T03:55:54.789Z","type":"join"}
{"nick":"Gazooo","date":"2017-02-01T03:56:06.803Z","type":"join"}
{"nick":"miklb","message":"joepie91 if I curl localhost:8080 I get the message for /","date":"2017-02-01T03:56:07.431Z","type":"message"}
{"nick":"lithie","reason":"Quit: Connection closed for inactivity","date":"2017-02-01T03:56:10.306Z","type":"quit"}
{"nick":"joepie91","message":"miklb: the CSS path I mean","date":"2017-02-01T03:56:33.763Z","type":"message"}
{"nick":"smccarthy","reason":"Ping timeout: 240 seconds","date":"2017-02-01T03:57:07.638Z","type":"quit"}
{"nick":"joepie91","message":"except requesting it from localhost","date":"2017-02-01T03:57:08.699Z","type":"message"}
{"nick":"joepie91","message":"er","date":"2017-02-01T03:57:12.817Z","type":"message"}
{"nick":"joepie91","message":"from localhost:8080","date":"2017-02-01T03:57:15.248Z","type":"message"}
{"nick":"joepie91","message":"instead of through nginx","date":"2017-02-01T03:57:18.503Z","type":"message"}
{"nick":"joepie91","message":"miklb: (the point being to determine whether it's breaking on the reverse proxying or whether it just doesn't work at all)","date":"2017-02-01T03:59:32.543Z","type":"message"}
{"nick":"gooddoggytreat","reason":"Ping timeout: 240 seconds","date":"2017-02-01T04:00:06.482Z","type":"quit"}
{"nick":"kaicataldo","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T04:00:11.542Z","type":"quit"}
{"nick":"the_ant","reason":"Remote host closed the connection","date":"2017-02-01T04:00:36.667Z","type":"quit"}
{"nick":"miklb","message":"joepie91 right. I'm using a shorter string to pass and now I'm seeing a cannot GET curl http://localhost:8080/static/SourceSansPro-Regular.css?text=foobarbaz","date":"2017-02-01T04:02:25.020Z","type":"message"}
{"nick":"the_ant","date":"2017-02-01T04:02:27.777Z","type":"join"}
{"nick":"sterns","reason":"Remote host closed the connection","date":"2017-02-01T04:02:58.965Z","type":"quit"}
{"nick":"joepie91","message":"miklb: does that yield a 404 as well?","date":"2017-02-01T04:03:05.793Z","type":"message"}
{"nick":"miklb","message":"when I curl? no","date":"2017-02-01T04:03:19.506Z","type":"message"}
{"nick":"dk0r","reason":"Read error: Connection reset by peer","date":"2017-02-01T04:04:03.574Z","type":"quit"}
{"nick":"evahop","date":"2017-02-01T04:04:04.345Z","type":"join"}
{"nick":"joepie91","message":"miklb: aha, I've spotted a possible issue.","date":"2017-02-01T04:05:05.196Z","type":"message"}
{"nick":"evahop","date":"2017-02-01T04:05:12.390Z","type":"part"}
{"nick":"joepie91","message":"miklb: how are you starting your Node process?","date":"2017-02-01T04:05:12.982Z","type":"message"}
{"nick":"joepie91","message":"(on the server)","date":"2017-02-01T04:05:15.585Z","type":"message"}
{"nick":"miklb","message":"I used pm2","date":"2017-02-01T04:05:22.054Z","type":"message"}
{"nick":"joyee","date":"2017-02-01T04:05:30.858Z","type":"join"}
{"nick":"zhodge","reason":"Ping timeout: 252 seconds","date":"2017-02-01T04:05:39.656Z","type":"quit"}
{"nick":"joepie91","message":"okay, so the problem is most likely this line: https://gist.github.com/miklb/f1877f84b393c4f8c351c022779773a4#file-index-js-L8","date":"2017-02-01T04:05:44.232Z","type":"message"}
{"nick":"joepie91","message":"\"public/fonts\" refers to the public/fonts path *relative to the working directory*","date":"2017-02-01T04:05:56.006Z","type":"message"}
{"nick":"joepie91","message":"which,  when using pm2 or another process manager, is probably different from the actual project root","date":"2017-02-01T04:06:05.575Z","type":"message"}
{"nick":"jon_x114","reason":"Ping timeout: 260 seconds","date":"2017-02-01T04:06:09.169Z","type":"quit"}
{"nick":"joepie91","message":"whereas if you run it locally for dev purposes, you usually run it from the project root","date":"2017-02-01T04:06:13.432Z","type":"message"}
{"nick":"joepie91","message":"the solution is to explicitly make it relative to your project","date":"2017-02-01T04:06:30.423Z","type":"message"}
{"nick":"joepie91","message":"path.join(__dirname, \"public/css\") will yield a path that's relative to the file in which you define it","date":"2017-02-01T04:06:45.805Z","type":"message"}
{"nick":"joepie91","message":"(__dirname contains the file path of the .js file it's being used in, and path.join combines it with \"public/css\")","date":"2017-02-01T04:07:03.237Z","type":"message"}
{"nick":"joepie91","message":"so it would look like app.use('/static', serveFontmin(path.join(__dirname, 'public/fonts')));","date":"2017-02-01T04:07:17.546Z","type":"message"}
{"nick":"joepie91","message":"and *that* should work since it ignores the working directory","date":"2017-02-01T04:07:23.268Z","type":"message"}
{"nick":"joepie91","message":"@ miklb","date":"2017-02-01T04:07:24.831Z","type":"message"}
{"nick":"miklb","message":"joepie91 might be getting somewhere ReferenceError: path is not defined","date":"2017-02-01T04:09:21.467Z","type":"message"}
{"nick":"joepie91","message":"miklb: oh yeah, sorry, you need to require `path` as well","date":"2017-02-01T04:09:37.584Z","type":"message"}
{"nick":"joepie91","message":"it's a core module","date":"2017-02-01T04:09:39.433Z","type":"message"}
{"nick":"kaicataldo","date":"2017-02-01T04:09:44.171Z","type":"join"}
{"nick":"SuperHans","date":"2017-02-01T04:09:52.976Z","type":"join"}
{"nick":"joyee","reason":"Ping timeout: 252 seconds","date":"2017-02-01T04:10:03.700Z","type":"quit"}
{"nick":"sillyslux","reason":"Read error: Connection reset by peer","date":"2017-02-01T04:10:25.911Z","type":"quit"}
{"nick":"miklb","message":"joepie91++","date":"2017-02-01T04:10:38.983Z","type":"message"}
{"nick":"horsey","date":"2017-02-01T04:11:06.209Z","type":"join"}
{"nick":"joepie91","message":"miklb: did it fix the issue?","date":"2017-02-01T04:11:28.275Z","type":"message"}
{"nick":"miklb","message":"joepie91 yes indeed.","date":"2017-02-01T04:11:39.460Z","type":"message"}
{"nick":"joepie91","message":"excellent :)","date":"2017-02-01T04:11:54.637Z","type":"message"}
{"nick":"joepie91","message":"took me a while to spot it, I need more caffeine :(","date":"2017-02-01T04:12:03.120Z","type":"message"}
{"nick":"joepie91","message":"miklb: also, I still really recommend Caddy btw :P","date":"2017-02-01T04:12:09.516Z","type":"message"}
{"nick":"miklb","message":"joepie91 I will definitely take a closer look.","date":"2017-02-01T04:12:25.813Z","type":"message"}
{"nick":"joepie91","message":"miklb: the guide I linked should give you an idea of what config looks like, especially https://gist.github.com/joepie91/2b02afe2dfa65ef1d2b9975ca2d0ece3#setting-up-reverse-proxying","date":"2017-02-01T04:12:55.865Z","type":"message"}
{"nick":"miklb","message":"lol","date":"2017-02-01T04:13:12.739Z","type":"message"}
{"nick":"joepie91","message":"(those examples are self-contained - they're the *entire* config file)","date":"2017-02-01T04:13:24.009Z","type":"message"}
{"nick":"saslam","reason":"Ping timeout: 255 seconds","date":"2017-02-01T04:13:31.281Z","type":"quit"}
{"nick":"miklb","message":"joepie91 I'm sold. I will throw up a droplet and test tomorrow.","date":"2017-02-01T04:13:48.682Z","type":"message"}
{"nick":"joepie91","message":"hehe","date":"2017-02-01T04:13:55.018Z","type":"message"}
{"nick":"joepie91","message":"have fun :P","date":"2017-02-01T04:13:59.178Z","type":"message"}
{"nick":"joepie91","message":"miklb: oh and that includes TLS btw","date":"2017-02-01T04:14:08.743Z","type":"message"}
{"nick":"jon_x114","date":"2017-02-01T04:14:10.189Z","type":"join"}
{"nick":"joepie91","message":"it sets up TLS automatically","date":"2017-02-01T04:14:12.817Z","type":"message"}
{"nick":"Siegfried","date":"2017-02-01T04:14:14.969Z","type":"join"}
{"nick":"joepie91","message":"(via Let's Encrypt)","date":"2017-02-01T04:14:15.795Z","type":"message"}
{"nick":"joepie91","message":"unless you explicitly tell it not to","date":"2017-02-01T04:14:20.661Z","type":"message"}
{"nick":"SuperHans","reason":"Ping timeout: 255 seconds","date":"2017-02-01T04:14:29.883Z","type":"quit"}
{"nick":"polydo_s","date":"2017-02-01T04:14:37.962Z","type":"join"}
{"nick":"polydo_s","reason":"Remote host closed the connection","date":"2017-02-01T04:14:39.577Z","type":"quit"}
{"nick":"zumba_ad_","date":"2017-02-01T04:15:37.801Z","type":"join"}
{"nick":"nitpe","reason":"Ping timeout: 245 seconds","date":"2017-02-01T04:15:43.348Z","type":"quit"}
{"nick":"zumba_ad_","message":"hey folks, need your help. I'm getting an error line line 9 or 10 - http://pastebin.com/zbLv5Wn1","date":"2017-02-01T04:16:01.645Z","type":"message"}
{"nick":"zumba_ad_","message":"the error is in line 11","date":"2017-02-01T04:16:22.933Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: there's a circular reference in the thing you're trying to res.send","date":"2017-02-01T04:16:47.727Z","type":"message"}
{"nick":"zumba_ad_","message":"how do I fix it?","date":"2017-02-01T04:17:04.476Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: by making it not have a circular reference :P","date":"2017-02-01T04:17:12.121Z","type":"message"}
{"nick":"zumba_ad_","message":":D","date":"2017-02-01T04:17:19.236Z","type":"message"}
{"nick":"joepie91","message":"JSON can't represent circular references","date":"2017-02-01T04:17:23.517Z","type":"message"}
{"nick":"joepie91","message":"(please don't try to use libraries that \"fix\" this :P)","date":"2017-02-01T04:17:31.612Z","type":"message"}
{"nick":"zumba_ad_","message":"so I'll have to use .map to reference data property then res.send it?","date":"2017-02-01T04:18:38.331Z","type":"message"}
{"nick":"Atemu","date":"2017-02-01T04:18:55.518Z","type":"join"}
{"nick":"tiwest","reason":"Ping timeout: 245 seconds","date":"2017-02-01T04:19:53.313Z","type":"quit"}
{"nick":"joepie91","message":"zumba_ad_: I don't understand what you're asking","date":"2017-02-01T04:20:06.641Z","type":"message"}
{"nick":"Siegfried","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T04:20:31.177Z","type":"quit"}
{"nick":"joepie91","message":"zumba_ad_: do you know what circular references are?","date":"2017-02-01T04:20:36.345Z","type":"message"}
{"nick":"zumba_ad_","message":"i'm sorry. I can see the json that I need. I console.log it. The json output looks like a promise","date":"2017-02-01T04:20:40.437Z","type":"message"}
{"nick":"joepie91","message":"huh?","date":"2017-02-01T04:21:02.605Z","type":"message"}
{"nick":"zumba_ad_","message":"someone like myobj.prop = someprop","date":"2017-02-01T04:21:06.017Z","type":"message"}
{"nick":"zumba_ad_","message":"somewhat","date":"2017-02-01T04:21:10.982Z","type":"message"}
{"nick":"joepie91","message":"no","date":"2017-02-01T04:21:17.506Z","type":"message"}
{"nick":"zumba_ad_","message":"oh","date":"2017-02-01T04:21:39.105Z","type":"message"}
{"nick":"joepie91","message":">> let a = {}; let b = {foo: a}; a.bar = b; a","date":"2017-02-01T04:21:39.106Z","type":"message"}
{"nick":"ecmabot","message":"joepie91: (object) {bar: {foo: (Circular)}}","date":"2017-02-01T04:21:39.106Z","type":"message"}
{"nick":"zumba_ad_","message":"got it","date":"2017-02-01T04:22:00.689Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: anyway, what's this about \"looks like a promise\"?","date":"2017-02-01T04:22:23.948Z","type":"message"}
{"nick":"zumba_ad_","message":"not sure if my axios.all's result is doing it","date":"2017-02-01T04:22:25.726Z","type":"message"}
{"nick":"joepie91","message":"but what do you mean with that?","date":"2017-02-01T04:22:44.236Z","type":"message"}
{"nick":"zumba_ad_","message":"oh, my json is very small but when I console.log it, it has tons of other infomation like the endpoint, Writeable, events, etc","date":"2017-02-01T04:22:59.459Z","type":"message"}
{"nick":"joepie91","message":"that sounds like a stream","date":"2017-02-01T04:23:09.079Z","type":"message"}
{"nick":"zumba_ad_","message":"I'll paste it","date":"2017-02-01T04:23:09.532Z","type":"message"}
{"nick":"joepie91","message":"not a promise","date":"2017-02-01T04:23:10.824Z","type":"message"}
{"nick":"ecuanaso","reason":"Quit: My MacBook has gone to sleep. ZZZzzz…","date":"2017-02-01T04:24:03.146Z","type":"quit"}
{"nick":"harai","reason":"Ping timeout: 252 seconds","date":"2017-02-01T04:24:21.755Z","type":"quit"}
{"nick":"zumba_ad_","message":"here - http://pastebin.com/JPX6wBuM","date":"2017-02-01T04:24:59.024Z","type":"message"}
{"nick":"zumba_ad_","message":"my axios.all made 3 calls since my payload had 3 values","date":"2017-02-01T04:25:20.854Z","type":"message"}
{"nick":"smccarth_","reason":"Remote host closed the connection","date":"2017-02-01T04:25:35.068Z","type":"quit"}
{"nick":"zumba_ad_","message":"you'll 3 status: 200","date":"2017-02-01T04:25:48.376Z","type":"message"}
{"nick":"zumba_ad_","message":"see^","date":"2017-02-01T04:25:56.578Z","type":"message"}
{"nick":"smccarthy","date":"2017-02-01T04:26:02.477Z","type":"join"}
{"nick":"joepie91","message":"zumba_ad_: soooo the problem seems to be that you're trying to res.send an axios response","date":"2017-02-01T04:26:05.134Z","type":"message"}
{"nick":"zumba_ad_","message":"yeah","date":"2017-02-01T04:26:15.642Z","type":"message"}
{"nick":"Industrial","reason":"Quit: Page closed","date":"2017-02-01T04:26:15.824Z","type":"quit"}
{"nick":"joepie91","message":"which... is not really possible","date":"2017-02-01T04:26:25.312Z","type":"message"}
{"nick":"zumba_ad_","message":"that's correct since I was guessing how to send it","date":"2017-02-01T04:26:26.412Z","type":"message"}
{"nick":"joepie91","message":"since it has stateful things like streams","date":"2017-02-01T04:26:27.231Z","type":"message"}
{"nick":"zumba_ad_","message":"oh ok","date":"2017-02-01T04:26:28.650Z","type":"message"}
{"nick":"joepie91","message":"what are you *actually* trying to res.send?","date":"2017-02-01T04:26:35.638Z","type":"message"}
{"nick":"zumba_ad_","message":"the json in that output i posted","date":"2017-02-01T04:26:50.611Z","type":"message"}
{"nick":"tiwest","date":"2017-02-01T04:26:54.611Z","type":"join"}
{"nick":"zumba_ad_","message":"search for dateOfBuild","date":"2017-02-01T04:27:03.257Z","type":"message"}
{"nick":"zumba_ad_","message":"that's one of the fields","date":"2017-02-01T04:27:10.011Z","type":"message"}
{"nick":"zumba_ad_","message":"beside it are the others","date":"2017-02-01T04:27:21.482Z","type":"message"}
{"nick":"zumba_ad_","message":"it's the data: object","date":"2017-02-01T04:27:29.178Z","type":"message"}
{"nick":"zumba_ad_","message":"I guess I should use .map then reference  .data","date":"2017-02-01T04:27:58.809Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: so, what you want to send is the *response body*, which is indeed stored as .data","date":"2017-02-01T04:28:08.366Z","type":"message"}
{"nick":"joepie91","message":"right","date":"2017-02-01T04:28:10.662Z","type":"message"}
{"nick":"zumba_ad_","message":"oh ok, I was thinking it right then","date":"2017-02-01T04:28:34.105Z","type":"message"}
{"nick":"schm0","date":"2017-02-01T04:29:19.468Z","type":"join"}
{"nick":"zumba_ad_","message":"but what can I improve on my api /buidnumbers endpoint?","date":"2017-02-01T04:29:19.469Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: that's a very open question :P","date":"2017-02-01T04:29:19.469Z","type":"message"}
{"nick":"zumba_ad_","message":"ok :)","date":"2017-02-01T04:29:19.469Z","type":"message"}
{"nick":"joepie91","message":"like, \"improve\" in what sense?","date":"2017-02-01T04:29:44.235Z","type":"message"}
{"nick":"Atemu","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2017-02-01T04:29:44.235Z","type":"quit"}
{"nick":"zumba_ad_","message":"i feel like it looks very elementary","date":"2017-02-01T04:29:49.991Z","type":"message"}
{"nick":"zumba_ad_","message":"it works though","date":"2017-02-01T04:29:55.969Z","type":"message"}
{"nick":"zumba_ad_","message":"let me write the .map first","date":"2017-02-01T04:30:09.521Z","type":"message"}
{"nick":"joepie91","message":"zumba_ad_: well, simpler is better :P","date":"2017-02-01T04:30:50.031Z","type":"message"}
