{"nick":"mmalecki","reason":"Quit: leaving","date":"2012-05-11T01:35:35.764Z","type":"quit"}
{"nick":"dvv","reason":"Ping timeout: 265 seconds","date":"2012-05-11T01:53:17.616Z","type":"quit"}
{"nick":"dvv","date":"2012-05-11T02:05:48.946Z","type":"join"}
{"nick":"dvv","reason":"Ping timeout: 260 seconds","date":"2012-05-11T02:23:33.947Z","type":"quit"}
{"nick":"zx9597446","date":"2012-05-11T02:28:22.072Z","type":"join"}
{"nick":"hij1nx","date":"2012-05-11T02:46:53.504Z","type":"join"}
{"nick":"zx9597446","date":"2012-05-11T03:12:22.270Z","type":"part"}
{"nick":"dvv","date":"2012-05-11T03:58:14.628Z","type":"join"}
{"nick":"TheJH","date":"2012-05-11T05:04:27.534Z","type":"join"}
{"nick":"TheJH","reason":"Ping timeout: 245 seconds","date":"2012-05-11T05:08:42.998Z","type":"quit"}
{"nick":"hij1nx","reason":"Quit: hij1nx","date":"2012-05-11T07:38:50.529Z","type":"quit"}
{"nick":"AvianFlu","reason":"Quit: Leaving","date":"2012-05-11T08:17:26.112Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T08:32:52.193Z","type":"join"}
{"nick":"mmalecki","reason":"Ping timeout: 240 seconds","date":"2012-05-11T09:02:47.149Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T09:03:28.624Z","type":"join"}
{"nick":"mmalecki","reason":"Quit: Reconnecting","date":"2012-05-11T10:19:20.636Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T10:19:29.428Z","type":"join"}
{"nick":"mmalecki","reason":"Client Quit","date":"2012-05-11T10:23:27.241Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T10:29:28.161Z","type":"join"}
{"nick":"xming","date":"2012-05-11T11:33:36.485Z","type":"join"}
{"nick":"mmalecki","reason":"Quit: Reconnecting","date":"2012-05-11T11:34:24.332Z","type":"quit"}
{"nick":"mmalecki_","date":"2012-05-11T11:34:33.379Z","type":"join"}
{"nick":"mmalecki_","reason":"Client Quit","date":"2012-05-11T11:36:35.241Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T11:36:42.780Z","type":"join"}
{"nick":"mmalecki","reason":"Quit: Reconnecting","date":"2012-05-11T11:42:43.123Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T11:43:14.581Z","type":"join"}
{"nick":"mmalecki","reason":"Client Quit","date":"2012-05-11T11:43:44.877Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T11:46:54.596Z","type":"join"}
{"nick":"xming","message":"I want to emit an event when receiving data from a socket, but I can't get it right","date":"2012-05-11T11:47:53.161Z","type":"message"}
{"nick":"mmalecki_","date":"2012-05-11T11:50:28.051Z","type":"join"}
{"nick":"mmalecki","reason":"Client Quit","date":"2012-05-11T11:50:43.620Z","type":"quit"}
{"nick":"mmalecki_","reason":"Client Quit","date":"2012-05-11T11:51:06.366Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T11:51:16.962Z","type":"join"}
{"nick":"indexzero_","reason":"Quit: indexzero_","date":"2012-05-11T12:04:32.171Z","type":"quit"}
{"nick":"xming","message":"the idea is basically the same as in http.lua, converting tcp to application proto","date":"2012-05-11T12:06:41.667Z","type":"message"}
{"nick":"xming","message":"so I can create new ojb from it","date":"2012-05-11T12:06:53.846Z","type":"message"}
{"nick":"xming","message":"but I can't get it right :/","date":"2012-05-11T12:07:07.769Z","type":"message"}
{"nick":"creationix","message":"xming, what is the hard part?","date":"2012-05-11T14:08:38.549Z","type":"message"}
{"nick":"xming","message":"I thkn I get it now","date":"2012-05-11T14:14:04.075Z","type":"message"}
{"nick":"xming","message":"the hard part is that I don't know how things work (in a high level) as I am not comingfrom nodejs","date":"2012-05-11T14:14:46.037Z","type":"message"}
{"nick":"xming","message":"I missed good high level docs, including the flow of the stream","date":"2012-05-11T14:15:14.923Z","type":"message"}
{"nick":"xming","message":"creationix: does this looks right to you? http://pastebin.com/5ujxkbtv","date":"2012-05-11T14:18:29.996Z","type":"message"}
{"nick":"creationix","message":"xming, so, so far this is a simple tcp server with \"new\" and \"foo\" events?","date":"2012-05-11T14:20:40.121Z","type":"message"}
{"nick":"creationix","message":"xming, though, your \"new\" event doesn't send any data, but you're expecting data down in main.lua","date":"2012-05-11T14:22:02.569Z","type":"message"}
{"nick":"mmalecki","reason":"Quit: Reconnecting","date":"2012-05-11T14:28:39.674Z","type":"quit"}
{"nick":"mmalecki","date":"2012-05-11T14:28:48.055Z","type":"join"}
{"nick":"xming","message":"yes just trying to see how things work (the flow, callbacks, etc)","date":"2012-05-11T14:30:50.008Z","type":"message"}
{"nick":"xming","message":"creationix: those func args are left over, it's not meant to be like that. My question is about the events/listeners, am I doing it the right way?","date":"2012-05-11T14:34:10.376Z","type":"message"}
{"nick":"creationix","message":"xming, yes, that's how emitters work","date":"2012-05-11T14:37:04.549Z","type":"message"}
{"nick":"creationix","message":"and any extra args passed to emit are the args in the listener","date":"2012-05-11T14:37:13.376Z","type":"message"}
{"nick":"xming","message":"ah okay thanks","date":"2012-05-11T14:38:09.885Z","type":"message"}
{"nick":"xming","message":"so conn:emit('foo', arg1) and conn:on('foo', function(arg1_from_emitter) ... end","date":"2012-05-11T14:39:26.991Z","type":"message"}
{"nick":"xming","message":"something like that?","date":"2012-05-11T14:39:31.304Z","type":"message"}
{"nick":"creationix","message":"yep","date":"2012-05-11T14:39:40.735Z","type":"message"}
{"nick":"xming","message":"my actual problem was I missed that callback, so onConnection(conn) fixed it","date":"2012-05-11T14:42:41.483Z","type":"message"}
{"nick":"hij1nx","date":"2012-05-11T15:03:09.831Z","type":"join"}
{"nick":"hij1nx","reason":"Quit: hij1nx","date":"2012-05-11T15:47:54.234Z","type":"quit"}
{"nick":"hij1nx","date":"2012-05-11T16:01:11.600Z","type":"join"}
{"nick":"TheJH","date":"2012-05-11T16:03:58.354Z","type":"join"}
{"nick":"hij1nx","reason":"Read error: Connection reset by peer","date":"2012-05-11T16:19:33.120Z","type":"quit"}
{"nick":"hij1nx","date":"2012-05-11T16:24:10.351Z","type":"join"}
{"nick":"tsing","date":"2012-05-11T16:36:51.424Z","type":"join"}
{"nick":"tsing","date":"2012-05-11T16:41:03.983Z","type":"quit"}
{"nick":"hij1nx","reason":"Quit: hij1nx","date":"2012-05-11T16:41:15.470Z","type":"quit"}
{"nick":"neomantra1","date":"2012-05-11T16:58:07.118Z","type":"join"}
{"nick":"tsing","date":"2012-05-11T16:58:46.010Z","type":"join"}
{"nick":"hij1nx","date":"2012-05-11T17:00:31.080Z","type":"join"}
{"nick":"philips","message":"I think I want to add a way to set the luvit return code to say 1- that way if the loop exits before the user expects it to we get a failing return code. Thoughts?","date":"2012-05-11T17:17:58.184Z","type":"message"}
{"nick":"AvianFlu","date":"2012-05-11T17:19:24.646Z","type":"join"}
{"nick":"dvv","message":"settable process.exitCode, which is 0-ed when exiting cleanly?","date":"2012-05-11T17:26:48.451Z","type":"message"}
{"nick":"philips","message":"dvv: yea, essentially","date":"2012-05-11T17:27:30.373Z","type":"message"}
{"nick":"dvv","message":"+1","date":"2012-05-11T17:27:37.931Z","type":"message"}
{"nick":"dvv","message":"but i believe we do have this already","date":"2012-05-11T17:28:02.054Z","type":"message"}
{"nick":"mmalecki","reason":"Quit: leaving","date":"2012-05-11T17:40:11.166Z","type":"quit"}
{"nick":"creationix","message":"I didn't add such a feature","date":"2012-05-11T17:41:20.964Z","type":"message"}
{"nick":"creationix","message":"I like it","date":"2012-05-11T17:41:22.100Z","type":"message"}
{"nick":"philips","message":"creationix: We just encountered a problem where our unit tests triggered a bug and the event loop exited early but luvit's return code was 0 so buildbot made it green. I iwll work on that","date":"2012-05-11T17:48:12.253Z","type":"message"}
{"nick":"creationix","message":"I wonder if we should add that feature to node as well","date":"2012-05-11T17:48:37.162Z","type":"message"}
{"nick":"creationix","message":"philips, how important is it for you guys that we stick to node APIs","date":"2012-05-11T17:48:47.532Z","type":"message"}
{"nick":"creationix","message":"I know you use both there","date":"2012-05-11T17:48:51.125Z","type":"message"}
{"nick":"philips","message":"creationix: Not terribly important, it makes context switching slightly easier","date":"2012-05-11T17:49:08.740Z","type":"message"}
{"nick":"philips","message":"creationix: What do you have in mind","date":"2012-05-11T17:49:13.840Z","type":"message"}
{"nick":"philips","message":"creationix: I would rather not make sweeping api changes and break virgo though :)","date":"2012-05-11T17:49:26.278Z","type":"message"}
{"nick":"creationix","message":"no, I don't have any sweeping changes in mind","date":"2012-05-11T17:50:07.988Z","type":"message"}
{"nick":"creationix","message":"just wondering how important it is","date":"2012-05-11T17:50:12.889Z","type":"message"}
{"nick":"creationix","message":"this exit code API, for example, doesn't exist in node","date":"2012-05-11T17:50:20.931Z","type":"message"}
{"nick":"philips","message":"creationix: oh I am fine with extensions and new stuff","date":"2012-05-11T17:51:33.386Z","type":"message"}
{"nick":"philips","message":"creationix: What do you think?","date":"2012-05-11T17:52:29.559Z","type":"message"}
{"nick":"creationix","message":"fine by me","date":"2012-05-11T17:52:36.995Z","type":"message"}
{"nick":"tsing_","date":"2012-05-11T17:56:41.233Z","type":"join"}
{"nick":"tsing","reason":"Ping timeout: 245 seconds","date":"2012-05-11T18:00:22.968Z","type":"quit"}
{"nick":"luvit-bb","message":"build #1586 of virgo-rhel6.1_x64 is complete: Failure [failed integration tests]  Build details are at https://virgo-bb.k1k.me/builders/virgo-rhel6.1_x64/builds/1586","date":"2012-05-11T18:02:32.017Z","type":"message"}
{"nick":"luvit-bb","message":"build #1587 of virgo-rhel6.1_x64 is complete: Success [build successful]  Build details are at https://virgo-bb.k1k.me/builders/virgo-rhel6.1_x64/builds/1587","date":"2012-05-11T18:14:03.569Z","type":"message"}
{"nick":"tsing","date":"2012-05-11T18:17:31.928Z","type":"join"}
{"nick":"tsing_","reason":"Read error: Connection reset by peer","date":"2012-05-11T18:18:59.985Z","type":"quit"}
{"nick":"tsing_","date":"2012-05-11T18:19:23.586Z","type":"join"}
{"nick":"tsing","reason":"Ping timeout: 260 seconds","date":"2012-05-11T18:23:08.928Z","type":"quit"}
{"nick":"indexzero","date":"2012-05-11T18:34:29.398Z","type":"join"}
{"nick":"indexzero","reason":"Ping timeout: 250 seconds","date":"2012-05-11T18:39:58.836Z","type":"quit"}
{"nick":"Thomas000","date":"2012-05-11T18:53:44.392Z","type":"join"}
{"nick":"Thomas000","message":"Hello, is there a memorycache as known from PHP APC (read/store variables) in Luvit or an external Library that does this storage without network-based connects?","date":"2012-05-11T18:55:17.353Z","type":"message"}
{"nick":"creationix","message":"Thomas000, you can simply store values in a global table","date":"2012-05-11T19:06:56.546Z","type":"message"}
{"nick":"creationix","message":"luvit processes are persistent","date":"2012-05-11T19:07:03.489Z","type":"message"}
{"nick":"creationix","message":"local db = {}","date":"2012-05-11T19:07:11.106Z","type":"message"}
{"nick":"creationix","message":"or do you need something persistent to disk?","date":"2012-05-11T19:07:43.835Z","type":"message"}
{"nick":"Thomas000","message":"Thank you! Is luvit multi-threading (1 process per core) possible or on todo list? When to expect roundabout? creationix","date":"2012-05-11T19:59:01.493Z","type":"message"}
{"nick":"creationix","message":"the whole control-flow is based on the assumption that all lua runs in the same thread","date":"2012-05-11T19:59:44.421Z","type":"message"}
{"nick":"creationix","message":"dvv does have an experiment where he uses the uv thread-pool to run some lua in another thread","date":"2012-05-11T20:00:06.099Z","type":"message"}
{"nick":"creationix","message":"kinda like web workers","date":"2012-05-11T20:00:08.993Z","type":"message"}
{"nick":"xming","message":"bloody namespace collision","date":"2012-05-11T20:00:41.937Z","type":"message"}
{"nick":"Thomas000","message":"I was looking for a nodejs cluster equivalent.","date":"2012-05-11T20:01:10.264Z","type":"message"}
{"nick":"creationix","message":"Thomas000, fd sharing is possible once someone adds write2 bindings for libuv","date":"2012-05-11T20:01:44.736Z","type":"message"}
{"nick":"creationix","message":"then you can bind to port 80 in a parent process, spawn X child processes passing them all a handle to the port's fd","date":"2012-05-11T20:02:10.621Z","type":"message"}
{"nick":"creationix","message":"and never accept connections in the parent","date":"2012-05-11T20:02:18.060Z","type":"message"}
{"nick":"creationix","message":"the os will load balance across the X children on each request","date":"2012-05-11T20:02:34.418Z","type":"message"}
{"nick":"Thomas000","message":"because speed(Luvit with limit to 1 core) < speed(most other solutions being multithreadable)","date":"2012-05-11T20:02:34.845Z","type":"message"}
{"nick":"Thomas000","message":"ah that sounds very interesting","date":"2012-05-11T20:02:49.004Z","type":"message"}
{"nick":"creationix","message":"is luvit's speed really a bottleneck?","date":"2012-05-11T20:02:50.226Z","type":"message"}
{"nick":"creationix","message":"I mean, I can get over 120,000/second on a single core if I tune luvit enough","date":"2012-05-11T20:03:04.906Z","type":"message"}
{"nick":"Thomas000","message":"Sure most projects just don't get the attention to have that many visitors","date":"2012-05-11T20:03:16.100Z","type":"message"}
{"nick":"creationix","message":"my most active site gets a < 100,000/day","date":"2012-05-11T20:03:21.572Z","type":"message"}
{"nick":"Thomas000","message":"I wanted to use luvit for an Android App similar to WhattsApp","date":"2012-05-11T20:03:46.118Z","type":"message"}
{"nick":"creationix","message":"but yes, fd sharing is possible if someone takes the time to add uv_write2 bindings","date":"2012-05-11T20:03:47.986Z","type":"message"}
{"nick":"Thomas000","message":"Correection: For the server side","date":"2012-05-11T20:04:05.177Z","type":"message"}
{"nick":"creationix","message":"but then all your workers have to be stateless since you never know which one will get a request","date":"2012-05-11T20:04:06.219Z","type":"message"}
{"nick":"Thomas000","message":"And this leads to a need for a central and fast \"persistent\" storage","date":"2012-05-11T20:04:28.649Z","type":"message"}
{"nick":"Thomas000","message":"like known from APC PHP cache","date":"2012-05-11T20:04:38.453Z","type":"message"}
{"nick":"creationix","message":"I know redis and riak are often used with node","date":"2012-05-11T20:04:52.925Z","type":"message"}
{"nick":"creationix","message":"I think there is a redis library for luvit","date":"2012-05-11T20:05:04.898Z","type":"message"}
{"nick":"creationix","message":"but if one process can handle your load, then that's much simpler","date":"2012-05-11T20:05:28.506Z","type":"message"}
{"nick":"creationix","message":"don't overcomplicate things","date":"2012-05-11T20:05:34.234Z","type":"message"}
{"nick":"Thomas000","message":"Yes, but they are only \"hm, ok\" for clusters with more than 1 server. On just one server, redis is the bottleneck because the network stuff is several orders of magnitude slower than direct Shared Memory access","date":"2012-05-11T20:05:50.237Z","type":"message"}
{"nick":"Thomas000","message":"It is like a magic wall.","date":"2012-05-11T20:06:23.849Z","type":"message"}
{"nick":"creationix","message":"that could probably be added as a binary addon","date":"2012-05-11T20:06:30.122Z","type":"message"}
{"nick":"Thomas000","message":"I can only speak for nodejs with this example","date":"2012-05-11T20:06:34.585Z","type":"message"}
{"nick":"creationix","message":"I don't know enough about shared memory coding to tell","date":"2012-05-11T20:06:43.442Z","type":"message"}
{"nick":"creationix","message":"but since luvit is 2-4x faster than node, a single luvit process can do what 4 node processes can do","date":"2012-05-11T20:07:11.601Z","type":"message"}
{"nick":"creationix","message":"(of course this depends heavily on what exactly you're doing)","date":"2012-05-11T20:07:33.133Z","type":"message"}
{"nick":"Thomas000","message":"The problem is this dilemma: One Core: is \"fast\" with some few thousand requests per second. As soon as more than one core is involved, overall performance gets lower due to persistent storage management which is needed. Needing more than 1 server further dramatically decreses speed","date":"2012-05-11T20:07:49.393Z","type":"message"}
{"nick":"Thomas000","message":"as one then needs network-io-based persistent storage.","date":"2012-05-11T20:08:05.309Z","type":"message"}
{"nick":"creationix","message":"true, but that's a generic scaling issue","date":"2012-05-11T20:08:22.266Z","type":"message"}
{"nick":"creationix","message":"the larger you scale, the less effecient each node is","date":"2012-05-11T20:08:31.906Z","type":"message"}
{"nick":"Thomas000","message":"The performance per core goes down ddown down with every new extension and it seems there is a performance-wall.","date":"2012-05-11T20:08:32.736Z","type":"message"}
{"nick":"creationix","message":"for n-n broadcast style systems, yes","date":"2012-05-11T20:09:03.636Z","type":"message"}
{"nick":"creationix","message":"those are hard to scale","date":"2012-05-11T20:09:08.626Z","type":"message"}
{"nick":"Thomas000","message":"I never came over 100,000 requests per second wih an aritificial benchmark. I do this just out of curiosity.","date":"2012-05-11T20:09:10.932Z","type":"message"}
{"nick":"creationix","message":"but usually there is some application level trick to optimize and shard things","date":"2012-05-11T20:09:18.426Z","type":"message"}
{"nick":"Thomas000","message":"And as Luvit is some few times faster than nodejs I wanted to test the same stuff like clustering ,etc. I will just keep Luvit on my agenda and revisit month by month.","date":"2012-05-11T20:10:34.035Z","type":"message"}
{"nick":"creationix","message":"I was able to get >100k by doing manual http pipelining and keepalive","date":"2012-05-11T20:11:05.314Z","type":"message"}
{"nick":"creationix","message":"I imagine with fd sharing it will scale linearly per core","date":"2012-05-11T20:11:21.526Z","type":"message"}
{"nick":"creationix","message":"or I would like to see if it can","date":"2012-05-11T20:11:30.858Z","type":"message"}
{"nick":"creationix","message":"that would be 1m/second on my desktop","date":"2012-05-11T20:11:38.089Z","type":"message"}
{"nick":"creationix","message":"I doubt it scales that far","date":"2012-05-11T20:11:42.431Z","type":"message"}
{"nick":"Thomas000","message":"But maybe a good server could do that then.","date":"2012-05-11T20:12:12.918Z","type":"message"}
{"nick":"creationix","message":"sure, but not with any real workload","date":"2012-05-11T20:12:24.966Z","type":"message"}
{"nick":"creationix","message":"a server that responds with static Hello World isn't very useful","date":"2012-05-11T20:12:38.309Z","type":"message"}
{"nick":"creationix","message":"add any real work and the numbers plummit","date":"2012-05-11T20:12:49.999Z","type":"message"}
{"nick":"creationix","message":"for every platform","date":"2012-05-11T20:12:54.547Z","type":"message"}
{"nick":"Thomas000","message":"Sure, as soon as you need a session lookup (inmemory) or worse: a DB-lookup, all is voer :-(","date":"2012-05-11T20:13:13.803Z","type":"message"}
{"nick":"Thomas000","message":"voer=over","date":"2012-05-11T20:13:23.584Z","type":"message"}
{"nick":"creationix","message":"hmm, that would be a good benchmark","date":"2012-05-11T20:13:30.385Z","type":"message"}
{"nick":"creationix","message":"load session, load template from disk, query database, render html, serve","date":"2012-05-11T20:13:48.810Z","type":"message"}
{"nick":"creationix","message":"no caching at all","date":"2012-05-11T20:13:53.890Z","type":"message"}
{"nick":"Thomas000","message":"I made some tests, for example with nginx+LuaJit on a 6core Xeon and it gave about 210k/sec. keepalive","date":"2012-05-11T20:13:59.031Z","type":"message"}
{"nick":"creationix","message":"nice","date":"2012-05-11T20:14:08.113Z","type":"message"}
{"nick":"Thomas000","message":"With a simple Lua-script that made an easy math-addition and printed \"Hello blablabla\"+i","date":"2012-05-11T20:14:31.168Z","type":"message"}
{"nick":"Thomas000","message":"It was just to see the overall overhead of parsing/Lua-instance reusage, etc","date":"2012-05-11T20:14:52.757Z","type":"message"}
{"nick":"Thomas000","message":"Intention was: Many requests with very low data-payload like a messenger","date":"2012-05-11T20:15:43.159Z","type":"message"}
{"nick":"Thomas000","message":"Good bye","date":"2012-05-11T20:20:05.940Z","type":"message"}
{"nick":"Thomas000","message":"and thank you","date":"2012-05-11T20:20:19.951Z","type":"message"}
{"nick":"Thomas000","reason":"Quit: Page closed","date":"2012-05-11T20:20:27.012Z","type":"quit"}
{"nick":"luvit-bb","reason":"Ping timeout: 244 seconds","date":"2012-05-11T20:21:58.875Z","type":"quit"}
{"nick":"tsing_","reason":"Remote host closed the connection","date":"2012-05-11T20:30:39.557Z","type":"quit"}
{"nick":"pquerna","message":"http://playcontrol.net/opensource/LuaCocoa/","date":"2012-05-11T20:31:43.191Z","type":"message"}
{"nick":"pquerna","message":"so, has anyone tried to integrate with NSRunLoop?","date":"2012-05-11T20:40:10.020Z","type":"message"}
{"nick":"creationix","message":"tootallnate has done some with node I think","date":"2012-05-11T21:14:19.225Z","type":"message"}
{"nick":"creationix","message":"pquerna, what do you think about https://gist.github.com/4b71912f266133c69506","date":"2012-05-11T21:14:39.277Z","type":"message"}
{"nick":"philips","message":"creationix: That looks reasonable. Adding a simple TCP server \"database\" that simply echos out the JSON for the records might be a nice second level since it is very unlikely you have to do zero I/O.","date":"2012-05-11T21:29:28.491Z","type":"message"}
{"nick":"creationix","message":"so require I/O in all the cases then?","date":"2012-05-11T21:29:50.438Z","type":"message"}
{"nick":"philips","message":"Just a short TCP server written in C that everyone uses","date":"2012-05-11T21:29:51.160Z","type":"message"}
{"nick":"creationix","message":"oh, share the database, I see","date":"2012-05-11T21:30:03.598Z","type":"message"}
{"nick":"creationix","message":"not a bad idea","date":"2012-05-11T21:30:11.457Z","type":"message"}
{"nick":"creationix","message":"input is table/key, output is value?","date":"2012-05-11T21:30:29.081Z","type":"message"}
{"nick":"creationix","message":"something like that?","date":"2012-05-11T21:30:31.743Z","type":"message"}
{"nick":"philips","message":"creationix: I was thinking input was \"users\" or \"sessions\" and output would be the JSON for those","date":"2012-05-11T21:32:32.839Z","type":"message"}
{"nick":"creationix","message":"I don't want to dump the entire database on query","date":"2012-05-11T21:32:53.092Z","type":"message"}
{"nick":"philips","message":"creationix: How would a more complex db add to the benchmark?","date":"2012-05-11T21:36:31.830Z","type":"message"}
{"nick":"creationix","message":"well, for this one, it doesn't take much","date":"2012-05-11T21:37:00.661Z","type":"message"}
{"nick":"creationix","message":"send \"users/creationix\" and it responds with the json","date":"2012-05-11T21:37:11.758Z","type":"message"}
{"nick":"creationix","message":"send \"sessions/adsfkjadfs\" and it responds with the session","date":"2012-05-11T21:37:20.838Z","type":"message"}
{"nick":"creationix","message":"I should probably allow connection pooling","date":"2012-05-11T21:37:32.481Z","type":"message"}
{"nick":"creationix","message":"null bytes to end queries","date":"2012-05-11T21:37:47.102Z","type":"message"}
{"nick":"creationix","message":"allow query pipelining","date":"2012-05-11T21:38:01.840Z","type":"message"}
{"nick":"creationix","message":"should be easy enough using libuv","date":"2012-05-11T21:38:06.585Z","type":"message"}
{"nick":"philips","message":"creationix: It might be a rabbit hole. The spec you have so far seems useful.","date":"2012-05-11T21:38:32.516Z","type":"message"}
{"nick":"creationix","message":"well, I want to give people options to optimize","date":"2012-05-11T21:38:51.298Z","type":"message"}
{"nick":"creationix","message":"I do think having a tcp database is a good idea though","date":"2012-05-11T21:39:05.694Z","type":"message"}
{"nick":"creationix","message":"what about templates?","date":"2012-05-11T21:39:09.722Z","type":"message"}
{"nick":"creationix","message":"are those fine pre-compiled and in-memory functions?","date":"2012-05-11T21:39:18.310Z","type":"message"}
{"nick":"creationix","message":"I'd like to force file I/O somehow","date":"2012-05-11T21:39:39.450Z","type":"message"}
{"nick":"creationix","message":"maybe make them load the template from disk and compile it on the fly?","date":"2012-05-11T21:39:49.590Z","type":"message"}
{"nick":"creationix","message":"maybe I should have the template be a static file as part of the benchmark and they have to load and render it","date":"2012-05-11T21:43:16.507Z","type":"message"}
{"nick":"rphillips","message":"i would go for a redis-like clone... file i/o isn't consistent across computers","date":"2012-05-11T21:45:29.761Z","type":"message"}
{"nick":"rphillips","message":"memory + cpu is a bit better, IMO","date":"2012-05-11T21:45:41.736Z","type":"message"}
{"nick":"philips","message":"yea, file i/o isn't useful, tmpfs would be what everyone uses","date":"2012-05-11T21:50:49.434Z","type":"message"}
{"nick":"neomantra1","reason":"Quit: Leaving.","date":"2012-05-11T22:01:40.611Z","type":"quit"}
{"nick":"creationix","message":"ok, updated gist with the beginning of a simple tcp database https://gist.github.com/4b71912f266133c69506#file_db.c","date":"2012-05-11T22:09:17.516Z","type":"message"}
{"nick":"creationix","message":"ok, I'll let them cache the template","date":"2012-05-11T22:10:05.099Z","type":"message"}
{"nick":"creationix","message":"that's usually what happens in production anyway","date":"2012-05-11T22:10:13.162Z","type":"message"}
{"nick":"creationix","message":"rphillips, would tcp over localhost be consistent enough?","date":"2012-05-11T22:10:34.916Z","type":"message"}
{"nick":"mmalecki","date":"2012-05-11T22:23:41.498Z","type":"join"}
{"nick":"mmalecki","reason":"Quit: leaving","date":"2012-05-11T22:37:23.348Z","type":"quit"}
{"nick":"rphillips","message":"probably... i was just thinking reading from the template files isn't a great test","date":"2012-05-11T22:45:38.733Z","type":"message"}
