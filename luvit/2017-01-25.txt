{"nick":"DarkGod","reason":"Write error: Broken pipe","date":"2017-01-25T01:52:21.311Z","type":"quit"}
{"nick":"SkyRocknRoll","date":"2017-01-25T04:00:16.570Z","type":"join"}
{"nick":"SkyRocknRoll","reason":"Ping timeout: 240 seconds","date":"2017-01-25T07:25:10.559Z","type":"quit"}
{"nick":"DarkGod","date":"2017-01-25T08:30:28.477Z","type":"join"}
{"nick":"rendar","date":"2017-01-25T10:07:03.439Z","type":"join"}
{"nick":"rendar","reason":"Ping timeout: 255 seconds","date":"2017-01-25T11:02:24.323Z","type":"quit"}
{"nick":"DarkGod","reason":"Quit: Leaving","date":"2017-01-25T11:21:24.541Z","type":"quit"}
{"nick":"rendar","date":"2017-01-25T11:24:43.932Z","type":"join"}
{"nick":"DarkGod","date":"2017-01-25T13:52:07.838Z","type":"join"}
{"nick":"Go-use-CTCP-S","new_nick":"CTCP-User","date":"2017-01-25T15:21:00.693Z","type":"nick"}
{"nick":"LuaStoned","reason":"Remote host closed the connection","date":"2017-01-25T15:53:50.211Z","type":"quit"}
{"nick":"LuaStoned","date":"2017-01-25T15:54:04.102Z","type":"join"}
{"nick":"CTCP-User","message":"I hate reverse-engineering :/","date":"2017-01-25T17:29:18.093Z","type":"message"}
{"nick":"rphillips","message":"CTCP-User: what are you reversing?","date":"2017-01-25T17:30:24.211Z","type":"message"}
{"nick":"CTCP-User","message":"coro-net","date":"2017-01-25T17:30:29.346Z","type":"message"}
{"nick":"rphillips","message":"ah","date":"2017-01-25T17:30:34.482Z","type":"message"}
{"nick":"CTCP-User","message":"not even a single comment","date":"2017-01-25T17:30:43.158Z","type":"message"}
{"nick":"CTCP-User","message":">.>","date":"2017-01-25T17:30:46.813Z","type":"message"}
{"nick":"SinisterRectus","message":"have you had a look at the other files that use it","date":"2017-01-25T17:40:48.242Z","type":"message"}
{"nick":"SinisterRectus","message":"not that they are documented, but at least there are some examples","date":"2017-01-25T17:41:10.608Z","type":"message"}
{"nick":"CTCP-User","message":"https://themissingdocs.tumblr.com/post/156361295623/luvit-creationixcoro-net-api","date":"2017-01-25T17:45:05.636Z","type":"message"}
{"nick":"CTCP-User","message":"things I learned while writing that: tumblr sucks.","date":"2017-01-25T17:45:34.354Z","type":"message"}
{"nick":"DarkGod","reason":"Ping timeout: 240 seconds","date":"2017-01-25T18:23:41.790Z","type":"quit"}
{"nick":"creationix","message":"I found some bugs in rphillips/options.  Published to lit by rphillips but authored by pancake","date":"2017-01-25T19:02:38.337Z","type":"message"}
{"nick":"creationix","message":"there is no homepage in the lit metadata?  Do you know where the source is?","date":"2017-01-25T19:02:58.105Z","type":"message"}
{"nick":"rphillips","message":"creationix: https://github.com/rphillips/luvit-options","date":"2017-01-25T19:04:09.330Z","type":"message"}
{"nick":"rphillips","message":"forked from https://github.com/radare/luvit-options","date":"2017-01-25T19:04:21.815Z","type":"message"}
{"nick":"creationix","message":"thanks","date":"2017-01-25T19:07:52.494Z","type":"message"}
{"nick":"creationix","message":"PR incoming","date":"2017-01-25T19:07:52.667Z","type":"message"}
{"nick":"creationix","message":"https://github.com/rphillips/luvit-options/pull/1","date":"2017-01-25T19:09:03.878Z","type":"message"}
{"nick":"rphillips","message":"thanks","date":"2017-01-25T19:09:54.578Z","type":"message"}
{"nick":"rphillips","message":"merged","date":"2017-01-25T19:09:57.392Z","type":"message"}
{"nick":"creationix","message":"btw, how do you test new agent checks?","date":"2017-01-25T19:11:08.496Z","type":"message"}
{"nick":"creationix","message":"I ran it locally and it output the JSON data","date":"2017-01-25T19:11:14.285Z","type":"message"}
{"nick":"creationix","message":"what's the lifecycle for hostinfo checks","date":"2017-01-25T19:11:27.776Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, what do you think of my docs?","date":"2017-01-25T19:22:25.936Z","type":"message"}
{"nick":"creationix","message":"CTCP-User neat, I'll look at it later when I'm done with my meetin","date":"2017-01-25T19:23:10.691Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, also how do I read terminal input in a nonblocking way?","date":"2017-01-25T19:24:00.155Z","type":"message"}
{"nick":"creationix","message":"convert stdin to a coro stream","date":"2017-01-25T19:24:17.838Z","type":"message"}
{"nick":"creationix","message":"do you want to read data or write a interactive terminal?","date":"2017-01-25T19:24:36.057Z","type":"message"}
{"nick":"CTCP-User","message":"just read lines","date":"2017-01-25T19:24:42.287Z","type":"message"}
{"nick":"creationix","message":"wrapStream will turn a libuv stream (tty, tcp, pipe, etc) into a coroutine based read/write functions https://github.com/luvit/lit/blob/master/deps/coro-net.lua#L18","date":"2017-01-25T19:25:35.465Z","type":"message"}
{"nick":"CTCP-User","message":"and how do I turn stdin into a libuv stream?","date":"2017-01-25T19:26:07.180Z","type":"message"}
{"nick":"creationix","message":"if you want input line delimited, you might need a codec that buffers till new line and breaks at newlines","date":"2017-01-25T19:26:08.614Z","type":"message"}
{"nick":"creationix","message":"you're in luvit or raw luvi or normal lua with luv?","date":"2017-01-25T19:26:28.599Z","type":"message"}
{"nick":"CTCP-User","message":"luvit","date":"2017-01-25T19:26:33.911Z","type":"message"}
{"nick":"creationix","message":"CTCP-User: ok, in luvit it's wrapped to either a TCP or PIPE libuv object here https://github.com/luvit/luvit/blob/master/deps/pretty-print.lua#L322-L324","date":"2017-01-25T19:29:31.218Z","type":"message"}
{"nick":"creationix","message":"which is then exported here https://github.com/luvit/luvit/blob/master/deps/pretty-print.lua#L361","date":"2017-01-25T19:29:46.571Z","type":"message"}
{"nick":"creationix","message":"so `require('pretty-print').stdin` should give you the raw libuv stream","date":"2017-01-25T19:29:57.202Z","type":"message"}
{"nick":"creationix","message":"or easier, it's at `process.stdin.handle`","date":"2017-01-25T19:30:50.429Z","type":"message"}
{"nick":"creationix","message":"CTCP-User ^","date":"2017-01-25T19:30:56.230Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, does wrapStream yield?","date":"2017-01-25T19:31:36.735Z","type":"message"}
{"nick":"creationix","message":"no","date":"2017-01-25T19:31:46.480Z","type":"message"}
{"nick":"creationix","message":"https://github.com/luvit/lit/blob/master/deps/coro-net.lua#L105-L106","date":"2017-01-25T19:32:06.343Z","type":"message"}
{"nick":"creationix","message":"it does have half a dozen return values though","date":"2017-01-25T19:32:35.448Z","type":"message"}
{"nick":"creationix","message":"if you don't give it a decoder, it will emit raw chunks which may or may not be line delimited","date":"2017-01-25T19:33:16.144Z","type":"message"}
{"nick":"CTCP-User","message":"I have no idea how decoders work, look at the \"themissingdocs\" thing I linked","date":"2017-01-25T19:34:06.270Z","type":"message"}
{"nick":"CTCP-User","message":"local b = \"\" while true do while not b:find(\"\\r\\n\", 1, true) do local v, e = r() if v then b = b .. v else print(\"ERROR\", e) end end DO_STUFF_HERE end","date":"2017-01-25T19:35:19.474Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, ^","date":"2017-01-25T19:35:23.763Z","type":"message"}
{"nick":"CTCP-User","message":"where \"r\" is the read function","date":"2017-01-25T19:35:45.863Z","type":"message"}
{"nick":"creationix","message":"ok, almost done.  I'll write a decoder that supports arbitrary delimiters and check your docs","date":"2017-01-25T19:35:54.806Z","type":"message"}
{"nick":"CTCP-User","message":"I even put \"decode = nil, -- unknown\" and \"updateDecoder(decoder) -- unknown\"","date":"2017-01-25T19:36:30.854Z","type":"message"}
{"nick":"CTCP-User","message":"because, as I said, idk what they do","date":"2017-01-25T19:36:40.888Z","type":"message"}
{"nick":"CTCP-User","message":"and yes I know this is horrifying","date":"2017-01-25T19:38:51.917Z","type":"message"}
{"nick":"creationix","message":"do decoders are optional","date":"2017-01-25T19:40:11.049Z","type":"message"}
{"nick":"creationix","message":"by default it emits raw chunks as they come from the system as lua strings","date":"2017-01-25T19:40:25.385Z","type":"message"}
{"nick":"creationix","message":"so tcp packets, etc","date":"2017-01-25T19:40:30.885Z","type":"message"}
{"nick":"creationix","message":"decoders let you convert that to anything and change the number of events","date":"2017-01-25T19:40:47.776Z","type":"message"}
{"nick":"creationix","message":"one tcp packet could contain 50.5 lines of text","date":"2017-01-25T19:41:00.332Z","type":"message"}
{"nick":"creationix","message":"it would emit 50 events and keep the extra half line to merge with the next tcp packet","date":"2017-01-25T19:41:13.377Z","type":"message"}
{"nick":"creationix","message":"the http codec reads tcp packets and converts to one big lua table for headers and status and then events for body chunks","date":"2017-01-25T19:41:49.315Z","type":"message"}
{"nick":"creationix","message":"if it was chuncked-encoding they are turned into plain chunks","date":"2017-01-25T19:42:03.107Z","type":"message"}
{"nick":"CTCP-User","message":"TCP packets aren't a thing","date":"2017-01-25T19:42:13.061Z","type":"message"}
{"nick":"creationix","message":"and then it emits an empty string to signal end of http body","date":"2017-01-25T19:42:14.334Z","type":"message"}
{"nick":"CTCP-User","message":"or rather, they are","date":"2017-01-25T19:42:32.000Z","type":"message"}
{"nick":"CTCP-User","message":"but not the way you're thinking","date":"2017-01-25T19:42:35.561Z","type":"message"}
{"nick":"CTCP-User","message":"when you send a line and it's split in 20 packets, the other end could receive the packets out of order","date":"2017-01-25T19:43:04.416Z","type":"message"}
{"nick":"CTCP-User","message":"it then reorders the packets and once all packets are received it triggers the event","date":"2017-01-25T19:43:19.546Z","type":"message"}
{"nick":"creationix","message":"well whatever you call them, but at the libuv level you get arbitrarily sized pieces of the data stream","date":"2017-01-25T19:43:26.683Z","type":"message"}
{"nick":"CTCP-User","message":"yes, but they're not packets","date":"2017-01-25T19:43:40.608Z","type":"message"}
{"nick":"creationix","message":"you're right it's a little higher abstraction than raw tcp packets","date":"2017-01-25T19:43:49.790Z","type":"message"}
{"nick":"CTCP-User","message":"you could say \"raw data\" I guess?","date":"2017-01-25T19:44:30.696Z","type":"message"}
{"nick":"creationix","message":"stream chunk","date":"2017-01-25T19:44:37.729Z","type":"message"}
{"nick":"creationix","message":"either way, the point of decoders is to take these arbitrarily chopped up chunks and reassemble them into something more convenient","date":"2017-01-25T19:45:08.651Z","type":"message"}
{"nick":"creationix","message":"and also optionally parse them into objects","date":"2017-01-25T19:45:14.984Z","type":"message"}
{"nick":"CTCP-User","message":"stream chunk doesn't apply to UDP because UDP is packets instead of streams","date":"2017-01-25T19:45:29.623Z","type":"message"}
{"nick":"creationix","message":"udp isn't a stream in llibuv","date":"2017-01-25T19:45:46.532Z","type":"message"}
{"nick":"creationix","message":"used to be, but they fixed that","date":"2017-01-25T19:45:50.059Z","type":"message"}
{"nick":"creationix","message":":)","date":"2017-01-25T19:45:50.995Z","type":"message"}
{"nick":"CTCP-User","message":"oh alright","date":"2017-01-25T19:46:09.802Z","type":"message"}
{"nick":"creationix","message":"so if you give my code a udp_t it will fail since the methods at the C level are different","date":"2017-01-25T19:46:13.470Z","type":"message"}
{"nick":"CTCP-User","message":"so no udp coroutines?","date":"2017-01-25T19:46:34.090Z","type":"message"}
{"nick":"CTCP-User","message":"anyway uh","date":"2017-01-25T19:46:57.133Z","type":"message"}
{"nick":"CTCP-User","message":"please describe decoders as short as possible","date":"2017-01-25T19:47:10.024Z","type":"message"}
{"nick":"CTCP-User","message":"including function signatures","date":"2017-01-25T19:47:21.831Z","type":"message"}
{"nick":"CTCP-User","message":"(what goes in, what comes out, what it's expected to do, etc)","date":"2017-01-25T19:47:32.007Z","type":"message"}
{"nick":"creationix","message":"uv_tty_t, uv_tcp_t, and uv_pipe_t are the three that support uv_stream_t","date":"2017-01-25T19:47:45.939Z","type":"message"}
{"nick":"creationix","message":"I could probably add support for uv_udp_t and just emit events as they come","date":"2017-01-25T19:47:56.162Z","type":"message"}
{"nick":"creationix","message":"it would be custom code though, a different wrapper","date":"2017-01-25T19:48:05.783Z","type":"message"}
{"nick":"creationix","message":"here is a simpler codec for redis protocol https://github.com/creationix/redis-luvit/blob/master/libs/redis-codec.lua","date":"2017-01-25T19:49:11.259Z","type":"message"}
{"nick":"creationix","message":"decode takes chunk","date":"2017-01-25T19:49:32.370Z","type":"message"}
{"nick":"creationix","message":"and returns either:","date":"2017-01-25T19:49:46.276Z","type":"message"}
{"nick":"creationix","message":"1. nothing if more data is needed to parse","date":"2017-01-25T19:49:51.217Z","type":"message"}
{"nick":"creationix","message":"2. the first event and the leftover data","date":"2017-01-25T19:50:01.217Z","type":"message"}
{"nick":"creationix","message":"It","date":"2017-01-25T19:50:05.159Z","type":"message"}
{"nick":"creationix","message":"It's not the best API since it means slicing up data and doing lots of memcpy internally, but it works fairly well in practice","date":"2017-01-25T19:50:28.493Z","type":"message"}
{"nick":"creationix","message":"I should have designed it to take (chunk, offset) and return (data, offset)","date":"2017-01-25T19:50:54.157Z","type":"message"}
{"nick":"creationix","message":"the code calling the decoder is responsible for concatenating the leftover data with new events","date":"2017-01-25T19:51:29.898Z","type":"message"}
{"nick":"creationix","message":"also it's responsible for re-feeding the leftover data to the decoder till it returns nil","date":"2017-01-25T19:51:46.320Z","type":"message"}
{"nick":"ldub","date":"2017-01-25T19:59:06.096Z","type":"join"}
{"nick":"CTCP-User","message":"creationix, what do you mean it's easier to do what I did? .-.","date":"2017-01-25T19:59:23.248Z","type":"message"}
{"nick":"creationix","message":"?","date":"2017-01-25T20:00:17.081Z","type":"message"}
{"nick":"creationix","message":"let me write up a decoder for line delimited strings.  That seems to be a common request anyway","date":"2017-01-25T20:00:38.607Z","type":"message"}
{"nick":"creationix","message":"and I'll pair it with an encoder that simply adds newlines","date":"2017-01-25T20:00:59.998Z","type":"message"}
{"nick":"creationix","message":"for symmetry","date":"2017-01-25T20:01:09.142Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, you're basically telling me it's easier to use this: (1 sec let me tweak it a bit","date":"2017-01-25T20:08:05.137Z","type":"message"}
{"nick":"CTCP-User","message":"local b = \"\" while true do while not b:find(\"\\r\\n\", 1, true) do local v, e = r() if v then b = b .. v else print(\"ERROR\", e) end end local v = b:sub(1, b:find('\\r\\n', 1, true) - 1) b = b:sub(b:find('\\r\\n', 1, true) + 2) DO_STUFF_WITH_v_HERE end","date":"2017-01-25T20:08:36.968Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, right?","date":"2017-01-25T20:08:42.380Z","type":"message"}
{"nick":"CTCP-User","message":"uh r returns \"ok, err\" right?","date":"2017-01-25T20:09:09.517Z","type":"message"}
{"nick":"creationix","message":"not sure, hard to read in that format","date":"2017-01-25T20:09:23.650Z","type":"message"}
{"nick":"CTCP-User","message":"(r is the first value of wrapStream, or read)","date":"2017-01-25T20:09:25.930Z","type":"message"}
{"nick":"CTCP-User","message":" \u0001F 02,99\u0001local\u0001F 99,99\u0001 b = \u0001F 05,99\u0001\"\u0001F 99,99\u0001\u0001F 05,99\u0001\"\u0001F 99,99\u0001 \u0001F 02,99\u0001while\u0001F 99,99\u0001 \u0001F 02,99\u0001true\u0001F 99,99\u0001 \u0001F 02,99\u0001do\u0001F 99,99\u0001 \u0001F 02,99\u0001while\u0001F 99,99\u0001 \u0001F 06,99\u0001not\u0001F 99,99\u0001 b:find(\u0001F 05,99\u0001\"\u0001F 99,99\u0001\u0001F 05,99\u0001\\r\u0001F 99,99\u0001\u0001F 05,99\u0001\\n\u0001F 99,99\u0001\u0001F 05,99\u0001\"\u0001F 99,99\u0001, \u0001F 02,99\u00011\u0001F 99,99\u0001, \u0001F 02,99\u0001true\u0001F 99,99\u0001) \u0001F 02,99\u0001do\u0001F 99,99\u0001 \u0001F 02,99\u0001local\u0001F 99,99\u0001 v, e = r() \u0001F 02,99\u0001if\u0001F 99,99\u0001 v \u0001F 02,99\u0001then\u0001F 99,99\u0001 b = b .. v \u0001F 02,99\u0001else\u0001F 99,99\u0001","date":"2017-01-25T20:09:56.656Z","type":"message"}
{"nick":"CTCP-User","message":"\u0001F 10,99\u0001print\u0001F 99,99\u0001(\u0001F 05,99\u0001\"\u0001F 99,99\u0001\u0001F 05,99\u0001E\u0001F 99,99\u0001\u0001F 05,99\u0001R\u0001F 99,99\u0001\u0001F 05,99\u0001R\u0001F 99,99\u0001\u0001F 05,99\u0001O\u0001F 99,99\u0001\u0001F 05,99\u0001R\u0001F 99,99\u0001\u0001F 05,99\u0001\"\u0001F 99,99\u0001, e) \u0001F 02,99\u0001end\u0001F 99,99\u0001 \u0001F 02,99\u0001end\u0001F 99,99\u0001 \u0001F 02,99\u0001local\u0001F 99,99\u0001 v = b:sub(\u0001F 02,99\u00011\u0001F 99,99\u0001, b:find(\u0001F 05,99\u0001'\u0001F 99,99\u0001\u0001F 05,99\u0001\\r\u0001F 99,99\u0001\u0001F 05,99\u0001\\n\u0001F 99,99\u0001\u0001F 05,99\u0001'\u0001F 99,99\u0001, \u0001F 02,99\u00011\u0001F 99,99\u0001, \u0001F 02,99\u0001true\u0001F 99,99\u0001) - \u0001F 02,99\u00011\u0001F 99,99\u0001) b = b:sub(b:find(\u0001F 05,99\u0001'\u0001F","date":"2017-01-25T20:09:56.847Z","type":"message"}
{"nick":"CTCP-User","message":"99,99\u0001\u0001F 05,99\u0001\\r\u0001F 99,99\u0001\u0001F 05,99\u0001\\n\u0001F 99,99\u0001\u0001F 05,99\u0001'\u0001F 99,99\u0001, \u0001F 02,99\u00011\u0001F 99,99\u0001, \u0001F 02,99\u0001true\u0001F 99,99\u0001) + \u0001F 02,99\u00012\u0001F 99,99\u0001) DO_STUFF_WITH_v_HERE \u0001F 02,99\u0001end\u0001F 99,99\u0001","date":"2017-01-25T20:09:57.679Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, better?","date":"2017-01-25T20:10:02.009Z","type":"message"}
{"nick":"inex","message":"what the fuck","date":"2017-01-25T20:10:18.826Z","type":"message"}
{"nick":"CTCP-User","message":"uh looks like my IRC client didn't split it correctly","date":"2017-01-25T20:10:35.278Z","type":"message"}
{"nick":"CTCP-User","message":"that was supposed to be syntax hilighted","date":"2017-01-25T20:10:41.690Z","type":"message"}
{"nick":"creationix","message":"no worries, I reformatted it in my editor","date":"2017-01-25T20:10:49.402Z","type":"message"}
{"nick":"creationix","message":"colored IRC text doesn't work in many clients anyway","date":"2017-01-25T20:11:06.755Z","type":"message"}
{"nick":"creationix","message":"https://gist.github.com/creationix/70936904f18d496cd1a9e7706f54974d","date":"2017-01-25T20:11:29.138Z","type":"message"}
{"nick":"creationix","message":"CTCP-User if you use a decoder you don't need this code","date":"2017-01-25T20:11:59.185Z","type":"message"}
{"nick":"creationix","message":"just a sec...","date":"2017-01-25T20:12:03.263Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, show me what it looks like with a decoder","date":"2017-01-25T20:12:13.522Z","type":"message"}
{"nick":"creationix","message":"for line in read do","date":"2017-01-25T20:12:48.137Z","type":"message"}
{"nick":"creationix","message":"  -- do stuff with line","date":"2017-01-25T20:12:48.310Z","type":"message"}
{"nick":"creationix","message":"end","date":"2017-01-25T20:12:48.310Z","type":"message"}
{"nick":"CTCP-User","message":"uh neat","date":"2017-01-25T20:13:15.320Z","type":"message"}
{"nick":"creationix","message":"CTCP-User a line codec is easy https://gist.github.com/creationix/00d31eda01bb2aaca1091666b1c39f31","date":"2017-01-25T20:16:35.054Z","type":"message"}
{"nick":"creationix","message":"could even make it configurable where instead of \"\\n\" it allows any delimeter","date":"2017-01-25T20:17:04.938Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, how about this","date":"2017-01-25T20:17:31.729Z","type":"message"}
{"nick":"CTCP-User","message":"switch that \"\" with a {}","date":"2017-01-25T20:17:37.902Z","type":"message"}
{"nick":"CTCP-User","message":"(in the buffer code)","date":"2017-01-25T20:17:42.487Z","type":"message"}
{"nick":"creationix","message":"buffer code?","date":"2017-01-25T20:17:56.453Z","type":"message"}
{"nick":"CTCP-User","message":"then call the decoder with the new chunk and have it return an index","date":"2017-01-25T20:18:06.409Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, yeah in the wrapReader or w/e","date":"2017-01-25T20:18:15.929Z","type":"message"}
{"nick":"creationix","message":"oh, you're talking about changing the interface to decoders","date":"2017-01-25T20:18:31.555Z","type":"message"}
{"nick":"CTCP-User","message":"the one that does b = b .. raw","date":"2017-01-25T20:18:37.089Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, yeah, for performance","date":"2017-01-25T20:18:42.967Z","type":"message"}
{"nick":"creationix","message":"yeah, it can be improved, but changing it breaks all the existing code using it","date":"2017-01-25T20:18:51.470Z","type":"message"}
{"nick":"creationix","message":"basically we'll just need to add a new library that performs better and start migrating libs to it one at a time","date":"2017-01-25T20:19:06.015Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, true, but it's a third party lib so make it version 2.x","date":"2017-01-25T20:19:08.524Z","type":"message"}
{"nick":"creationix","message":"or do a 2.x like you say","date":"2017-01-25T20:19:34.698Z","type":"message"}
{"nick":"creationix","message":"you're still going to need concat in case of data being split across two chunks","date":"2017-01-25T20:19:53.252Z","type":"message"}
{"nick":"creationix","message":"I don't want decoders to have to worry about a list of chunks for input","date":"2017-01-25T20:20:11.727Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, you give them the new chunk","date":"2017-01-25T20:20:34.187Z","type":"message"}
{"nick":"CTCP-User","message":"if they return an index, you split","date":"2017-01-25T20:20:41.391Z","type":"message"}
{"nick":"creationix","message":"I've done this before for something, not sure where the code went","date":"2017-01-25T20:20:50.654Z","type":"message"}
{"nick":"CTCP-User","message":"since that's the most common use-case","date":"2017-01-25T20:20:54.698Z","type":"message"}
{"nick":"creationix","message":"but `decode(chunk, offset) -> data, offset` is much better than `decode(chunk) -> data, extra`","date":"2017-01-25T20:21:23.966Z","type":"message"}
{"nick":"creationix","message":"the wrapper is slightly more complex, but not much","date":"2017-01-25T20:21:32.360Z","type":"message"}
{"nick":"creationix","message":"and decoders need to take offset into account, but that's not too bad","date":"2017-01-25T20:21:42.065Z","type":"message"}
{"nick":"creationix","message":"actually decoders tend to get simpler since you can return offsets instead of constantly slicing to return extra","date":"2017-01-25T20:22:07.781Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, except you save a large amount of allocations and can use table.concat","date":"2017-01-25T20:22:24.670Z","type":"message"}
{"nick":"creationix","message":"tables have overhead","date":"2017-01-25T20:22:51.408Z","type":"message"}
{"nick":"creationix","message":"if I switch to string + offset it's pretty good actually","date":"2017-01-25T20:23:01.149Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, minimal compared to .. over and over again","date":"2017-01-25T20:23:01.702Z","type":"message"}
{"nick":"creationix","message":"in string + offset as proposed, you only concat for cases where a value is split across chunks","date":"2017-01-25T20:23:21.258Z","type":"message"}
{"nick":"CTCP-User","message":"with table.concat you allocate the full buffer once","date":"2017-01-25T20:23:21.431Z","type":"message"}
{"nick":"CTCP-User","message":"yes, most cases","date":"2017-01-25T20:23:41.048Z","type":"message"}
{"nick":"creationix","message":"I wouldn't say that's most cases","date":"2017-01-25T20:24:12.707Z","type":"message"}
{"nick":"creationix","message":"besides, unless the decoder has to be aware of how to read into a table of chunks, tables won't help any","date":"2017-01-25T20:24:31.334Z","type":"message"}
{"nick":"CTCP-User","message":"meh","date":"2017-01-25T20:24:54.993Z","type":"message"}
{"nick":"CTCP-User","message":"I guess if you want performance you just have to do everything yourself","date":"2017-01-25T20:25:03.751Z","type":"message"}
{"nick":"creationix","message":"and then it's really messy, you have `decode(vector,vector_offset,byte_offset)->data,vector_offset,byte_offset`","date":"2017-01-25T20:25:42.003Z","type":"message"}
{"nick":"creationix","message":"and every read into the data is `vector[vector_offset]` on top of the byte_offset passed to string methods","date":"2017-01-25T20:26:16.050Z","type":"message"}
{"nick":"creationix","message":"also you have to watch for boundaries and thus constantly query for the lengths of the vector pieces","date":"2017-01-25T20:26:31.425Z","type":"message"}
{"nick":"creationix","message":"it's way too much overhead and complexity just to avoid small concats in case of crossed boundaries","date":"2017-01-25T20:26:51.288Z","type":"message"}
{"nick":"creationix","message":"I'm sure there are cases where this does perform better, but generally it will perform worse and be *far* more complicated and error prone","date":"2017-01-25T20:27:26.100Z","type":"message"}
{"nick":"creationix","message":"the cost/benefit ratio of string+offset is good, the ratio for table of strings is bad","date":"2017-01-25T20:28:02.186Z","type":"message"}
{"nick":"CTCP-User","message":"return vector[vector_offset]:find(\"\\r\\n\", 1, true)","date":"2017-01-25T20:30:05.104Z","type":"message"}
{"nick":"CTCP-User","message":"is what I was hoping for","date":"2017-01-25T20:30:10.589Z","type":"message"}
{"nick":"creationix","message":"it's not that simple","date":"2017-01-25T20:30:25.057Z","type":"message"}
{"nick":"CTCP-User","message":"actually, return last_chunk:find(\"\\r\\n\", 1, true)","date":"2017-01-25T20:30:26.925Z","type":"message"}
{"nick":"CTCP-User","message":"and it'd concat all previous chunks for you","date":"2017-01-25T20:30:32.655Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, how often do you need to skip new data?","date":"2017-01-25T20:31:04.401Z","type":"message"}
{"nick":"creationix","message":"what do you mean?","date":"2017-01-25T20:32:02.606Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, I saw that, also most of my CTCPs are broken","date":"2017-01-25T20:32:20.133Z","type":"message"}
{"nick":"CTCP-User","message":"I'm too lazy to fix them tho","date":"2017-01-25T20:32:33.626Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, I mean, how often do you need to skip data in one of those decoders?","date":"2017-01-25T20:32:45.965Z","type":"message"}
{"nick":"CTCP-User","message":"hmm","date":"2017-01-25T20:32:52.640Z","type":"message"}
{"nick":"CTCP-User","message":"wait","date":"2017-01-25T20:32:53.649Z","type":"message"}
{"nick":"CTCP-User","message":"here's a better idea","date":"2017-01-25T20:32:56.787Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, why not have decoders and splitters?","date":"2017-01-25T20:33:03.854Z","type":"message"}
{"nick":"creationix","message":"yes with decoder you re-parse data you've already parsed","date":"2017-01-25T20:33:11.597Z","type":"message"}
{"nick":"creationix","message":"that's why I was initially against this style","date":"2017-01-25T20:33:19.495Z","type":"message"}
{"nick":"creationix","message":"but experience has told me that it's better overall","date":"2017-01-25T20:33:26.482Z","type":"message"}
{"nick":"CTCP-User","message":"splitters just split the stream, decoders just parse the stream","date":"2017-01-25T20:33:27.881Z","type":"message"}
{"nick":"creationix","message":"you can do both","date":"2017-01-25T20:33:46.088Z","type":"message"}
{"nick":"CTCP-User","message":"splitters are blazing fast since they only care about the last_chunk (the one you get from the read call)","date":"2017-01-25T20:33:55.956Z","type":"message"}
{"nick":"creationix","message":"just organize the order of code in your codec to bail as early as possible","date":"2017-01-25T20:33:57.081Z","type":"message"}
{"nick":"creationix","message":"for example, a decoder that did line-delimited JSON","date":"2017-01-25T20:34:09.012Z","type":"message"}
{"nick":"creationix","message":"scan for newline, if not there, bail","date":"2017-01-25T20:34:15.213Z","type":"message"}
{"nick":"creationix","message":"next iteration is just scan again","date":"2017-01-25T20:34:22.205Z","type":"message"}
{"nick":"CTCP-User","message":"decoders would be faster since the splitter would be doing the splitting and the decoder wouldn't have to worry about that as much","date":"2017-01-25T20:34:26.641Z","type":"message"}
{"nick":"creationix","message":"you don't parse JSON till your'e sure it's all there","date":"2017-01-25T20:34:31.514Z","type":"message"}
{"nick":"CTCP-User","message":"and it'd do things like skip part of the stream","date":"2017-01-25T20:35:35.478Z","type":"message"}
{"nick":"CTCP-User","message":"reducing a ton of allocations","date":"2017-01-25T20:35:35.652Z","type":"message"}
{"nick":"CTCP-User","message":"(and using a table as a buffer)","date":"2017-01-25T20:35:36.000Z","type":"message"}
{"nick":"creationix","message":"much faster *and* simpler than interruptible/resumable streaming JSON parsers","date":"2017-01-25T20:35:38.998Z","type":"message"}
{"nick":"creationix","message":"I've written them, I would know","date":"2017-01-25T20:35:39.172Z","type":"message"}
{"nick":"creationix","message":"I understand what you want and can imagine cases where it's worth the cost","date":"2017-01-25T20:36:21.929Z","type":"message"}
{"nick":"creationix","message":"but this generic coro-channel interface is not a good place","date":"2017-01-25T20:36:50.447Z","type":"message"}
{"nick":"creationix","message":"a common example would be a REST service that returns a giant JSON body","date":"2017-01-25T20:37:14.326Z","type":"message"}
{"nick":"creationix","message":"the HTTP codec would pass the http body chunks through as-is where you can collect them into a lua table","date":"2017-01-25T20:37:37.860Z","type":"message"}
{"nick":"creationix","message":"then you can use table.concat once and JSON.parse once","date":"2017-01-25T20:37:46.565Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, the cost is minimal, I already have the whole code in my head","date":"2017-01-25T20:37:52.405Z","type":"message"}
{"nick":"CTCP-User","message":"and the performance improvement would be fairly large","date":"2017-01-25T20:38:01.402Z","type":"message"}
{"nick":"creationix","message":"I've written these and measured them","date":"2017-01-25T20:38:22.667Z","type":"message"}
{"nick":"creationix","message":"the performance was not what I expected","date":"2017-01-25T20:38:30.748Z","type":"message"}
{"nick":"creationix","message":"but you're welcome to write a fork or coro-wrapper that uses tables for buffer","date":"2017-01-25T20:38:51.255Z","type":"message"}
{"nick":"creationix","message":"your decoders will be much more complicated","date":"2017-01-25T20:38:55.157Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, you talked about calling it with a table, you talked about calling it with a string","date":"2017-01-25T20:38:57.717Z","type":"message"}
{"nick":"CTCP-User","message":"you didn't talk about having \"splitters\" and \"decoders\" as separate units that operate in sync with eachother","date":"2017-01-25T20:39:13.175Z","type":"message"}
{"nick":"CTCP-User","message":"splitters would take a string, return a point where to split it","date":"2017-01-25T20:39:33.522Z","type":"message"}
{"nick":"creationix","message":"I did actually, the HTTP + REST + giant JSON body example","date":"2017-01-25T20:39:42.624Z","type":"message"}
{"nick":"CTCP-User","message":"decoders would take a string, return a string","date":"2017-01-25T20:39:44.631Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, is this actually much more complicated?","date":"2017-01-25T20:40:07.129Z","type":"message"}
{"nick":"creationix","message":"the main problem with making it two layers is many protocols need coupling between them","date":"2017-01-25T20:41:03.804Z","type":"message"}
{"nick":"CTCP-User","message":"function split(x) return x:find('\\r\\n', 1, true) end function decode(x) return x:gsub('\\r\\n', '') end","date":"2017-01-25T20:41:10.440Z","type":"message"}
{"nick":"creationix","message":"you don't always know where to split before decoding partially","date":"2017-01-25T20:41:14.954Z","type":"message"}
{"nick":"creationix","message":"git pack file streams being a nasty example","date":"2017-01-25T20:42:12.394Z","type":"message"}
{"nick":"creationix","message":"the length header is the number of uncompressed bytes to expect, but what follows is a raw deflate stream of unknown length","date":"2017-01-25T20:42:33.533Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, local upvalue = -1 function split(x) if upvalue == -1 then upvalue = readint(x) if upvalue > #x-4 then upvalue = upvalue - #x-4 return nil end <other stuff here>","date":"2017-01-25T20:42:35.317Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, Lua has upvalues","date":"2017-01-25T20:42:50.066Z","type":"message"}
{"nick":"creationix","message":"you don't know when to stop reading till your inflate state machine reaches end state","date":"2017-01-25T20:42:51.077Z","type":"message"}
{"nick":"CTCP-User","message":"also, ouch","date":"2017-01-25T20:42:51.636Z","type":"message"}
{"nick":"CTCP-User","message":"I mean","date":"2017-01-25T20:43:04.714Z","type":"message"}
{"nick":"CTCP-User","message":"we could keep decoders as is","date":"2017-01-25T20:43:08.410Z","type":"message"}
{"nick":"CTCP-User","message":"and add a splitter layer","date":"2017-01-25T20:43:13.017Z","type":"message"}
{"nick":"CTCP-User","message":"that'd be backwards compatible and increase performance","date":"2017-01-25T20:43:20.994Z","type":"message"}
{"nick":"creationix","message":"that might help","date":"2017-01-25T20:43:49.261Z","type":"message"}
{"nick":"creationix","message":"adds a little complexity to the wrap api, but the new stuff can go at the end and be optional","date":"2017-01-25T20:44:23.609Z","type":"message"}
{"nick":"CTCP-User","message":"for the git thing, use a plain decoder, for IRC, use a plain splitter (+ decoder if you wanna remove \\r\\n)","date":"2017-01-25T20:44:31.945Z","type":"message"}
{"nick":"CTCP-User","message":"heh, funny how this went from documenting the API to improving the API","date":"2017-01-25T20:47:04.280Z","type":"message"}
{"nick":"creationix","message":"yep","date":"2017-01-25T20:52:34.575Z","type":"message"}
{"nick":"creationix","message":"so I think this could work well.  I wonder if we need to update the splitter ever","date":"2017-01-25T20:52:51.332Z","type":"message"}
{"nick":"creationix","message":"since it's coupled to the decoder, I would think so","date":"2017-01-25T20:53:01.947Z","type":"message"}
{"nick":"CTCP-User","message":"or add a new arg to updateDecoder","date":"2017-01-25T20:57:46.260Z","type":"message"}
{"nick":"CTCP-User","message":"right?","date":"2017-01-25T20:58:02.607Z","type":"message"}
{"nick":"CTCP-User","message":"idk what updateDecoder actually does tho","date":"2017-01-25T20:58:11.043Z","type":"message"}
{"nick":"CTCP-User","message":"so I might be spouting BS","date":"2017-01-25T20:58:17.833Z","type":"message"}
{"nick":"CTCP-User","message":":P","date":"2017-01-25T20:58:19.251Z","type":"message"}
{"nick":"ldub","reason":"Remote host closed the connection","date":"2017-01-25T20:58:50.774Z","type":"quit"}
{"nick":"creationix","message":"hmm, looks like I was in the process of refactoring this before","date":"2017-01-25T20:58:50.948Z","type":"message"}
{"nick":"creationix","message":"the coro-wrapper library looks interesting","date":"2017-01-25T20:59:03.629Z","type":"message"}
{"nick":"creationix","message":"I think I was trying to decouple decoders from the conversion from libuv callbacks to coroutine blocking read/write functions","date":"2017-01-25T20:59:36.290Z","type":"message"}
{"nick":"creationix","message":"so  a custom splitter layer helps with the pathological case where a value is split across many chunks","date":"2017-01-25T21:01:17.687Z","type":"message"}
{"nick":"ldub","date":"2017-01-25T21:01:20.455Z","type":"join"}
{"nick":"creationix","message":"but we also need the offset input in decoder to solve the case where a chunk contains many events","date":"2017-01-25T21:01:35.904Z","type":"message"}
{"nick":"ldub","reason":"Read error: Connection reset by peer","date":"2017-01-25T21:01:49.356Z","type":"quit"}
{"nick":"creationix","message":"one large chunk could contain hundreds or even thousands of lines.  Without offset, we have to slice and allocate over and over for each line","date":"2017-01-25T21:02:19.686Z","type":"message"}
{"nick":"CTCP-User","message":"oh","date":"2017-01-25T21:02:54.343Z","type":"message"}
{"nick":"CTCP-User","message":"yes that's a good idea","date":"2017-01-25T21:03:07.711Z","type":"message"}
{"nick":"CTCP-User","message":"but we don't want the buffer to grow indefinitely","date":"2017-01-25T21:03:14.141Z","type":"message"}
{"nick":"CTCP-User","message":"creationix, how to clear the buffer?","date":"2017-01-25T21:03:27.979Z","type":"message"}
{"nick":"creationix","message":"when the decoder returns nil it means it's done with the buffer and nothing is left","date":"2017-01-25T21:03:44.091Z","type":"message"}
{"nick":"creationix","message":"it will be concatenated to the front of the next chunk","date":"2017-01-25T21:03:58.102Z","type":"message"}
{"nick":"creationix","message":"(assuming there are extra bytes, this is often not the case in my testing)","date":"2017-01-25T21:04:22.806Z","type":"message"}
{"nick":"CTCP-User","message":"o ok","date":"2017-01-25T21:04:51.332Z","type":"message"}
{"nick":"CTCP-User","message":"alright","date":"2017-01-25T21:04:54.540Z","type":"message"}
{"nick":"creationix","message":"I like thinking of this layer apart from the splitter helper","date":"2017-01-25T21:04:56.355Z","type":"message"}
{"nick":"creationix","message":"they solve different problems","date":"2017-01-25T21:05:03.258Z","type":"message"}
{"nick":"CTCP-User","message":"neat","date":"2017-01-25T21:05:12.595Z","type":"message"}
{"nick":"creationix","message":"so the splitter's job is to efficiently merge many chunks","date":"2017-01-25T21:05:43.529Z","type":"message"}
{"nick":"creationix","message":"since the decoder merges by concatting over and over, it doesn't do it well on it's own","date":"2017-01-25T21:06:03.642Z","type":"message"}
{"nick":"creationix","message":"but a splitter (or merger or whatever) could quickly collect hundreds of chunks for a giant body and merge at once","date":"2017-01-25T21:06:50.854Z","type":"message"}
{"nick":"CTCP-User","message":"yup","date":"2017-01-25T21:07:05.539Z","type":"message"}
{"nick":"creationix","message":"changing the decoder to accept offset is a breaking change though","date":"2017-01-25T21:07:23.782Z","type":"message"}
{"nick":"creationix","message":"might as well do both at once","date":"2017-01-25T21:07:28.337Z","type":"message"}
{"nick":"CTCP-User","message":"ok","date":"2017-01-25T21:07:37.020Z","type":"message"}
{"nick":"creationix","message":"and I'd really like to finish decoupling the decoder/splitter from the nasty libuv->coro translation code if it's possible to do without overhead","date":"2017-01-25T21:08:02.628Z","type":"message"}
{"nick":"creationix","message":"this is nasty https://github.com/luvit/lit/blob/master/deps/coro-channel.lua","date":"2017-01-25T21:08:52.611Z","type":"message"}
{"nick":"creationix","message":"but once you assume a base of coroutine-style streams, it's pretty simple https://github.com/luvit/lit/blob/master/deps/coro-wrapper.lua","date":"2017-01-25T21:09:14.098Z","type":"message"}
{"nick":"creationix","message":"it does mean one extra closure since the wrapper takes read() and returns a new read()","date":"2017-01-25T21:09:47.069Z","type":"message"}
{"nick":"creationix","message":"that's probably worth the costs","date":"2017-01-25T21:09:56.866Z","type":"message"}
{"nick":"creationix","message":"and more importantly we can use the decoder/splitter logic on other streams, not just libuv streams","date":"2017-01-25T21:10:30.420Z","type":"message"}
{"nick":"creationix","message":"makes unit tests for decoders easier","date":"2017-01-25T21:10:57.916Z","type":"message"}
{"nick":"creationix","message":"rphillips if you publish a new version of rphillips/options to lit then the next agent version will pick it up I think","date":"2017-01-25T21:15:01.152Z","type":"message"}
{"nick":"creationix","message":"I don't remember is the agent is published to lit","date":"2017-01-25T21:15:35.873Z","type":"message"}
{"nick":"creationix","message":"*if","date":"2017-01-25T21:15:40.930Z","type":"message"}
{"nick":"creationix","message":"CTCP-User ok, working on optimizing coro-channel","date":"2017-01-25T21:45:18.864Z","type":"message"}
{"nick":"creationix","message":"another reason to decoulpe decoder from libuv shim is so we can easily add support for uv_udp_t","date":"2017-01-25T21:45:51.055Z","type":"message"}
{"nick":"DarkGod","date":"2017-01-25T22:11:55.456Z","type":"join"}
{"nick":"creationix","message":"CTCP-User Here is a simple merger function that helps for cases where there are too mane concatenations https://gist.github.com/creationix/579fa1244fe3b83fe8f1c0565c88b6f8","date":"2017-01-25T22:29:01.879Z","type":"message"}
{"nick":"rphillips","message":"creationix: published that options package","date":"2017-01-25T22:57:31.538Z","type":"message"}
{"nick":"rphillips","message":"0.0.6","date":"2017-01-25T22:57:38.369Z","type":"message"}
{"nick":"creationix","message":"awesome thanks","date":"2017-01-25T22:57:38.929Z","type":"message"}
{"nick":"creationix","message":"that will make errors in the agent CLI much easier to read","date":"2017-01-25T22:57:47.353Z","type":"message"}
{"nick":"rphillips","message":"cool","date":"2017-01-25T22:57:54.403Z","type":"message"}
{"nick":"creationix","message":"it was a tiny error message followed by 20 lines of stack trace","date":"2017-01-25T22:57:57.093Z","type":"message"}
{"nick":"creationix","message":"took me 10 minutes to figure out the stack trace wasn't the root cause","date":"2017-01-25T22:58:11.534Z","type":"message"}
{"nick":"creationix","message":"https://github.com/luvit/lit/pull/197","date":"2017-01-25T23:03:46.579Z","type":"message"}
{"nick":"rphillips","message":"creationix: the string concat on line 103 is pretty slow","date":"2017-01-25T23:05:00.023Z","type":"message"}
{"nick":"rphillips","message":"any way to tabelize it?","date":"2017-01-25T23:05:11.432Z","type":"message"}
{"nick":"creationix","message":"that's what the merger helper up top is for","date":"2017-01-25T23:05:22.676Z","type":"message"}
{"nick":"creationix","message":"you use merger if your protocol will have lots of concats","date":"2017-01-25T23:05:34.915Z","type":"message"}
{"nick":"rphillips","message":"ah hah!","date":"2017-01-25T23:05:41.837Z","type":"message"}
{"nick":"creationix","message":"this concat is for small events that get split across chunk boundaries","date":"2017-01-25T23:05:45.832Z","type":"message"}
{"nick":"rphillips","message":"awesome","date":"2017-01-25T23:05:46.006Z","type":"message"}
{"nick":"rphillips","message":"makes sense","date":"2017-01-25T23:05:55.361Z","type":"message"}
{"nick":"creationix","message":"and the new index parameter to decoder will avoid lots of mem copies","date":"2017-01-25T23:06:25.174Z","type":"message"}
{"nick":"creationix","message":"the concat in decode only happens if there was a partial event between chunks.","date":"2017-01-25T23:06:57.727Z","type":"message"}
{"nick":"creationix","message":"(sub is also slow since it creates a new interned string in lua)","date":"2017-01-25T23:07:17.330Z","type":"message"}
{"nick":"creationix","message":"I only use it on line 99 to avoid a case where a tiny tail is after a huge head of already used data","date":"2017-01-25T23:07:51.164Z","type":"message"}
{"nick":"creationix","message":"again, this case only happens if there is leftover data between chunks","date":"2017-01-25T23:08:05.445Z","type":"message"}
{"nick":"creationix","message":"or in other words, this only happens if decode returns nil asking for more data","date":"2017-01-25T23:09:07.142Z","type":"message"}
{"nick":"creationix","message":"hence why merger is so useful, it helps ensure that for many cases, the decoder will always have enough data","date":"2017-01-25T23:09:27.037Z","type":"message"}
{"nick":"rendar","reason":"Ping timeout: 252 seconds","date":"2017-01-25T23:13:06.705Z","type":"quit"}
{"nick":"CTCP-User","message":"creationix, don't use #parts","date":"2017-01-25T23:25:52.333Z","type":"message"}
{"nick":"SinisterRectus","message":"?","date":"2017-01-25T23:30:24.630Z","type":"message"}
{"nick":"rendar","date":"2017-01-25T23:42:12.956Z","type":"join"}
