{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-12-18T00:11:31.918Z","type":"quit"}
{"nick":"pfraze","date":"2015-12-18T00:11:54.008Z","type":"join"}
{"nick":"warbrett_","reason":"Quit: Connection closed for inactivity","date":"2015-12-18T00:48:05.233Z","type":"quit"}
{"nick":"phated","reason":"Remote host closed the connection","date":"2015-12-18T01:17:24.618Z","type":"quit"}
{"nick":"dguttman","reason":"Quit: dguttman","date":"2015-12-18T02:09:36.380Z","type":"quit"}
{"nick":"phated","date":"2015-12-18T03:38:23.410Z","type":"join"}
{"nick":"phated","reason":"Remote host closed the connection","date":"2015-12-18T03:44:49.190Z","type":"quit"}
{"nick":"dguttman","date":"2015-12-18T04:22:16.070Z","type":"join"}
{"nick":"dguttman","reason":"Client Quit","date":"2015-12-18T04:24:07.191Z","type":"quit"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-12-18T05:56:56.743Z","type":"quit"}
{"nick":"contrahax","reason":"Quit: Sleeping","date":"2015-12-18T06:18:31.994Z","type":"quit"}
{"nick":"contrahax","date":"2015-12-18T06:29:30.696Z","type":"join"}
{"nick":"contrahax","reason":"Quit: Sleeping","date":"2015-12-18T07:00:29.429Z","type":"quit"}
{"nick":"fotoverite","reason":"Quit: fotoverite","date":"2015-12-18T07:34:37.499Z","type":"quit"}
{"nick":"fotoverite","date":"2015-12-18T07:40:47.455Z","type":"join"}
{"nick":"fotoverite","reason":"Quit: fotoverite","date":"2015-12-18T07:51:13.052Z","type":"quit"}
{"nick":"drptbl","date":"2015-12-18T09:08:12.196Z","type":"join"}
{"nick":"drptbl","reason":"Ping timeout: 240 seconds","date":"2015-12-18T09:13:26.335Z","type":"quit"}
{"nick":"drptbl","date":"2015-12-18T09:17:12.156Z","type":"join"}
{"nick":"peutetre","date":"2015-12-18T10:03:15.731Z","type":"join"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T10:10:18.816Z","type":"quit"}
{"nick":"peutetre","date":"2015-12-18T10:19:00.005Z","type":"join"}
{"nick":"peutetre","reason":"Client Quit","date":"2015-12-18T10:20:08.628Z","type":"quit"}
{"nick":"peutetre","date":"2015-12-18T10:25:46.714Z","type":"join"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T10:34:51.024Z","type":"quit"}
{"nick":"peutetre","date":"2015-12-18T10:43:30.794Z","type":"join"}
{"nick":"peutetre","reason":"Client Quit","date":"2015-12-18T10:44:33.364Z","type":"quit"}
{"nick":"peutetre","date":"2015-12-18T11:00:46.595Z","type":"join"}
{"nick":"peutetre","reason":"Client Quit","date":"2015-12-18T11:01:45.333Z","type":"quit"}
{"nick":"drptbl","reason":"Ping timeout: 240 seconds","date":"2015-12-18T11:44:06.280Z","type":"quit"}
{"nick":"drptbl","date":"2015-12-18T11:47:46.373Z","type":"join"}
{"nick":"peutetre","date":"2015-12-18T12:35:39.863Z","type":"join"}
{"nick":"pfraze","date":"2015-12-18T13:13:00.986Z","type":"join"}
{"nick":"mafintosh","message":"mikolalysenko: noob question. when resizing an on-disk hash table are there any clever techniques or do you just rewrite everything from the old table to the new one?","date":"2015-12-18T13:17:50.887Z","type":"message"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-12-18T13:35:45.658Z","type":"quit"}
{"nick":"pfraze","date":"2015-12-18T13:36:09.047Z","type":"join"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-12-18T13:37:50.250Z","type":"quit"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T13:43:26.095Z","type":"quit"}
{"nick":"peutetre","date":"2015-12-18T13:52:37.347Z","type":"join"}
{"nick":"Jan____","new_nick":"jan____","date":"2015-12-18T14:01:57.175Z","type":"nick"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T14:12:42.206Z","type":"quit"}
{"nick":"pfraze","date":"2015-12-18T14:38:38.061Z","type":"join"}
{"nick":"pfraze","reason":"Ping timeout: 240 seconds","date":"2015-12-18T14:42:55.820Z","type":"quit"}
{"nick":"contrahax","date":"2015-12-18T14:48:07.818Z","type":"join"}
{"nick":"JSON_voorhees","reason":"Changing host","date":"2015-12-18T15:07:55.148Z","type":"quit"}
{"nick":"JSON_voorhees","date":"2015-12-18T15:07:55.376Z","type":"join"}
{"nick":"peutetre","date":"2015-12-18T15:18:33.814Z","type":"join"}
{"nick":"brycebaril_","date":"2015-12-18T15:22:00.134Z","type":"join"}
{"nick":"brycebaril","reason":"Ping timeout: 272 seconds","date":"2015-12-18T15:22:46.657Z","type":"quit"}
{"nick":"brycebaril_","new_nick":"brycebaril","date":"2015-12-18T15:22:47.290Z","type":"nick"}
{"nick":"mikolalysenko","message":"mafintosh: off the top of my head I've never heard of one","date":"2015-12-18T15:34:05.213Z","type":"message"}
{"nick":"mikolalysenko","message":"I guess you could replace the hash table with a trie","date":"2015-12-18T15:34:15.153Z","type":"message"}
{"nick":"mikolalysenko","message":"there is probably something out there that solves this","date":"2015-12-18T15:34:40.881Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: i was thinking about that as well","date":"2015-12-18T15:34:49.568Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: yep - haven't written anything yet so if you come across anything let me know","date":"2015-12-18T15:35:14.650Z","type":"message"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T15:35:20.797Z","type":"quit"}
{"nick":"mikolalysenko","message":"another thing you could consider is perfect hashing https://en.wikipedia.org/wiki/Dynamic_perfect_hashing","date":"2015-12-18T15:38:49.206Z","type":"message"}
{"nick":"mikolalysenko","message":"it is still amortized, but it might be a bit better for on-disk stuff","date":"2015-12-18T15:39:10.658Z","type":"message"}
{"nick":"mikolalysenko","message":"imo though a trie is simpler","date":"2015-12-18T15:40:18.311Z","type":"message"}
{"nick":"mikolalysenko","message":"but one draw back to a trie is that it would take O(hash size) number of disk seeks","date":"2015-12-18T15:40:38.354Z","type":"message"}
{"nick":"mikolalysenko","message":"which isn't great","date":"2015-12-18T15:40:44.007Z","type":"message"}
{"nick":"mikolalysenko","message":"well maybe less if the top few levels of the trie are cached","date":"2015-12-18T15:41:02.717Z","type":"message"}
{"nick":"mikolalysenko","message":"but still poor","date":"2015-12-18T15:41:11.792Z","type":"message"}
{"nick":"peutetre","date":"2015-12-18T15:50:09.830Z","type":"join"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-12-18T15:59:33.022Z","type":"quit"}
{"nick":"mafintosh","reason":"Ping timeout: 272 seconds","date":"2015-12-18T16:07:44.695Z","type":"quit"}
{"nick":"mafintosh","date":"2015-12-18T16:11:18.586Z","type":"join"}
{"nick":"therealkoopa","date":"2015-12-18T16:26:26.690Z","type":"join"}
{"nick":"pfraze","date":"2015-12-18T17:13:31.687Z","type":"join"}
{"nick":"drptbl","reason":"Quit: My MAC has gone to sleep. zZz..","date":"2015-12-18T17:14:33.161Z","type":"quit"}
{"nick":"ralphtheninja","date":"2015-12-18T17:29:04.662Z","type":"join"}
{"nick":"emilbayes","message":"mafintosh: When you told me that you'd support abstract-chunk-store in hyperdrive, so eg. S3 backend would be possible, you meant as a store for the metadata and chunks, right? Not the \"materialized\" files? Or did I misunderstand something?","date":"2015-12-18T17:42:08.611Z","type":"message"}
{"nick":"mafintosh","message":"emilbayes: for files as well","date":"2015-12-18T17:42:49.446Z","type":"message"}
{"nick":"mafintosh","message":"emilbayes: everything stored is technically blocks/chunks","date":"2015-12-18T17:43:17.199Z","type":"message"}
{"nick":"emilbayes","message":"mafintosh: Arr ok, I think I need to read the spec carefully then. I understood as the files not really \"existing\" but simply being feeds referring to chunks somewhere else","date":"2015-12-18T17:44:55.466Z","type":"message"}
{"nick":"mafintosh","message":"emilbayes: yes everything is chunks in feeds. if you think its unclear open sn issue so we can fix it :)","date":"2015-12-18T17:46:03.192Z","type":"message"}
{"nick":"emilbayes","message":"mafintosh: It's probably just me jumping to conclusions without reading carefully enough. Really want to try doing something with it, so I was thinking about trying to get a S3 backend working with leveldown. Is that too naive currently?","date":"2015-12-18T17:48:26.818Z","type":"message"}
{"nick":"mafintosh","message":"emilbayes: i thinks too low level since isnt really good for leveldb usecases. Maybe a blob store instead? Although i think that already exists","date":"2015-12-18T17:54:01.600Z","type":"message"}
{"nick":"therealkoopa","date":"2015-12-18T18:04:19.153Z","type":"quit"}
{"nick":"therealkoopa","date":"2015-12-18T18:05:58.211Z","type":"join"}
{"nick":"ogd","message":"emilbayes: s3 doesnt have sorted key iteration IIRC so a leveldown would be hard as one of the requirements is arbitrary forward/backward key range iterators on a lexicographically sorted idnex","date":"2015-12-18T18:10:26.227Z","type":"message"}
{"nick":"emilbayes","message":"ogd: Arr damn. I just thought I saw a S3 backed leweldown at some point","date":"2015-12-18T18:11:15.941Z","type":"message"}
{"nick":"ogd","message":"emilbayes: its probably possible but would be really slow hehe","date":"2015-12-18T18:11:45.552Z","type":"message"}
{"nick":"ogd","message":"emilbayes: there is an s3-blob-store though","date":"2015-12-18T18:11:52.327Z","type":"message"}
{"nick":"emilbayes","message":"ogd: I probably confused the s3-blob-store with the dynamodown... ðŸ˜…","date":"2015-12-18T18:17:04.478Z","type":"message"}
{"nick":"emilbayes","message":"ogd: I know I was thinking along the wrong lines, but the s3 list operations does return keys in lexicographical order. But it can only return 1000 keys per request, so I don't know if it's worth it. And it might get expensive quickly :p","date":"2015-12-18T18:26:33.060Z","type":"message"}
{"nick":"emilbayes","message":"*list operation","date":"2015-12-18T18:26:50.071Z","type":"message"}
{"nick":"ogd","message":"emilbayes: oh i didnt know that, nice","date":"2015-12-18T18:27:02.397Z","type":"message"}
{"nick":"ralphtheninja","reason":"Ping timeout: 256 seconds","date":"2015-12-18T18:29:48.699Z","type":"quit"}
{"nick":"sethvincent","date":"2015-12-18T18:31:22.859Z","type":"join"}
{"nick":"ralphtheninja","date":"2015-12-18T18:31:38.802Z","type":"join"}
{"nick":"phated","date":"2015-12-18T18:48:30.750Z","type":"join"}
{"nick":"sethvincent","reason":"Ping timeout: 272 seconds","date":"2015-12-18T19:04:26.458Z","type":"quit"}
{"nick":"therealkoopa","reason":"Remote host closed the connection","date":"2015-12-18T19:04:44.888Z","type":"quit"}
{"nick":"dguttman","date":"2015-12-18T19:06:35.560Z","type":"join"}
{"nick":"sethvincent","date":"2015-12-18T19:08:48.647Z","type":"join"}
{"nick":"therealkoopa","date":"2015-12-18T19:16:28.110Z","type":"join"}
{"nick":"contrahax","reason":"Quit: Sleeping","date":"2015-12-18T19:26:00.917Z","type":"quit"}
{"nick":"dguttman","reason":"Quit: dguttman","date":"2015-12-18T19:28:20.034Z","type":"quit"}
{"nick":"contrahax","date":"2015-12-18T19:46:07.634Z","type":"join"}
{"nick":"emilbayes","message":"mafintosh: Have you had issues when the seeding peer is running in the browser and the other peer is running in node? I get a \"ECONNREFUSED\" but not sure why","date":"2015-12-18T19:49:45.008Z","type":"message"}
{"nick":"freeman-lab","date":"2015-12-18T19:58:52.987Z","type":"quit"}
{"nick":"freeman-lab","date":"2015-12-18T20:00:57.882Z","type":"join"}
{"nick":"phated","reason":"Remote host closed the connection","date":"2015-12-18T20:21:41.075Z","type":"quit"}
{"nick":"sethvincent","reason":"Ping timeout: 256 seconds","date":"2015-12-18T20:32:12.645Z","type":"quit"}
{"nick":"phated","date":"2015-12-18T20:37:15.291Z","type":"join"}
{"nick":"fotoverite","date":"2015-12-18T21:18:59.993Z","type":"join"}
{"nick":"dguttman","date":"2015-12-18T21:52:55.328Z","type":"join"}
