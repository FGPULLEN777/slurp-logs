{"nick":"ircretary","reason":"Remote host closed the connection","date":"2015-10-04T00:00:01.761Z","type":"quit"}
{"nick":"ircretary","date":"2015-10-04T00:00:09.612Z","type":"join"}
{"nick":"domanic","date":"2015-10-04T00:11:03.223Z","type":"join"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-10-04T00:15:30.124Z","type":"quit"}
{"nick":"pfraze","date":"2015-10-04T00:16:51.583Z","type":"join"}
{"nick":"domanic_","date":"2015-10-04T00:22:18.293Z","type":"join"}
{"nick":"domanic","reason":"Ping timeout: 246 seconds","date":"2015-10-04T00:22:50.185Z","type":"quit"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-10-04T00:40:18.664Z","type":"quit"}
{"nick":"domanic_","reason":"Ping timeout: 256 seconds","date":"2015-10-04T00:45:46.312Z","type":"quit"}
{"nick":"substack","message":"jfhbrook: another one :/ https://github.com/jfhbrook/node-ecstatic/pull/162","date":"2015-10-04T00:56:53.387Z","type":"message"}
{"nick":"substack","message":"I should add some command-line options to the test suite","date":"2015-10-04T00:57:07.885Z","type":"message"}
{"nick":"jjjohnny","message":"substack: jfhbrook add this to ecstatic so no port colision at 8000? https://www.npmjs.com/package/answerver","date":"2015-10-04T01:21:34.307Z","type":"message"}
{"nick":"machty","reason":"Ping timeout: 240 seconds","date":"2015-10-04T01:32:07.162Z","type":"quit"}
{"nick":"owenb_____","reason":"Ping timeout: 240 seconds","date":"2015-10-04T01:32:07.338Z","type":"quit"}
{"nick":"mappum","reason":"Ping timeout: 240 seconds","date":"2015-10-04T01:34:27.110Z","type":"quit"}
{"nick":"owenb_____","date":"2015-10-04T01:35:19.262Z","type":"join"}
{"nick":"mappum","date":"2015-10-04T01:35:51.462Z","type":"join"}
{"nick":"machty","date":"2015-10-04T01:37:12.204Z","type":"join"}
{"nick":"phated","date":"2015-10-04T01:48:11.488Z","type":"join"}
{"nick":"phated","reason":"Ping timeout: 240 seconds","date":"2015-10-04T01:52:40.091Z","type":"quit"}
{"nick":"eyeforeigneye","date":"2015-10-04T02:04:22.226Z","type":"join"}
{"nick":"eyeforeigneye","reason":"Client Quit","date":"2015-10-04T02:04:33.675Z","type":"quit"}
{"nick":"stagas","reason":"Ping timeout: 240 seconds","date":"2015-10-04T03:11:47.088Z","type":"quit"}
{"nick":"juliangruber","reason":"Ping timeout: 244 seconds","date":"2015-10-04T03:19:09.326Z","type":"quit"}
{"nick":"juliangruber","date":"2015-10-04T03:19:40.650Z","type":"join"}
{"nick":"pfraze","date":"2015-10-04T03:21:55.379Z","type":"join"}
{"nick":"domanic_","date":"2015-10-04T04:06:58.908Z","type":"join"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-10-04T04:11:36.903Z","type":"quit"}
{"nick":"domanic_","reason":"Ping timeout: 246 seconds","date":"2015-10-04T04:31:32.906Z","type":"quit"}
{"nick":"djcoin","date":"2015-10-04T05:37:55.133Z","type":"join"}
{"nick":"fotoverite","reason":"Quit: fotoverite","date":"2015-10-04T07:08:44.271Z","type":"quit"}
{"nick":"fotoverite","date":"2015-10-04T07:14:38.597Z","type":"join"}
{"nick":"fotoverite","reason":"Quit: fotoverite","date":"2015-10-04T07:19:58.202Z","type":"quit"}
{"nick":"peutetre","date":"2015-10-04T08:10:43.565Z","type":"join"}
{"nick":"peutetre","reason":"Quit: ...","date":"2015-10-04T08:31:53.791Z","type":"quit"}
{"nick":"AndreasMadsen","date":"2015-10-04T08:55:29.093Z","type":"join"}
{"nick":"stagas","date":"2015-10-04T09:15:40.531Z","type":"join"}
{"nick":"AndreasMadsen","reason":"Remote host closed the connection","date":"2015-10-04T10:44:02.712Z","type":"quit"}
{"nick":"djcoin","reason":"Quit: WeeChat 1.0.1","date":"2015-10-04T10:51:26.289Z","type":"quit"}
{"nick":"joepie91","new_nick":"tumbleweeds","date":"2015-10-04T11:28:27.929Z","type":"nick"}
{"nick":"tumbleweeds","new_nick":"joepie91","date":"2015-10-04T11:28:32.768Z","type":"nick"}
{"nick":"stagas","reason":"Ping timeout: 272 seconds","date":"2015-10-04T12:11:43.475Z","type":"quit"}
{"nick":"refset","date":"2015-10-04T13:39:37.688Z","type":"join"}
{"nick":"contrahax","date":"2015-10-04T14:41:50.579Z","type":"join"}
{"nick":"contrahax","reason":"Quit: Sleeping","date":"2015-10-04T14:49:28.592Z","type":"quit"}
{"nick":"fotoverite","date":"2015-10-04T15:01:29.450Z","type":"join"}
{"nick":"stagas","date":"2015-10-04T15:20:08.320Z","type":"join"}
{"nick":"ELLIOTTCABLE","date":"2015-10-04T15:54:33.043Z","type":"join"}
{"nick":"refset","reason":"Quit: Connection closed for inactivity","date":"2015-10-04T15:55:37.598Z","type":"quit"}
{"nick":"stagas","reason":"Ping timeout: 244 seconds","date":"2015-10-04T16:47:25.317Z","type":"quit"}
{"nick":"stagas","date":"2015-10-04T16:50:37.591Z","type":"join"}
{"nick":"AndreasMadsen","date":"2015-10-04T16:54:24.131Z","type":"join"}
{"nick":"stagas","reason":"Ping timeout: 240 seconds","date":"2015-10-04T17:02:51.561Z","type":"quit"}
{"nick":"pfraze","date":"2015-10-04T17:09:47.608Z","type":"join"}
{"nick":"AndreasMadsen","date":"2015-10-04T17:25:54.631Z","type":"quit"}
{"nick":"stagas","date":"2015-10-04T17:31:56.370Z","type":"join"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-10-04T17:34:32.175Z","type":"quit"}
{"nick":"dlmanning","reason":"Ping timeout: 240 seconds","date":"2015-10-04T18:28:47.077Z","type":"quit"}
{"nick":"dlmanning","date":"2015-10-04T18:31:17.946Z","type":"join"}
{"nick":"stagas","reason":"Ping timeout: 264 seconds","date":"2015-10-04T19:26:49.388Z","type":"quit"}
{"nick":"jjjohnny_","date":"2015-10-04T19:26:58.477Z","type":"join"}
{"nick":"mollerse_","date":"2015-10-04T19:27:54.101Z","type":"join"}
{"nick":"jfhbrook_","date":"2015-10-04T19:28:19.916Z","type":"join"}
{"nick":"robertko1alski","date":"2015-10-04T19:28:41.692Z","type":"join"}
{"nick":"hij1nx","date":"2015-10-04T19:28:52.543Z","type":"join"}
{"nick":"ralphthe1inja","date":"2015-10-04T19:28:53.406Z","type":"join"}
{"nick":"greweb_","date":"2015-10-04T19:29:08.089Z","type":"join"}
{"nick":"timoxley","reason":"Ping timeout: 260 seconds","date":"2015-10-04T19:30:42.950Z","type":"quit"}
{"nick":"Tristitia","reason":"Ping timeout: 260 seconds","date":"2015-10-04T19:30:43.528Z","type":"quit"}
{"nick":"jfhbrook","reason":"Ping timeout: 260 seconds","date":"2015-10-04T19:30:43.701Z","type":"quit"}
{"nick":"timoxley","date":"2015-10-04T19:32:07.571Z","type":"join"}
{"nick":"paul_irish","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:23.463Z","type":"quit"}
{"nick":"jjjohnny","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.334Z","type":"quit"}
{"nick":"bengl","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.335Z","type":"quit"}
{"nick":"ralphtheninja","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.335Z","type":"quit"}
{"nick":"greweb","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.335Z","type":"quit"}
{"nick":"mollerse","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.858Z","type":"quit"}
{"nick":"robertkowalski","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.858Z","type":"quit"}
{"nick":"hij1nx_","reason":"Ping timeout: 240 seconds","date":"2015-10-04T19:32:24.858Z","type":"quit"}
{"nick":"bengl","date":"2015-10-04T19:32:25.796Z","type":"join"}
{"nick":"paul_irish_","date":"2015-10-04T19:32:45.243Z","type":"join"}
{"nick":"bengl","new_nick":"Guest80443","date":"2015-10-04T19:32:55.457Z","type":"nick"}
{"nick":"Tristit1a","date":"2015-10-04T19:33:44.647Z","type":"join"}
{"nick":"mollerse_","new_nick":"mollerse","date":"2015-10-04T19:40:02.680Z","type":"nick"}
{"nick":"Tristit1a","new_nick":"Tristitia","date":"2015-10-04T19:47:35.843Z","type":"nick"}
{"nick":"robertko1alski","new_nick":"robertkowalski","date":"2015-10-04T20:17:54.001Z","type":"nick"}
{"nick":"pfraze","date":"2015-10-04T20:25:03.098Z","type":"join"}
{"nick":"ralphthe1inja","new_nick":"ralphtheninja","date":"2015-10-04T20:30:23.440Z","type":"nick"}
{"nick":"pfraze","reason":"Remote host closed the connection","date":"2015-10-04T20:31:06.666Z","type":"quit"}
{"nick":"phated","date":"2015-10-04T20:44:52.297Z","type":"join"}
{"nick":"jfhbrook_","new_nick":"jfhbrook","date":"2015-10-04T21:03:21.588Z","type":"nick"}
{"nick":"phated","reason":"Remote host closed the connection","date":"2015-10-04T21:03:55.912Z","type":"quit"}
{"nick":"jjjohnny_","message":"WHOA THERE BUDDY","date":"2015-10-04T21:46:23.945Z","type":"message"}
{"nick":"pfraze","date":"2015-10-04T22:16:32.916Z","type":"join"}
{"nick":"contrahax","date":"2015-10-04T22:25:23.460Z","type":"join"}
{"nick":"stagas","date":"2015-10-04T22:25:29.378Z","type":"join"}
{"nick":"ogd","message":"https://www.irccloud.com/pastebin/Pz6u06MJ/","date":"2015-10-04T22:39:21.854Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: mafintosh and i are trying to figure out an approach to o/","date":"2015-10-04T22:39:34.016Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: i should mention also: the graph is append-only and stored on disk so we are trying to figure out a path indexing scheme we can store on disk to make these lookups fast","date":"2015-10-04T22:40:23.995Z","type":"message"}
{"nick":"mikolalysenko","message":"ogd: what operations does your dag need to support?","date":"2015-10-04T22:41:56.773Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: .put([array of parent nodes, 1 parent node, or 0 parent nodes for a new head], buffer)","date":"2015-10-04T22:42:47.609Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: and then this proposed .getPathSegments(node) that does whats in the gist","date":"2015-10-04T22:43:30.821Z","type":"message"}
{"nick":"mikolalysenko","message":"so:  create node, and link node are your two update operations","date":"2015-10-04T22:43:41.385Z","type":"message"}
{"nick":"mikolalysenko","message":"do you ever have to do cut an edge?","date":"2015-10-04T22:43:51.641Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: whats that mean?","date":"2015-10-04T22:44:06.270Z","type":"message"}
{"nick":"mikolalysenko","message":"like a -> b at time 0, then later on you cut the graph so a and b are not connected directly","date":"2015-10-04T22:44:27.092Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: no the graph is append only","date":"2015-10-04T22:44:43.981Z","type":"message"}
{"nick":"mikolalysenko","message":"ok, so this is an incremental problem","date":"2015-10-04T22:45:53.173Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: yes","date":"2015-10-04T22:45:58.746Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: yea we wanna avoid traversals on get/put","date":"2015-10-04T22:46:16.094Z","type":"message"}
{"nick":"mikolalysenko","message":"right","date":"2015-10-04T22:46:23.396Z","type":"message"}
{"nick":"freeman-lab","date":"2015-10-04T22:46:23.711Z","type":"join"}
{"nick":"mikolalysenko","message":"so one screwy way to do this is you could use demaine's functional link cut tree data structure","date":"2015-10-04T22:47:50.365Z","type":"message"}
{"nick":"mikolalysenko","message":"but that has some drawbacks","date":"2015-10-04T22:47:53.478Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: we need a way to find all the paths from a given node to any root reachable from that node (and we want to have the paths deduplicated if that makes sense)","date":"2015-10-04T22:48:01.386Z","type":"message"}
{"nick":"mikolalysenko","message":"like you can only have a finite number of iterators into the tree at any given moment","date":"2015-10-04T22:48:10.031Z","type":"message"}
{"nick":"mikolalysenko","message":"mafintosh: there could be an exponential number of such paths though","date":"2015-10-04T22:48:55.683Z","type":"message"}
{"nick":"mikolalysenko","message":"think about a sequence of diamonds:","date":"2015-10-04T22:50:17.789Z","type":"message"}
{"nick":"mikolalysenko","message":"/\\","date":"2015-10-04T22:50:17.964Z","type":"message"}
{"nick":"mikolalysenko","message":"\\/","date":"2015-10-04T22:50:17.964Z","type":"message"}
{"nick":"mikolalysenko","message":"/\\","date":"2015-10-04T22:50:17.964Z","type":"message"}
{"nick":"mikolalysenko","message":"\\/","date":"2015-10-04T22:50:17.964Z","type":"message"}
{"nick":"mikolalysenko","message":"...","date":"2015-10-04T22:50:18.366Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: i should correct my self - we only needs as many paths needed to cover all nodes in the subtree","date":"2015-10-04T22:50:19.858Z","type":"message"}
{"nick":"mikolalysenko","message":"mafintosh: why not just report the whole subgraph?","date":"2015-10-04T22:51:21.451Z","type":"message"}
{"nick":"mikolalysenko","message":"you could do that in linear time in the size of the result by just doing a boring old bfs traversal","date":"2015-10-04T22:52:14.813Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: yes but is there a good way to index that?","date":"2015-10-04T22:53:33.029Z","type":"message"}
{"nick":"contrahax","reason":"Ping timeout: 250 seconds","date":"2015-10-04T22:53:39.364Z","type":"quit"}
{"nick":"mikolalysenko","message":"that is basically optimal","date":"2015-10-04T22:53:44.765Z","type":"message"}
{"nick":"mikolalysenko","message":"if you have an output of size O(n), you can't process it faster than O(n)","date":"2015-10-04T22:53:57.741Z","type":"message"}
{"nick":"mikolalysenko","message":"unless you return references or evaluate it lazily","date":"2015-10-04T22:54:09.108Z","type":"message"}
{"nick":"mikolalysenko","message":"then you can amortize a bit by streaming, but that is it","date":"2015-10-04T22:54:18.166Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: but can we index that on insert time somehow?","date":"2015-10-04T22:54:30.938Z","type":"message"}
{"nick":"mikolalysenko","message":"wouldn't matter","date":"2015-10-04T22:54:43.933Z","type":"message"}
{"nick":"mikolalysenko","message":"even if you indexed it, just reading out the index would take as long","date":"2015-10-04T22:54:54.287Z","type":"message"}
{"nick":"mafintosh","message":"i'm not sure i follow :)","date":"2015-10-04T22:55:37.899Z","type":"message"}
{"nick":"mikolalysenko","message":"I can write some psuedo code","date":"2015-10-04T22:55:58.595Z","type":"message"}
{"nick":"mikolalysenko","message":"but before I do that, can you answer me a question:","date":"2015-10-04T22:56:09.657Z","type":"message"}
{"nick":"mikolalysenko","message":"what do you do in the diamond path case?","date":"2015-10-04T22:56:15.097Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: yes 2 sec - let me gist it","date":"2015-10-04T22:56:29.664Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: https://gist.github.com/mafintosh/5357d2c64d4bb918878f","date":"2015-10-04T22:58:23.397Z","type":"message"}
{"nick":"stagas","reason":"Read error: Connection reset by peer","date":"2015-10-04T22:58:32.688Z","type":"quit"}
{"nick":"stagas","date":"2015-10-04T22:58:44.438Z","type":"join"}
{"nick":"mikolalysenko","message":"mafintosh: but fc isn't a path","date":"2015-10-04T22:58:47.070Z","type":"message"}
{"nick":"mikolalysenko","message":"you could do acdfg maybe","date":"2015-10-04T22:59:13.906Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: thats what i meant by \"deduplicated\" path","date":"2015-10-04T22:59:39.834Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: i'm not sure i know the right terminology","date":"2015-10-04T22:59:57.776Z","type":"message"}
{"nick":"mikolalysenko","message":"hmm","date":"2015-10-04T23:00:12.655Z","type":"message"}
{"nick":"mikolalysenko","message":"what about this:  maybe you want to decompose the dag rooted at a into a collection of paths where the length of each path is as long as possible","date":"2015-10-04T23:00:48.998Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: so in that graph the two paths, abdeg and acdfg would cover all nodes","date":"2015-10-04T23:00:59.787Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: yea that sounds accurate","date":"2015-10-04T23:01:22.096Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: but i only writes nodes once to a path","date":"2015-10-04T23:01:30.093Z","type":"message"}
{"nick":"contrahax","date":"2015-10-04T23:01:34.125Z","type":"join"}
{"nick":"stagas","reason":"Client Quit","date":"2015-10-04T23:01:41.313Z","type":"quit"}
{"nick":"ogd","message":"mikolalysenko: we want to make the graph into a series of paths, but we wont need to be able to do graph queries against the output","date":"2015-10-04T23:01:50.258Z","type":"message"}
{"nick":"stagas","date":"2015-10-04T23:01:55.375Z","type":"join"}
{"nick":"mikolalysenko","message":"well, why bother with paths then.  why not just write all the nodes?","date":"2015-10-04T23:01:56.896Z","type":"message"}
{"nick":"ogd","message":"s/make/decompose","date":"2015-10-04T23:01:58.022Z","type":"message"}
{"nick":"mikolalysenko","message":"or how about this:  maybe you want to cover the dag rooted at a with a tree?","date":"2015-10-04T23:03:21.156Z","type":"message"}
{"nick":"stagas","reason":"Read error: Connection reset by peer","date":"2015-10-04T23:03:25.420Z","type":"quit"}
{"nick":"mikolalysenko","message":"and then take that tree and compute a heavy-light decomposition","date":"2015-10-04T23:03:32.642Z","type":"message"}
{"nick":"stagas","date":"2015-10-04T23:03:35.407Z","type":"join"}
{"nick":"phated","date":"2015-10-04T23:04:24.255Z","type":"join"}
{"nick":"ogd","message":"mikolalysenko: ah this is cool https://en.wikipedia.org/wiki/Heavy_path_decomposition","date":"2015-10-04T23:04:56.777Z","type":"message"}
{"nick":"mikolalysenko","message":"yeah, but it only works for trees","date":"2015-10-04T23:05:14.664Z","type":"message"}
{"nick":"mikolalysenko","message":"though you could tree-ify this dag and then run heavy-light on the result","date":"2015-10-04T23:05:33.548Z","type":"message"}
{"nick":"mikolalysenko","message":"(or at least I've never heard of a way to do heavy-light decomposition on a dag)","date":"2015-10-04T23:05:54.280Z","type":"message"}
{"nick":"ogd","message":"treeifying would just involve denormalizing (for lack of a better word) all subtrees?","date":"2015-10-04T23:06:15.332Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: i wanna get  the \"paths\" to be able to perform a binary search on each path against another dag to figure out which nodes they share","date":"2015-10-04T23:06:15.605Z","type":"message"}
{"nick":"ogd","message":"subgraphs*","date":"2015-10-04T23:06:19.187Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: because our dag is a merkle dag we know that if you have a node on a path you'll have everything before that node as well","date":"2015-10-04T23:06:54.783Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: so fx in the diamond gist graph if you have d we know you have abc also","date":"2015-10-04T23:07:22.465Z","type":"message"}
{"nick":"ogd","message":"the binary search is to find the latest common ancestor node","date":"2015-10-04T23:07:37.682Z","type":"message"}
{"nick":"ogd","message":"latest/most recent","date":"2015-10-04T23:07:44.443Z","type":"message"}
{"nick":"mikolalysenko","message":"ok, so you want to diff two dags quickly?","date":"2015-10-04T23:08:49.952Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: thats what we end up doing","date":"2015-10-04T23:09:05.329Z","type":"message"}
{"nick":"phated","reason":"Ping timeout: 246 seconds","date":"2015-10-04T23:09:05.897Z","type":"quit"}
{"nick":"mafintosh","message":"mikolalysenko: after we have the paths","date":"2015-10-04T23:09:18.953Z","type":"message"}
{"nick":"mikolalysenko","message":"hmm","date":"2015-10-04T23:11:08.828Z","type":"message"}
{"nick":"mikolalysenko","message":"I don't quite get why they need to be paths","date":"2015-10-04T23:11:15.747Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: the network api between the two graphs is: do you have these nodes [array of nodes]. other side responds by telling you which of the nodes it has","date":"2015-10-04T23:11:20.376Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: the paths just give us an order we can use in our binary search to find the common ancestor","date":"2015-10-04T23:13:11.323Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: but if the nodes were ordered in some other way that would work too i guess","date":"2015-10-04T23:13:21.957Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: so we can do it in log(n) network roundtrips","date":"2015-10-04T23:13:33.854Z","type":"message"}
{"nick":"mikolalysenko","message":"hmm","date":"2015-10-04T23:13:54.182Z","type":"message"}
{"nick":"mikolalysenko","message":"how does lca help here?","date":"2015-10-04T23:14:00.727Z","type":"message"}
{"nick":"mikolalysenko","message":"or what is the lca computing?","date":"2015-10-04T23:14:12.287Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: then we know everything thats in common between the graphs since its a merkle graph and all nodes older than lca are already in sync","date":"2015-10-04T23:14:32.569Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: then we can just request the data for all nodes after that point","date":"2015-10-04T23:14:45.200Z","type":"message"}
{"nick":"mikolalysenko","message":"ok","date":"2015-10-04T23:14:58.187Z","type":"message"}
{"nick":"mikolalysenko","message":"so I've been reading about communication complexity lately, but it seems to me that this problem is at least as hard as solving disjointness","date":"2015-10-04T23:19:08.525Z","type":"message"}
{"nick":"mikolalysenko","message":"or basically you are computing the set difference of two sets of nodes","date":"2015-10-04T23:19:20.443Z","type":"message"}
{"nick":"ogd","message":"brb this cafe is closing","date":"2015-10-04T23:19:45.091Z","type":"message"}
{"nick":"mikolalysenko","message":"it doesn't seem like the fact that the nodes are in a dag helps much, since at least in theory you could get  a bunch of nodes with a common parent","date":"2015-10-04T23:19:49.747Z","type":"message"}
{"nick":"stagas","reason":"Ping timeout: 250 seconds","date":"2015-10-04T23:20:05.364Z","type":"quit"}
{"nick":"mikolalysenko","message":"I'm not sure what the multiround complexity of disjointness is, but I do know that in 1 round the best you can do is transmit the whole set or all O(n) nodes","date":"2015-10-04T23:20:22.105Z","type":"message"}
{"nick":"mikolalysenko","message":"and I think this also holds for multiple rounds, even probabilistically","date":"2015-10-04T23:22:08.684Z","type":"message"}
{"nick":"mikolalysenko","message":"what is less clear to me is how you can do it in less than O(n) bits, even using multiple rounds","date":"2015-10-04T23:24:27.082Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: ok back on wifi","date":"2015-10-04T23:34:32.363Z","type":"message"}
{"nick":"mikolalysenko","message":"so, I guess what I am saying first is that I don't get how it being a dag helps much.  what if you have one node with a ton of children?","date":"2015-10-04T23:35:49.605Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: our use case is kinda like the linux kernel git repo","date":"2015-10-04T23:36:08.214Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: we have a bunch of nodes in a dag, at any time you might create new branches in the dag, when you push or pull with someone we want to establish which parts of the dag are already replicated so we can skip them and only send the new stuff","date":"2015-10-04T23:36:45.385Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: its not very common that someone would create a million new branches, but they might have a million nodes in 1 new branch","date":"2015-10-04T23:37:08.552Z","type":"message"}
{"nick":"contrahax","reason":"Quit: Sleeping","date":"2015-10-04T23:37:53.029Z","type":"quit"}
{"nick":"mikolalysenko","message":"how does git do this?","date":"2015-10-04T23:40:27.249Z","type":"message"}
{"nick":"mikolalysenko","message":"do you just send a timestamp or something, and then the server sends you everything after that time?","date":"2015-10-04T23:40:49.729Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: mafintosh' current approach is to store a bunch of what he calls 'deduplicated paths' which means taking a dag and representing it as a bunch of paths, where each vertex is only a member of a single path. that way we can binary search each path to figure out if theres a point in that path that is already in sync. once we find the last node in","date":"2015-10-04T23:41:05.692Z","type":"message"}
{"nick":"ogd","message":"a path that exists on the other side we know all nodes before that path are in sync. then we can request the data for the nodes that are missing","date":"2015-10-04T23:41:05.866Z","type":"message"}
{"nick":"mikolalysenko","message":"hmm","date":"2015-10-04T23:47:42.687Z","type":"message"}
{"nick":"mikolalysenko","message":"I think I could construct the paths, but I'm still not quite sure how this speeds things up","date":"2015-10-04T23:48:02.785Z","type":"message"}
{"nick":"mikolalysenko","message":"as a sketch of how you could build this, you could just keep iteratively removing the longest path from the dag until you are done","date":"2015-10-04T23:50:01.601Z","type":"message"}
{"nick":"mikolalysenko","message":"and because it is a dag, you can do that in linear time","date":"2015-10-04T23:50:08.340Z","type":"message"}
{"nick":"mafintosh","message":"mikolalysenko: yea thats basically what we're doing now","date":"2015-10-04T23:50:47.294Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: our problem is basically: given two graphs that no nothing about each other, how do you figure out what nodes in graph A are missing from graph B. minimizing for number of round trips, and allowing for new nodes to be appended without expensive traversals on each insert","date":"2015-10-04T23:52:06.742Z","type":"message"}
{"nick":"ogd","message":"know nothing*","date":"2015-10-04T23:52:15.968Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: so the 'deduplicated path' thing is just a construct that gives us a range to binary search against","date":"2015-10-04T23:52:59.821Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: so that we know by searching all paths taht we cover 100% of the graph","date":"2015-10-04T23:53:16.583Z","type":"message"}
{"nick":"ogd","message":"mikolalysenko: a more trivial implementation to solve the same problem would be to start by asking the remote graph for all its latest nodes (heads), including the list of parent nodes for that node. you check if you have those nodes and their parents, for any node that is missing you repeat until you have all nodes. this works but is a lot of round trips","date":"2015-10-04T23:58:31.888Z","type":"message"}
{"nick":"ogd","message":"(by 'parent nodes' above i mean direct parents, not all ancestors)","date":"2015-10-04T23:59:19.561Z","type":"message"}
