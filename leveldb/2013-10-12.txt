{"nick":"mikeal","date":"2013-10-12T00:09:21.122Z","type":"join"}
{"nick":"wolfeidau","date":"2013-10-12T00:10:27.112Z","type":"join"}
{"nick":"wolfeida_","date":"2013-10-12T00:11:34.952Z","type":"join"}
{"nick":"wolfeidau","reason":"Ping timeout: 265 seconds","date":"2013-10-12T00:15:29.944Z","type":"quit"}
{"nick":"mikeal","reason":"Ping timeout: 272 seconds","date":"2013-10-12T00:19:27.820Z","type":"quit"}
{"nick":"wolfeida_","reason":"Remote host closed the connection","date":"2013-10-12T00:32:50.814Z","type":"quit"}
{"nick":"wolfeida_","date":"2013-10-12T00:35:22.034Z","type":"join"}
{"nick":"brycebaril","message":"rvagg: is there any way to know if {sync: true} is working? In my batch load testing I can't really see a difference.","date":"2013-10-12T00:44:12.824Z","type":"message"}
{"nick":"brycebaril","message":"mostly I'm trying to figure out a way to signal backpressure to a writeStream wrapper. I think what I need now is some way to signal back-pressure upstream","date":"2013-10-12T00:46:41.540Z","type":"message"}
{"nick":"brycebaril","message":"If I avoid objectMode streams & key/value encoding logic with pure binary (multibuffer) streams, I can significantly cut the memory & time, but it appears to hit a point where I'm still ending up queing most/all of it into memory","date":"2013-10-12T00:49:19.504Z","type":"message"}
{"nick":"julianduque","reason":"Ping timeout: 246 seconds","date":"2013-10-12T00:49:31.902Z","type":"quit"}
{"nick":"levelbot","message":"[npm] level-assoc@0.13.0 <http://npm.im/level-assoc>: relational foreign key associations (hasMany, belongsTo) for leveldb (@substack)","date":"2013-10-12T00:49:41.569Z","type":"message"}
{"nick":"substack","message":"row.blah({ limit: n }) works yay","date":"2013-10-12T00:52:22.719Z","type":"message"}
{"nick":"thlorenz","date":"2013-10-12T00:52:39.407Z","type":"join"}
{"nick":"brycebaril","message":"I'll try a manual throttle to see if that helps for now, but it would be nice if there was something exposed in the LevelDB api that correlated with write task readiness (or LOG->table pending work)","date":"2013-10-12T00:53:04.879Z","type":"message"}
{"nick":"thlorenz","reason":"Ping timeout: 245 seconds","date":"2013-10-12T00:56:51.259Z","type":"quit"}
{"nick":"fb55","date":"2013-10-12T01:03:57.413Z","type":"join"}
{"nick":"fb55","reason":"Remote host closed the connection","date":"2013-10-12T01:04:22.039Z","type":"quit"}
{"nick":"fb55","date":"2013-10-12T01:04:48.503Z","type":"join"}
{"nick":"fb55","reason":"Ping timeout: 246 seconds","date":"2013-10-12T01:09:28.982Z","type":"quit"}
{"nick":"mikeal","date":"2013-10-12T01:15:44.939Z","type":"join"}
{"nick":"wolfeida_","reason":"Remote host closed the connection","date":"2013-10-12T01:18:12.663Z","type":"quit"}
{"nick":"mikeal","reason":"Ping timeout: 272 seconds","date":"2013-10-12T01:20:37.741Z","type":"quit"}
{"nick":"brycebaril","message":"rvagg: Hmm... well, duh -- for bulk loading {sync: true} wouldn't matter. Is there anyway to expose a sync batch that *does* behave synchronously WRT Node?","date":"2013-10-12T01:29:07.547Z","type":"message"}
{"nick":"zz_eugeneware","new_nick":"eugeneware","date":"2013-10-12T01:30:28.694Z","type":"nick"}
{"nick":"rvagg","message":"brycebaril: in terms of blocking behaviour you *could* expose a synchronous/blocking batch, but we're not going to do that; ideally the callback should be all you need but what I'm hearing is that it isn't for this bulk load situation","date":"2013-10-12T01:35:46.757Z","type":"message"}
{"nick":"rvagg","message":"it would be lovely to have an event system for leveldb that gave us insight into compactions and other internal behaviours","date":"2013-10-12T01:37:58.720Z","type":"message"}
{"nick":"rvagg","message":"not impossible but it would mean properly digging in to the guts of leveldb to expose it, which isn't very friendly for an upgrade path","date":"2013-10-12T01:38:19.927Z","type":"message"}
{"nick":"rvagg","message":"... but it would be interesting!","date":"2013-10-12T01:38:24.830Z","type":"message"}
{"nick":"wolfeidau","date":"2013-10-12T01:41:15.241Z","type":"join"}
{"nick":"esundahl","date":"2013-10-12T01:41:45.002Z","type":"join"}
{"nick":"wolfeidau","reason":"Remote host closed the connection","date":"2013-10-12T01:46:52.426Z","type":"quit"}
{"nick":"wolfeidau","date":"2013-10-12T01:47:24.429Z","type":"join"}
{"nick":"rud","date":"2013-10-12T01:49:15.279Z","type":"join"}
{"nick":"thlorenz","date":"2013-10-12T01:49:38.608Z","type":"join"}
{"nick":"rvagg","message":"I'm thinking that we should perhaps make our own Log implementation that can be plugged in to and streamed so you can watch progress and/or pipe it to an actual log somewhere if you like","date":"2013-10-12T01:49:51.081Z","type":"message"}
{"nick":"wolfeidau","reason":"Ping timeout: 272 seconds","date":"2013-10-12T01:52:17.731Z","type":"quit"}
{"nick":"rud","reason":"Quit: rud","date":"2013-10-12T02:04:06.827Z","type":"quit"}
{"nick":"nathan7","message":"rvagg: does LevelDB have any dtraceness?","date":"2013-10-12T02:51:00.379Z","type":"message"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-10-12T02:53:40.152Z","type":"quit"}
{"nick":"ogd","message":"rvagg: from what i can tell compaction is important for bulk loading stuff but theres no visibility into what the compaction state is","date":"2013-10-12T02:54:00.761Z","type":"message"}
{"nick":"ogd","message":"rvagg: the callback for a batch fires and compaction might still be happening","date":"2013-10-12T02:54:23.135Z","type":"message"}
{"nick":"ogd","message":"rvagg: but i think its only an issue if you are writing too much data","date":"2013-10-12T02:55:27.321Z","type":"message"}
{"nick":"ogd","message":"so i guess the answer is to not write too much data","date":"2013-10-12T02:56:38.762Z","type":"message"}
{"nick":"ogd","message":"i'm still interested to see someone test out that multiple leveldbs for writing that get combined later idea","date":"2013-10-12T02:57:06.655Z","type":"message"}
{"nick":"ramitos","date":"2013-10-12T02:57:55.769Z","type":"join"}
{"nick":"nnnnathann","reason":"Ping timeout: 245 seconds","date":"2013-10-12T03:06:01.182Z","type":"quit"}
{"nick":"ramitos","reason":"Quit: Computer has gone to sleep.","date":"2013-10-12T03:12:31.051Z","type":"quit"}
{"nick":"ramitos","date":"2013-10-12T03:14:16.221Z","type":"join"}
{"nick":"thlorenz","date":"2013-10-12T03:24:49.639Z","type":"join"}
{"nick":"ramitos","reason":"Quit: Textual IRC Client: www.textualapp.com","date":"2013-10-12T03:30:13.910Z","type":"quit"}
{"nick":"thlorenz","reason":"Ping timeout: 240 seconds","date":"2013-10-12T03:32:48.202Z","type":"quit"}
{"nick":"jcrugzz","date":"2013-10-12T03:38:03.182Z","type":"join"}
{"nick":"dominictarr","date":"2013-10-12T03:45:23.900Z","type":"join"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-10-12T03:51:34.596Z","type":"quit"}
{"nick":"timoxley","date":"2013-10-12T03:52:08.788Z","type":"join"}
{"nick":"juliangruber","message":"substack: sweet","date":"2013-10-12T03:52:22.262Z","type":"message"}
{"nick":"jcrugzz","reason":"Ping timeout: 246 seconds","date":"2013-10-12T04:18:49.882Z","type":"quit"}
{"nick":"thlorenz","date":"2013-10-12T04:29:43.984Z","type":"join"}
{"nick":"thlorenz","reason":"Ping timeout: 272 seconds","date":"2013-10-12T04:34:25.727Z","type":"quit"}
{"nick":"rvagg","message":"ogd: https://github.com/rvagg/node-leveldown/pull/67","date":"2013-10-12T04:49:07.833Z","type":"message"}
{"nick":"jxson","reason":"Remote host closed the connection","date":"2013-10-12T04:59:11.127Z","type":"quit"}
{"nick":"ogd","message":"rvagg: nice","date":"2013-10-12T05:04:22.205Z","type":"message"}
{"nick":"brycebaril","message":"rvagg: awesome, I'll take a look. Yeah, I don't think the bulk load situation needs much, just some way of propogating backpressure. The issue is with the async callbacks there is nothing to tell upstream to pause","date":"2013-10-12T05:12:45.516Z","type":"message"}
{"nick":"rvagg","message":"yeah.. using log data for anything useful would be pretty hacky; but the info is interesting and educational nonetheless","date":"2013-10-12T05:15:52.683Z","type":"message"}
{"nick":"brycebaril","message":"rvagg: what about deferring the batch callback until the sync was done if {sync: true}? That way the api doesn't change, just timing if they request synchronous writes?","date":"2013-10-12T05:45:13.953Z","type":"message"}
{"nick":"rvagg","message":"brycebaril: that's the way it should happen","date":"2013-10-12T05:45:30.106Z","type":"message"}
{"nick":"esundahl","reason":"Remote host closed the connection","date":"2013-10-12T05:47:31.385Z","type":"quit"}
{"nick":"brycebaril","message":"Oh? Hmm, lemme see if I can see a timing difference between batches with sync true or false. Maybe it is something else.","date":"2013-10-12T05:47:44.994Z","type":"message"}
{"nick":"levelbot","message":"[npm] memdown@0.4.0 <http://npm.im/memdown>: An drop-in replacement for LevelDOWN that works in memory only (@rvagg)","date":"2013-10-12T05:48:39.991Z","type":"message"}
{"nick":"mikeal","date":"2013-10-12T05:50:02.718Z","type":"join"}
{"nick":"brycebaril","message":"I'm still trying to figure out what is taking up heapspace memory in my bulk loader. So if buffers mostly live outside heap, any idea what the heap memory component looks like for them?","date":"2013-10-12T05:50:06.495Z","type":"message"}
{"nick":"levelbot","message":"[npm] memdown@0.4.1 <http://npm.im/memdown>: An drop-in replacement for LevelDOWN that works in memory only (@rvagg)","date":"2013-10-12T05:53:40.055Z","type":"message"}
{"nick":"rvagg","message":"join #libuv and bother trevnorris","date":"2013-10-12T05:59:09.238Z","type":"message"}
{"nick":"ogd","message":"hmm something im doing in dat is slowing reads down to 7k/s whereas i get ~100k/s with normal levelup... need to investigate","date":"2013-10-12T05:59:23.146Z","type":"message"}
{"nick":"rvagg","message":"actually, trevnorris is in here","date":"2013-10-12T05:59:29.627Z","type":"message"}
{"nick":"levelbot","message":"[npm] level-packager@0.17.0-2 <http://npm.im/level-packager>: LevelUP package helper for distributing with a LevelDOWN-compatible back-end (@rvagg)","date":"2013-10-12T06:05:10.729Z","type":"message"}
{"nick":"levelbot","message":"[npm] level-mem@0.17.0 <http://npm.im/level-mem>: A convenience package bundling LevelUP & MemDOWN (@rvagg)","date":"2013-10-12T06:07:39.909Z","type":"message"}
{"nick":"eugeneware","new_nick":"zz_eugeneware","date":"2013-10-12T06:09:11.269Z","type":"nick"}
{"nick":"brycebaril","message":"Yeah, I get the same mean/median timing for batches if sync is true or false","date":"2013-10-12T06:19:54.263Z","type":"message"}
{"nick":"rvagg","message":"that's odd","date":"2013-10-12T06:22:46.013Z","type":"message"}
{"nick":"rvagg","message":"chained batch or array batch?","date":"2013-10-12T06:23:04.236Z","type":"message"}
{"nick":"brycebaril","message":"array","date":"2013-10-12T06:23:20.542Z","type":"message"}
{"nick":"rvagg","message":"I'll double-check that sync is getting properly passed down to leveldb when I have time later tonight, it's impossible to unit test for unfortunately","date":"2013-10-12T06:24:30.055Z","type":"message"}
{"nick":"rvagg","message":"can't mock out kernel fs writes unfortunately!","date":"2013-10-12T06:24:56.228Z","type":"message"}
{"nick":"brycebaril","message":"I'm still getting 28k records per second, which isn't bad by any means","date":"2013-10-12T06:28:07.117Z","type":"message"}
{"nick":"brycebaril","message":"Apparently memwatch heapdump on a 700+ meg heapspace isn't a good idea","date":"2013-10-12T06:29:33.978Z","type":"message"}
{"nick":"brycebaril","message":"22449 bryce     20   0 11.6g 6.5g  788 R   26 84.2   5:29.16 node","date":"2013-10-12T06:29:44.578Z","type":"message"}
{"nick":"brycebaril","message":"ok, solved my memory problem","date":"2013-10-12T06:45:26.423Z","type":"message"}
{"nick":"brycebaril","message":"array batch = bad for memory","date":"2013-10-12T06:45:41.285Z","type":"message"}
{"nick":"brycebaril","message":"rvagg: memory use for standard levelup rs.pipe(ws) for a 5 million record database: (1994.csv that ogd uses): 1364895432","date":"2013-10-12T06:47:43.232Z","type":"message"}
{"nick":"brycebaril","message":"using the buffers-only read/write streams I'm working on: 13701672","date":"2013-10-12T06:48:06.116Z","type":"message"}
{"nick":"brycebaril","message":"those are JS heap space","date":"2013-10-12T06:48:12.091Z","type":"message"}
{"nick":"brycebaril","message":"rss 3_153_367_040 vs 554_786_816","date":"2013-10-12T06:49:01.294Z","type":"message"}
{"nick":"brycebaril","message":"timing 257s -> 182s","date":"2013-10-12T06:50:24.175Z","type":"message"}
{"nick":"rvagg","message":"this is why writestream has to go, it's a bikeshed","date":"2013-10-12T06:58:31.622Z","type":"message"}
{"nick":"brycebaril","message":"I'm over worrying about keeping it in the core. I'll still use some sort of writeStream interface, but I know what I'm doing.","date":"2013-10-12T07:02:52.515Z","type":"message"}
{"nick":"brycebaril","message":"If someone with a big level instance takes the README's advice about making a copy() function they are guaranteed to have a bad experience. That's probably reason enough to pull it.","date":"2013-10-12T07:03:38.552Z","type":"message"}
{"nick":"rvagg","message":"in fact there's a .copy() exported on LevelUP that probably shouldn't be there","date":"2013-10-12T07:06:34.801Z","type":"message"}
{"nick":"rvagg","message":"see latest comment on #199","date":"2013-10-12T07:06:57.603Z","type":"message"}
{"nick":"brycebaril","message":"I'm assuming by bikeshed you mean that any given developer/application is going to see a different need for writeStream that needs a completely different implementation? If so, I completely agree.","date":"2013-10-12T07:07:29.618Z","type":"message"}
{"nick":"wolfeidau","date":"2013-10-12T07:15:09.470Z","type":"join"}
{"nick":"zz_eugeneware","new_nick":"eugeneware","date":"2013-10-12T07:16:03.723Z","type":"nick"}
{"nick":"eugeneware","new_nick":"zz_eugeneware","date":"2013-10-12T07:33:15.996Z","type":"nick"}
{"nick":"fb55","date":"2013-10-12T08:46:03.064Z","type":"join"}
{"nick":"dominictarr","date":"2013-10-12T08:46:07.754Z","type":"join"}
{"nick":"levelbot","message":"[npm] level-ws@0.0.0 <http://npm.im/level-ws>: A basic WriteStream implementation for LevelUP (@rvagg)","date":"2013-10-12T09:07:41.222Z","type":"message"}
{"nick":"fb55","reason":"Remote host closed the connection","date":"2013-10-12T09:07:58.044Z","type":"quit"}
{"nick":"fb55","date":"2013-10-12T09:08:25.110Z","type":"join"}
{"nick":"fb55","reason":"Ping timeout: 246 seconds","date":"2013-10-12T09:12:49.897Z","type":"quit"}
{"nick":"levelbot","message":"[npm] level-packager@0.17.0-3 <http://npm.im/level-packager>: LevelUP package helper for distributing with a LevelDOWN-compatible back-end (@rvagg)","date":"2013-10-12T09:17:40.074Z","type":"message"}
{"nick":"thlorenz","date":"2013-10-12T09:32:53.051Z","type":"join"}
{"nick":"levelbot","message":"[npm] level-packager@0.17.0-4 <http://npm.im/level-packager>: LevelUP package helper for distributing with a LevelDOWN-compatible back-end (@rvagg)","date":"2013-10-12T09:33:41.223Z","type":"message"}
{"nick":"pgte","date":"2013-10-12T09:35:56.517Z","type":"join"}
{"nick":"thlorenz","reason":"Ping timeout: 264 seconds","date":"2013-10-12T09:37:26.752Z","type":"quit"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-10-12T09:38:47.532Z","type":"quit"}
{"nick":"rvagg","message":"FYI anyone not following #199 (remove WriteStream) https://github.com/rvagg/node-levelup/issues/199#issuecomment-26194464","date":"2013-10-12T09:44:46.958Z","type":"message"}
{"nick":"fb55","date":"2013-10-12T09:51:03.756Z","type":"join"}
{"nick":"pgte","reason":"Remote host closed the connection","date":"2013-10-12T09:56:39.938Z","type":"quit"}
{"nick":"pgte","date":"2013-10-12T09:57:11.604Z","type":"join"}
{"nick":"pgte","reason":"Ping timeout: 265 seconds","date":"2013-10-12T10:01:47.588Z","type":"quit"}
{"nick":"zz_eugeneware","new_nick":"eugeneware","date":"2013-10-12T10:16:03.504Z","type":"nick"}
{"nick":"fb55","reason":"Ping timeout: 240 seconds","date":"2013-10-12T10:17:02.543Z","type":"quit"}
{"nick":"fb55","date":"2013-10-12T10:24:53.909Z","type":"join"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-10-12T11:55:23.441Z","type":"quit"}
{"nick":"dominictarr","date":"2013-10-12T11:56:52.075Z","type":"join"}
{"nick":"dominictarr","reason":"Client Quit","date":"2013-10-12T11:58:18.006Z","type":"quit"}
{"nick":"eugeneware","new_nick":"zz_eugeneware","date":"2013-10-12T11:59:28.286Z","type":"nick"}
{"nick":"thlorenz","date":"2013-10-12T12:19:46.947Z","type":"join"}
{"nick":"jez0990","reason":"Remote host closed the connection","date":"2013-10-12T12:22:09.582Z","type":"quit"}
{"nick":"jez0990","date":"2013-10-12T12:24:57.556Z","type":"join"}
{"nick":"thlorenz","reason":"Ping timeout: 272 seconds","date":"2013-10-12T12:25:37.746Z","type":"quit"}
{"nick":"jez0990","reason":"Read error: Connection reset by peer","date":"2013-10-12T12:28:54.005Z","type":"quit"}
{"nick":"dominictarr","date":"2013-10-12T12:28:55.215Z","type":"join"}
{"nick":"carolyns","new_nick":"foxcat","date":"2013-10-12T12:31:53.056Z","type":"nick"}
{"nick":"dominictarr","message":"rvagg: hey, did you document your setup for your nexus7/rpi thing?","date":"2013-10-12T12:31:53.968Z","type":"message"}
{"nick":"foxcat","date":"2013-10-12T12:32:13.990Z","type":"part"}
{"nick":"hij1nx","message":"i noticed that goatdb has migrated to australia...","date":"2013-10-12T12:35:19.545Z","type":"message"}
{"nick":"rvagg","message":"dominictarr: no, no documentation, typical linux hackety hack","date":"2013-10-12T12:40:09.758Z","type":"message"}
{"nick":"rvagg","message":"dominictarr: if you need it I guess I can","date":"2013-10-12T12:40:29.444Z","type":"message"}
{"nick":"rvagg","message":"hij1nx: where is it?","date":"2013-10-12T12:41:00.045Z","type":"message"}
{"nick":"dominictarr","message":"rvagg: main question: did you use a seprate router? how do you get the rpi to connect to the right network?","date":"2013-10-12T12:41:08.259Z","type":"message"}
{"nick":"rvagg","message":"dominictarr: linux wifi tools","date":"2013-10-12T12:41:26.626Z","type":"message"}
{"nick":"rvagg","message":"dominictarr: pi has a wifi dongle and a bluetooth dongle","date":"2013-10-12T12:41:36.874Z","type":"message"}
{"nick":"rvagg","message":"the bluetooth is the most important, it's set up so that I can connect to it from the nexus","date":"2013-10-12T12:41:57.101Z","type":"message"}
{"nick":"dominictarr","message":"so, you connect to the nexus7 via bt?","date":"2013-10-12T12:42:04.016Z","type":"message"}
{"nick":"rvagg","message":"I can pull out the wifi and it still works, I just get no external networking","date":"2013-10-12T12:42:08.416Z","type":"message"}
{"nick":"rvagg","message":"yeah, bluetooth from nexus to pi","date":"2013-10-12T12:42:15.945Z","type":"message"}
{"nick":"rvagg","message":"bluetooth networking to be exact","date":"2013-10-12T12:42:21.538Z","type":"message"}
{"nick":"dominictarr","message":"right - I see","date":"2013-10-12T12:42:27.430Z","type":"message"}
{"nick":"rvagg","message":"that was a bit of a pain but I think I could probably document the recipe that I landed on","date":"2013-10-12T12:42:32.658Z","type":"message"}
{"nick":"rvagg","message":"it's always predictable, the pi shows up with ip address 192.168.200.1 which I start a session on when the bluetooth is configured","date":"2013-10-12T12:43:13.911Z","type":"message"}
{"nick":"rvagg","message":"then when I'm in I manually configure whatever wifi network is available using wpa_supplicant ... grr ... linux wifi crap","date":"2013-10-12T12:43:32.535Z","type":"message"}
{"nick":"rud","date":"2013-10-12T12:43:49.747Z","type":"join"}
{"nick":"rud","reason":"Changing host","date":"2013-10-12T12:43:49.959Z","type":"quit"}
{"nick":"rud","date":"2013-10-12T12:43:49.959Z","type":"join"}
{"nick":"rvagg","message":"ingredients: pi, bluetooth dongle pi compatible, wifi dongle pi compatible, nexus 7, bluetooth keyboard for nexus 7, battery pack for pi and nexus and keyboard where required","date":"2013-10-12T12:44:24.176Z","type":"message"}
{"nick":"rvagg","message":"the last leg of my trip home I had the pi & battery tucked away in my bag in the overhead baggage locker and it never came out, I just fired up the nexus when I was ready to hack and connected via bluetooth","date":"2013-10-12T12:45:43.673Z","type":"message"}
{"nick":"rvagg","message":"I do have a problem with repeat bluetooth connections, it doesn't seem to reset well so as insurance if I'm disconnecting the nexus from the pi and I know I'll want to reconnect later I'll tell it to reboot just to start fresh and so I don't have to rip the power out and put it back in again to force a restart","date":"2013-10-12T12:46:25.858Z","type":"message"}
{"nick":"rvagg","message":"but that's something that just needs tweaking so I can reconnect later","date":"2013-10-12T12:46:36.730Z","type":"message"}
{"nick":"rvagg","message":"otherwise it's pretty stable and works well","date":"2013-10-12T12:46:47.187Z","type":"message"}
{"nick":"rvagg","message":"and I actually got a fair bit of work done on the plane this time, more than I've done before","date":"2013-10-12T12:46:59.943Z","type":"message"}
{"nick":"rvagg","message":"heh, pomke has goatdb now","date":"2013-10-12T12:49:03.101Z","type":"message"}
{"nick":"rvagg","action":"bed","date":"2013-10-12T12:49:47.609Z","type":"action"}
{"nick":"zz_eugeneware","new_nick":"eugeneware","date":"2013-10-12T12:56:19.020Z","type":"nick"}
{"nick":"fb55","reason":"Remote host closed the connection","date":"2013-10-12T13:23:53.717Z","type":"quit"}
{"nick":"fb55","date":"2013-10-12T13:24:20.498Z","type":"join"}
{"nick":"rud_","date":"2013-10-12T13:26:41.037Z","type":"join"}
{"nick":"rud","reason":"Ping timeout: 264 seconds","date":"2013-10-12T13:28:26.816Z","type":"quit"}
{"nick":"rud_","new_nick":"rud","date":"2013-10-12T13:28:27.026Z","type":"nick"}
{"nick":"fb55","reason":"Ping timeout: 272 seconds","date":"2013-10-12T13:29:35.735Z","type":"quit"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-10-12T13:34:05.449Z","type":"quit"}
{"nick":"pgte","date":"2013-10-12T13:58:41.386Z","type":"join"}
{"nick":"dominictarr","date":"2013-10-12T14:04:51.044Z","type":"join"}
{"nick":"eugeneware","new_nick":"zz_eugeneware","date":"2013-10-12T14:17:09.763Z","type":"nick"}
{"nick":"zz_eugeneware","new_nick":"eugeneware","date":"2013-10-12T14:18:46.430Z","type":"nick"}
{"nick":"pgte","reason":"Remote host closed the connection","date":"2013-10-12T14:19:11.644Z","type":"quit"}
{"nick":"pgte","date":"2013-10-12T14:24:30.397Z","type":"join"}
{"nick":"pgte","reason":"Remote host closed the connection","date":"2013-10-12T14:25:17.650Z","type":"quit"}
{"nick":"kenansulayman","date":"2013-10-12T14:29:33.324Z","type":"join"}
{"nick":"thlorenz","date":"2013-10-12T14:35:57.753Z","type":"join"}
{"nick":"insertcoffee","date":"2013-10-12T14:39:24.152Z","type":"join"}
{"nick":"thlorenz","reason":"Ping timeout: 240 seconds","date":"2013-10-12T14:40:14.541Z","type":"quit"}
{"nick":"thlorenz","date":"2013-10-12T14:50:28.958Z","type":"join"}
{"nick":"timoxley","date":"2013-10-12T14:50:34.759Z","type":"join"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-10-12T14:51:03.057Z","type":"quit"}
{"nick":"timoxley","date":"2013-10-12T14:51:20.098Z","type":"join"}
{"nick":"jcrugzz","date":"2013-10-12T15:02:39.634Z","type":"join"}
{"nick":"insertcoffee","reason":"Read error: Connection reset by peer","date":"2013-10-12T15:38:06.799Z","type":"quit"}
{"nick":"jcrugzz","reason":"Ping timeout: 240 seconds","date":"2013-10-12T15:40:28.411Z","type":"quit"}
{"nick":"esundahl","date":"2013-10-12T15:45:13.979Z","type":"join"}
