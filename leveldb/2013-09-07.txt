{"nick":"ryan_ramage","date":"2013-09-07T00:23:51.286Z","type":"join"}
{"nick":"eugeneware","date":"2013-09-07T00:26:30.331Z","type":"join"}
{"nick":"eugeneware","reason":"Remote host closed the connection","date":"2013-09-07T00:45:52.999Z","type":"quit"}
{"nick":"thlorenz_","date":"2013-09-07T00:48:17.267Z","type":"join"}
{"nick":"jxson","reason":"Remote host closed the connection","date":"2013-09-07T00:56:29.996Z","type":"quit"}
{"nick":"thlorenz_","message":"hey - whoever is in Ireland already and from the US - do the Mac Air US plugs need an adapter or do they fit?","date":"2013-09-07T00:58:03.570Z","type":"message"}
{"nick":"thlorenz_","new_nick":"thlorenz","date":"2013-09-07T00:58:09.057Z","type":"nick"}
{"nick":"thlorenz","message":"I know that the voltage will be converted by the Power Plug, but am wondering if I can physically plug it in w/out an adapter","date":"2013-09-07T00:58:44.414Z","type":"message"}
{"nick":"jcrugzz","date":"2013-09-07T01:04:49.601Z","type":"join"}
{"nick":"kenansulayman","reason":"Quit: ≈ and thus my mac took a subtle yet profound nap ≈","date":"2013-09-07T01:10:24.471Z","type":"quit"}
{"nick":"kenansulayman","date":"2013-09-07T01:10:40.367Z","type":"join"}
{"nick":"ryan_ramage","reason":"Quit: ryan_ramage","date":"2013-09-07T01:25:27.027Z","type":"quit"}
{"nick":"julianduque","reason":"Read error: Connection reset by peer","date":"2013-09-07T01:26:07.817Z","type":"quit"}
{"nick":"jxson","date":"2013-09-07T01:26:47.119Z","type":"join"}
{"nick":"jxson","reason":"Ping timeout: 245 seconds","date":"2013-09-07T01:35:00.118Z","type":"quit"}
{"nick":"eugeneware","date":"2013-09-07T01:37:24.100Z","type":"join"}
{"nick":"kenansulayman","reason":"Ping timeout: 264 seconds","date":"2013-09-07T02:01:04.351Z","type":"quit"}
{"nick":"kenansulayman","date":"2013-09-07T02:01:20.355Z","type":"join"}
{"nick":"fallsemo","date":"2013-09-07T02:01:59.361Z","type":"join"}
{"nick":"jcrugzz","reason":"Ping timeout: 260 seconds","date":"2013-09-07T02:01:59.361Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T02:03:08.050Z","type":"join"}
{"nick":"eugeneware","reason":"Remote host closed the connection","date":"2013-09-07T02:24:00.999Z","type":"quit"}
{"nick":"eugeneware","date":"2013-09-07T02:24:29.127Z","type":"join"}
{"nick":"ryan_ramage","date":"2013-09-07T02:27:33.080Z","type":"join"}
{"nick":"ryan_ramage","reason":"Client Quit","date":"2013-09-07T02:27:39.648Z","type":"quit"}
{"nick":"eugeneware","reason":"Ping timeout: 241 seconds","date":"2013-09-07T02:28:34.655Z","type":"quit"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T02:48:58.971Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T02:51:03.383Z","type":"join"}
{"nick":"eugeneware","date":"2013-09-07T02:55:00.343Z","type":"join"}
{"nick":"timoxley","date":"2013-09-07T03:02:16.239Z","type":"join"}
{"nick":"tmcw","date":"2013-09-07T03:05:24.978Z","type":"join"}
{"nick":"fallsemo","reason":"Quit: Leaving.","date":"2013-09-07T03:07:35.796Z","type":"quit"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T03:09:50.772Z","type":"quit"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-09-07T03:25:21.548Z","type":"quit"}
{"nick":"mageemooney","date":"2013-09-07T03:31:56.908Z","type":"join"}
{"nick":"levelbot","message":"[npm] modella-leveldb@0.0.4 <http://npm.im/modella-leveldb>: modella plugin for leveldb (@mattmueller)","date":"2013-09-07T03:33:14.420Z","type":"message"}
{"nick":"fallsemo","date":"2013-09-07T03:59:33.909Z","type":"join"}
{"nick":"fallsemo","reason":"Client Quit","date":"2013-09-07T04:01:03.729Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T04:06:54.396Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 245 seconds","date":"2013-09-07T04:11:15.148Z","type":"quit"}
{"nick":"jxson","date":"2013-09-07T04:34:13.012Z","type":"join"}
{"nick":"jxson","reason":"Read error: Connection reset by peer","date":"2013-09-07T04:35:52.746Z","type":"quit"}
{"nick":"jxson","date":"2013-09-07T04:36:05.681Z","type":"join"}
{"nick":"jxson","reason":"Remote host closed the connection","date":"2013-09-07T04:36:50.652Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T04:37:40.316Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T04:42:30.960Z","type":"quit"}
{"nick":"timoxley","date":"2013-09-07T04:43:37.973Z","type":"join"}
{"nick":"jondelamotte_","date":"2013-09-07T04:58:14.668Z","type":"join"}
{"nick":"jondelamotte","reason":"Ping timeout: 240 seconds","date":"2013-09-07T04:59:50.758Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T05:08:24.734Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 256 seconds","date":"2013-09-07T05:13:09.827Z","type":"quit"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T05:28:29.693Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T06:09:55.373Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 240 seconds","date":"2013-09-07T06:14:01.447Z","type":"quit"}
{"nick":"esundahl","reason":"Remote host closed the connection","date":"2013-09-07T06:28:37.743Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T06:29:11.696Z","type":"join"}
{"nick":"mageemooney","reason":"Remote host closed the connection","date":"2013-09-07T06:29:51.736Z","type":"quit"}
{"nick":"esundahl","reason":"Ping timeout: 240 seconds","date":"2013-09-07T06:33:22.005Z","type":"quit"}
{"nick":"mageemooney","date":"2013-09-07T06:33:51.495Z","type":"join"}
{"nick":"jcrugzz","date":"2013-09-07T06:36:26.634Z","type":"join"}
{"nick":"esundahl","date":"2013-09-07T06:59:43.276Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 264 seconds","date":"2013-09-07T07:08:19.012Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T07:11:25.742Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 260 seconds","date":"2013-09-07T07:15:43.971Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T07:34:33.164Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 260 seconds","date":"2013-09-07T07:39:03.966Z","type":"quit"}
{"nick":"mageemooney","reason":"Remote host closed the connection","date":"2013-09-07T07:44:52.543Z","type":"quit"}
{"nick":"levelbot","message":"[npm] level-assoc@0.9.0 <http://npm.im/level-assoc>: relational foreign key associations (hasMany, belongsTo) for leveldb (@substack)","date":"2013-09-07T07:55:45.945Z","type":"message"}
{"nick":"eugeneware","reason":"Remote host closed the connection","date":"2013-09-07T07:58:59.811Z","type":"quit"}
{"nick":"eugeneware","date":"2013-09-07T07:59:06.354Z","type":"join"}
{"nick":"kenansulayman","reason":"Quit: ≈ and thus my mac took a subtle yet profound nap ≈","date":"2013-09-07T07:59:07.334Z","type":"quit"}
{"nick":"kenansulayman","date":"2013-09-07T08:00:27.317Z","type":"join"}
{"nick":"kenansulayman","reason":"Client Quit","date":"2013-09-07T08:00:47.649Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T08:12:55.181Z","type":"join"}
{"nick":"juliangruber","message":"substack: maybe live coding a chat with multilevel and level-live-stream, but did this before, so not too exciting","date":"2013-09-07T08:15:06.705Z","type":"message"}
{"nick":"juliangruber","message":"substack: or all about dealing with the single process limit, so npm.im/multilevel and npm.im/role","date":"2013-09-07T08:15:28.084Z","type":"message"}
{"nick":"juliangruber","message":"substack: or an overview about the modules, and what leveldb is effective for using for right now","date":"2013-09-07T08:15:46.936Z","type":"message"}
{"nick":"substack","message":"ok! you should probably just do whatever you think will be the most fun and interesting!","date":"2013-09-07T08:16:55.253Z","type":"message"}
{"nick":"tmcw","reason":"Ping timeout: 260 seconds","date":"2013-09-07T08:17:19.944Z","type":"quit"}
{"nick":"substack","message":"my talk is going to be: trumpet -> hyperglue -> hyperspace -> hyperkey (unreleased) -> level-assoc -> hyperkey+assoc","date":"2013-09-07T08:19:09.744Z","type":"message"}
{"nick":"substack","message":"the broader topic is shared rendering with progressive enhancement","date":"2013-09-07T08:20:10.940Z","type":"message"}
{"nick":"substack","message":"that touches on level but not deeply because it's primarily about the other modules","date":"2013-09-07T08:20:39.414Z","type":"message"}
{"nick":"substack","message":"oh and level-track","date":"2013-09-07T08:24:15.680Z","type":"message"}
{"nick":"esundahl","date":"2013-09-07T08:35:05.672Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 260 seconds","date":"2013-09-07T08:39:44.222Z","type":"quit"}
{"nick":"juliangruber","message":"substack: ok, cool!","date":"2013-09-07T08:43:16.592Z","type":"message"}
{"nick":"juliangruber","message":"substack: sounds good","date":"2013-09-07T08:43:19.392Z","type":"message"}
{"nick":"tmcw","date":"2013-09-07T08:43:40.239Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T08:48:31.115Z","type":"quit"}
{"nick":"dominictarr","date":"2013-09-07T09:18:15.207Z","type":"join"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-09-07T10:04:32.590Z","type":"quit"}
{"nick":"dominictarr","date":"2013-09-07T10:10:26.379Z","type":"join"}
{"nick":"tmcw","date":"2013-09-07T10:15:54.707Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 256 seconds","date":"2013-09-07T10:20:18.113Z","type":"quit"}
{"nick":"jcrugzz","reason":"Ping timeout: 260 seconds","date":"2013-09-07T10:46:59.196Z","type":"quit"}
{"nick":"rvagg","message":"juliangruber, hij1nx, dominictarr: see nodeconfeu issue #6, I've given you access to my WIP presentation and put a quick rundown of the structure in the issue","date":"2013-09-07T11:08:09.992Z","type":"message"}
{"nick":"juliangruber","message":"rvagg: cloning :)","date":"2013-09-07T11:36:32.069Z","type":"message"}
{"nick":"rvagg","message":"ok, when you're done, pull the latest, I've just pushed more","date":"2013-09-07T11:37:11.740Z","type":"message"}
{"nick":"juliangruber","message":"rvagg: will clone when I'm dublin, the airport wifi is dying on me","date":"2013-09-07T11:39:18.061Z","type":"message"}
{"nick":"rvagg","message":"righto, have a good flight!","date":"2013-09-07T11:39:36.400Z","type":"message"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-09-07T11:44:32.172Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T11:48:08.595Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 260 seconds","date":"2013-09-07T11:52:47.184Z","type":"quit"}
{"nick":"levelbot","message":"[npm] level-assoc@0.10.0 <http://npm.im/level-assoc>: relational foreign key associations (hasMany, belongsTo) for leveldb (@substack)","date":"2013-09-07T12:05:45.240Z","type":"message"}
{"nick":"juliangruber","message":"rvagg: thanks man! are you in dublin yet?","date":"2013-09-07T12:07:37.996Z","type":"message"}
{"nick":"levelbot","message":"[npm] bytewise-hex@0.0.1 <http://npm.im/bytewise-hex>: Support for leveldb/levelup bytewise encodings in hex format (@eugeneware)","date":"2013-09-07T12:18:13.676Z","type":"message"}
{"nick":"tarruda","message":"what could cause database corruption that would make necessary a call to 'leveldb::RepairDB'","date":"2013-09-07T12:34:36.422Z","type":"message"}
{"nick":"rescrv","message":"tarruda: bit flips on disk, bugs in the fs/leveldb, applications above leveldb that corrupte the heap and corrupt LevelDB's state in a way that makes it to disk but doesn't crash","date":"2013-09-07T12:38:46.987Z","type":"message"}
{"nick":"rescrv","message":"tarruda: do you have a reproducible test case?","date":"2013-09-07T12:39:07.224Z","type":"message"}
{"nick":"tarruda","message":"rescrv: no, I just got curious after reading the documentation","date":"2013-09-07T12:41:09.831Z","type":"message"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-09-07T12:41:30.661Z","type":"quit"}
{"nick":"rescrv","message":"tarruda: it's basically a safety net.  if there was some way you could knowingly corrupt the db, they'd just code a way to prevent that.","date":"2013-09-07T12:41:54.795Z","type":"message"}
{"nick":"tarruda","message":"rescrv: ok","date":"2013-09-07T12:42:15.626Z","type":"message"}
{"nick":"tarruda","message":"rescrv: I started reading your paper on how ACID transactions are implemented on HyperDex, unfortunately that was too complicated for me","date":"2013-09-07T12:44:24.843Z","type":"message"}
{"nick":"tarruda","message":"rescrv: I got another idea on how to implement it though:","date":"2013-09-07T12:44:51.671Z","type":"message"}
{"nick":"tarruda","message":"rescrv: 1 - each transaction gets a unique id, and updates made on the transaction are saved under a transaction-specific key namespace(keys are prefixed with the transaction id)","date":"2013-09-07T12:46:30.517Z","type":"message"}
{"nick":"tarruda","message":"rescrv: also keeping track of uncommitted transactions on another key namespace","date":"2013-09-07T12:47:31.711Z","type":"message"}
{"nick":"tarruda","message":"2 - when the transaction is committed, iterate through all values updated by that transaction, and insert in batches outside the transaction-specific key namespace with sync = true","date":"2013-09-07T12:49:11.129Z","type":"message"}
{"nick":"tmcw","date":"2013-09-07T12:49:38.363Z","type":"join"}
{"nick":"tarruda","message":"but instead of adding the transaction id before the key we add it after in this second step(first step: [txid, key] second step: [key: txid])","date":"2013-09-07T12:50:29.583Z","type":"message"}
{"nick":"tarruda","message":"finally delete txid from the uncommitted transactions with sync: true","date":"2013-09-07T12:51:00.268Z","type":"message"}
{"nick":"tarruda","message":"what do you think?","date":"2013-09-07T12:52:19.670Z","type":"message"}
{"nick":"tmcw","reason":"Ping timeout: 245 seconds","date":"2013-09-07T12:53:45.146Z","type":"quit"}
{"nick":"rescrv","message":"tarruda: I think it's unnecessarily complicated, and writes way too much data","date":"2013-09-07T12:54:56.841Z","type":"message"}
{"nick":"rescrv","message":"tarruda: figure out what to write in the transaction and do it as one batch with sync=true","date":"2013-09-07T12:55:10.582Z","type":"message"}
{"nick":"rescrv","message":"if you're doing it on one node, that's easy","date":"2013-09-07T12:55:51.033Z","type":"message"}
{"nick":"rescrv","message":"tarruda: it's cross-node transactions that are expensive and that we target with Warp","date":"2013-09-07T12:56:08.432Z","type":"message"}
{"nick":"tarruda","message":"rescrv: I tought about that too, but I wanted to implement in a way that lets one have long-runnign transactions","date":"2013-09-07T12:56:17.619Z","type":"message"}
{"nick":"tarruda","message":"rescrv: so one could checkout a transaction and have a consistent snapshot of the database","date":"2013-09-07T12:57:03.748Z","type":"message"}
{"nick":"tarruda","message":"rescrv: like a version control system","date":"2013-09-07T12:57:18.191Z","type":"message"}
{"nick":"rescrv","message":"tarruda: long-running transactions are almost always aggregates.  They don't change much, but compute an aggregate and possibly write it.  Use LevelDB's snapshots and provide snapshot isolation instead of serializability","date":"2013-09-07T12:57:23.147Z","type":"message"}
{"nick":"rescrv","message":"tarruda: so you want historical data","date":"2013-09-07T12:57:40.515Z","type":"message"}
{"nick":"tarruda","message":"rescrv: I want ArchDB to work a bit like git","date":"2013-09-07T12:58:15.393Z","type":"message"}
{"nick":"tarruda","message":"rescrv: where one checkout a revision, do some work and then merge with the master branch","date":"2013-09-07T12:58:37.943Z","type":"message"}
{"nick":"tarruda","message":"rescrv: when merging the database checks for updated keys and throws conflict errors","date":"2013-09-07T12:59:21.527Z","type":"message"}
{"nick":"rescrv","message":"tarruda: if you're on a single host, use wall clock time.  Checkout Spanner (Corbett et. al. 2012) and Adya et. al 1995.","date":"2013-09-07T12:59:28.173Z","type":"message"}
{"nick":"tarruda","message":"rescrv: exactly like git does when it fails to merge","date":"2013-09-07T12:59:31.476Z","type":"message"}
{"nick":"rescrv","message":"what benefit does this give to the user?","date":"2013-09-07T12:59:40.220Z","type":"message"}
{"nick":"rescrv","message":"tarruda: it's MVCC with git-like semantics.  It seems like mechanism for mechanism's sake.  What is it that you want in the end?  Find that and then build mechanism that meets the goal.  Don't start with the mechanism.","date":"2013-09-07T13:00:22.127Z","type":"message"}
{"nick":"tarruda","message":"rescrv: that has the benefit of letting one work offline with data and then merge when connection is available","date":"2013-09-07T13:00:28.460Z","type":"message"}
{"nick":"rescrv","message":"and what happens when there's a conflict?","date":"2013-09-07T13:00:51.136Z","type":"message"}
{"nick":"tarruda","message":"rescrv: the database throws an error with all the conflicted keys and their updated values","date":"2013-09-07T13:01:25.196Z","type":"message"}
{"nick":"tarruda","message":"rescrv: which the user will be presented","date":"2013-09-07T13:01:36.388Z","type":"message"}
{"nick":"tarruda","message":"rescrv: when its updated again the merge will succeed(if it wasnt updated in the meantime)","date":"2013-09-07T13:01:59.532Z","type":"message"}
{"nick":"rescrv","message":"tarruda: and what does an application do?  will the transaction commit and later abort?  what can I do when in offline mode?","date":"2013-09-07T13:02:03.176Z","type":"message"}
{"nick":"tarruda","message":"rescrv: heres an example workflow:","date":"2013-09-07T13:02:28.556Z","type":"message"}
{"nick":"alanhoff","date":"2013-09-07T13:02:35.482Z","type":"join"}
{"nick":"tarruda","message":"rescrv: user A checkouts a revision and starts working with its local cache. user B checkouts the same revision updates key X and commits","date":"2013-09-07T13:03:49.140Z","type":"message"}
{"nick":"alanhoff","date":"2013-09-07T13:04:25.385Z","type":"part"}
{"nick":"mbalho","message":"tarruda: sounds like couch/dropbox datastore. mikeal has a similar project called couchup thats in node + levelup","date":"2013-09-07T13:04:52.787Z","type":"message"}
{"nick":"tarruda","message":"rescrv: if user A also updates key X the commit will fail, and the central system will send the updated value of X","date":"2013-09-07T13:05:14.548Z","type":"message"}
{"nick":"mbalho","message":"tarruda: mikeals version doesnt do branches, so each document has a linear revision history (to keep things simple)","date":"2013-09-07T13:05:25.217Z","type":"message"}
{"nick":"rescrv","message":"tarruda mbalho it sounds like you both want the same thing:  shove a database format into Git and write custom merge functions, so people can share data and share updates to data","date":"2013-09-07T13:05:53.296Z","type":"message"}
{"nick":"tarruda","message":"yes","date":"2013-09-07T13:06:13.552Z","type":"message"}
{"nick":"mbalho","message":"tarruda: im working on this for the next 6 months at least via a grant: https://github.com/maxogden/dat","date":"2013-09-07T13:06:29.208Z","type":"message"}
{"nick":"tarruda","message":"I'm focusing more on data consistency","date":"2013-09-07T13:06:34.624Z","type":"message"}
{"nick":"rescrv","message":"tarruda: I'm wondering when a transaction may commit.  If it has to wait for connectivity with others, then you're best to not even allow offline operation.","date":"2013-09-07T13:06:48.791Z","type":"message"}
{"nick":"tarruda","message":"rescrv: a transaction can only commit when connection is available, however archdb works in the web browser so its trivial to do offline work and then commit the transaction when connection is available","date":"2013-09-07T13:08:14.643Z","type":"message"}
{"nick":"tarruda","message":"mbalho: dat sounds nice","date":"2013-09-07T13:09:07.159Z","type":"message"}
{"nick":"tarruda","message":"mbalho: Im gonna investigate it","date":"2013-09-07T13:09:15.028Z","type":"message"}
{"nick":"rescrv","message":"tarruda: so it's meant for interactive access, where latency does not matter?","date":"2013-09-07T13:09:20.984Z","type":"message"}
{"nick":"tarruda","message":"rescrv: yes","date":"2013-09-07T13:09:29.524Z","type":"message"}
{"nick":"mbalho","message":"tarruda: feel free to check out/comment the issues on that repo, im open to ideas and feedback","date":"2013-09-07T13:09:38.501Z","type":"message"}
{"nick":"alanhoff","date":"2013-09-07T13:10:14.992Z","type":"join"}
{"nick":"tarruda","message":"I implemented ArchDB to work with a pluggable backend storage, so it works seamless on browser or node.js with the fs module","date":"2013-09-07T13:10:32.285Z","type":"message"}
{"nick":"rescrv","message":"tarruda: what is the consistency guarantee you want to provide?","date":"2013-09-07T13:10:52.496Z","type":"message"}
{"nick":"tarruda","message":"rescrv: that one cannot acidentally overwrite data","date":"2013-09-07T13:11:23.540Z","type":"message"}
{"nick":"tarruda","message":"besides ACID semantics","date":"2013-09-07T13:11:42.684Z","type":"message"}
{"nick":"tarruda","message":"I'm really new to this database business so I welcome any help/feedback you guys can provide","date":"2013-09-07T13:12:37.684Z","type":"message"}
{"nick":"rescrv","message":"tarruda: ACID will give you the property that \"one cannot accidently override data\" so long as one checks a key before writing it.","date":"2013-09-07T13:12:41.326Z","type":"message"}
{"nick":"rescrv","message":"here, I'm assuming ACID == one-copy serializability.  Which requires that you track values read and written.","date":"2013-09-07T13:13:18.307Z","type":"message"}
{"nick":"tarruda","message":"rescrv: thats all I want","date":"2013-09-07T13:13:24.666Z","type":"message"}
{"nick":"rescrv","message":"which?  that property, or ACID?","date":"2013-09-07T13:13:37.248Z","type":"message"}
{"nick":"tarruda","message":"ACID","date":"2013-09-07T13:13:41.427Z","type":"message"}
{"nick":"rescrv","message":"so you'll need to track the values that were read and written to ensure acid, which can be potentially many","date":"2013-09-07T13:14:36.908Z","type":"message"}
{"nick":"tarruda","message":"I want it to work a lot like git, except that when a merge/commit fails, one doesnt need to checkout the entire master branch","date":"2013-09-07T13:14:38.015Z","type":"message"}
{"nick":"tarruda","message":"just the updated keys","date":"2013-09-07T13:14:45.707Z","type":"message"}
{"nick":"tarruda","message":"(which will be done automatically since the error already contains information about the updated keys)","date":"2013-09-07T13:15:06.115Z","type":"message"}
{"nick":"rescrv","message":"the updated keys will be values you read that were overwritten, and values that were written by others that you wrote as well, right?","date":"2013-09-07T13:15:42.500Z","type":"message"}
{"nick":"tarruda","message":"rescrv: yes but that is already done automatically due to a design decision I made on archdb","date":"2013-09-07T13:15:53.121Z","type":"message"}
{"nick":"tarruda","message":"rescrv: archdb keeps a history index","date":"2013-09-07T13:16:15.825Z","type":"message"}
{"nick":"tarruda","message":"rescrv: that is used when doing conflict check","date":"2013-09-07T13:16:24.676Z","type":"message"}
{"nick":"rescrv","message":"tarruda: then it sounds like you can do it with the way you designed keys.  I just don't understand updating from a historical transaction.  E.g., checkout last week, update, and merge to master.","date":"2013-09-07T13:16:47.718Z","type":"message"}
{"nick":"tarruda","message":"rescrv: see these two test cases: https://github.com/tarruda/archdb/blob/master/test/acceptance/api.coffee#L423-L534","date":"2013-09-07T13:17:34.177Z","type":"message"}
{"nick":"tarruda","message":"it shows how a merge with/without key conflicts","date":"2013-09-07T13:18:11.481Z","type":"message"}
{"nick":"tarruda","message":"tx1,tx2,tx3 shows a conflict","date":"2013-09-07T13:18:50.712Z","type":"message"}
{"nick":"rescrv","message":"when you do find().all(), does it return every item in the DB?","date":"2013-09-07T13:19:11.892Z","type":"message"}
{"nick":"tarruda","message":"yes","date":"2013-09-07T13:19:31.080Z","type":"message"}
{"nick":"tarruda","message":"every item that matches the query","date":"2013-09-07T13:19:43.399Z","type":"message"}
{"nick":"tarruda","message":"find().each is used to iterating in a cursor-like behavior","date":"2013-09-07T13:20:01.232Z","type":"message"}
{"nick":"tarruda","message":"find() can receive a query argument","date":"2013-09-07T13:20:18.398Z","type":"message"}
{"nick":"rescrv","message":"I start a transaction, do find().all(), and maintain a count of the number of items.  While I'm doing this, you write a key that didn't exist.  Will you generate a conflict?","date":"2013-09-07T13:20:45.179Z","type":"message"}
{"nick":"tarruda","message":"heres a description of the merge algorithm: https://github.com/tarruda/archdb/blob/master/src/local/database.coffee#L51-L73","date":"2013-09-07T13:21:09.489Z","type":"message"}
{"nick":"rescrv","message":"If I write the count to a new key, does it generate a merge conflict?","date":"2013-09-07T13:21:57.789Z","type":"message"}
{"nick":"tarruda","message":"no, conflicts are only generated when updating a key that was modified after the revision was checked out","date":"2013-09-07T13:22:57.979Z","type":"message"}
{"nick":"rescrv","message":"so you don't want ACID the.  You want something looser.  The scenario I presented is not strictly serializable if my commit doesn't fail/generate a merge","date":"2013-09-07T13:24:02.211Z","type":"message"}
{"nick":"tarruda","message":"what does serializable means exactly?","date":"2013-09-07T13:25:12.112Z","type":"message"}
{"nick":"dominictarr","date":"2013-09-07T13:26:25.251Z","type":"join"}
{"nick":"rescrv","message":"one-copy serializable means that the execution is equivalent to some serial schedule.  Another way to think about it is that the result of the database after executing should be as if there was a giant lock around the DB that each transaction held for its entire duration without releasing until it committed.","date":"2013-09-07T13:26:59.632Z","type":"message"}
{"nick":"tarruda","message":"theres no lock, however commits are serialized","date":"2013-09-07T13:27:30.679Z","type":"message"}
{"nick":"tarruda","message":"the index implementation uses copy-on-write to maintain isolation","date":"2013-09-07T13:27:55.477Z","type":"message"}
{"nick":"rescrv","message":"The execution is serializable if there's some such ordering of the transactions under the locking scheme that produces the same result.  It's not saying you need a lock.  It's saying you need the resulting state to be identical to a state where you held the locks.","date":"2013-09-07T13:28:05.628Z","type":"message"}
{"nick":"rescrv","message":"the way you described it above, it's not providing isolation","date":"2013-09-07T13:28:29.875Z","type":"message"}
{"nick":"tarruda","message":"due to the conflict check?","date":"2013-09-07T13:28:49.443Z","type":"message"}
{"nick":"rescrv","message":"because it allows a non-serializable execution","date":"2013-09-07T13:29:28.795Z","type":"message"}
{"nick":"tarruda","message":"by starting a transaction, one is actually saving the root node of the database","date":"2013-09-07T13:30:44.103Z","type":"message"}
{"nick":"tarruda","message":"since the indexes are copy-on-write","date":"2013-09-07T13:30:53.563Z","type":"message"}
{"nick":"tarruda","message":"I think its isolated from other transactions","date":"2013-09-07T13:31:02.021Z","type":"message"}
{"nick":"tarruda","message":"isn't that what isolation means in transaction context?","date":"2013-09-07T13:31:23.584Z","type":"message"}
{"nick":"rescrv","message":"consider this concrete example.  The DB has {k_A: v_A, k_B: v_B, k_C: v_C}.  We both start a transaction.  I count all the keys and get 3.  You count all the keys and get 3.  I write k_rescrv: 3.  You write k_tarruda: 3.  You commit.  I try to commit.  If I'm allowed to commit, it's incorrect because there's no order where we both can add one key and have the other still see 3.","date":"2013-09-07T13:31:27.830Z","type":"message"}
{"nick":"rescrv","message":"isolation means that the transactions' operations do not affect each other.  COW can help with this, but its use does not automatically guarantee it.","date":"2013-09-07T13:32:27.907Z","type":"message"}
{"nick":"tarruda","message":"hmmm","date":"2013-09-07T13:33:07.999Z","type":"message"}
{"nick":"tarruda","message":"I still dont get why this previous example is wrong since we both counter our versions of the database","date":"2013-09-07T13:34:29.750Z","type":"message"}
{"nick":"tarruda","message":"counted*","date":"2013-09-07T13:34:35.716Z","type":"message"}
{"nick":"tarruda","message":"so thats not acid?","date":"2013-09-07T13:34:55.031Z","type":"message"}
{"nick":"tarruda","message":"what would happen if you did that on a transaction with 'serializable' isolation level on postgres?","date":"2013-09-07T13:36:19.139Z","type":"message"}
{"nick":"rescrv","message":"consider if there's a lock around the database.  Only one of us can have the lock at a time.  There's two possible outcomes:  {k_A: v_A, k_B: v_B, k_C: v_C, k_rescrv: 3, k_tarruda: 4} and {k_A: v_A, k_B: v_B, k_C: v_C, k_rescrv: 4, k_tarruda: 3}","date":"2013-09-07T13:37:00.454Z","type":"message"}
{"nick":"rescrv","message":"{k_A: v_A, k_B: v_B, k_C: v_C, k_rescrv: 3, k_tarruda: 3} is not a valid outcome","date":"2013-09-07T13:37:08.560Z","type":"message"}
{"nick":"rescrv","message":"I'm not familiar with postgres enough to know.  I hope it would abort or retry one or both of the transactions.","date":"2013-09-07T13:37:44.357Z","type":"message"}
{"nick":"tarruda","message":"I think I get it","date":"2013-09-07T13:37:59.820Z","type":"message"}
{"nick":"Acconut","date":"2013-09-07T13:38:49.795Z","type":"join"}
{"nick":"tarruda","message":"so to be considered ACID a database has to simulate serializable transactions","date":"2013-09-07T13:39:15.979Z","type":"message"}
{"nick":"rescrv","message":"in my mind, ACID implies the strongest guarantee of one-copy serializability.  You'll find plenty of database vendors that actually don't do that and market their product that does less as ACID, just to have the right buzzwords.","date":"2013-09-07T13:40:06.600Z","type":"message"}
{"nick":"tarruda","message":"I see","date":"2013-09-07T13:40:22.853Z","type":"message"}
{"nick":"rescrv","message":"there's a weaker guarantee called \"snapshot isolation\" that many people like to provide and call ACID.  I think it's OK to do that as long as you state \"ACID\" and \"snapshot isolation\" in the same size font within the paragraph where you claim ACID.","date":"2013-09-07T13:40:58.803Z","type":"message"}
{"nick":"rescrv","message":"I think the scheme you have would indeed be snapshot isolation.","date":"2013-09-07T13:41:11.842Z","type":"message"}
{"nick":"tarruda","message":"ok","date":"2013-09-07T13:41:29.722Z","type":"message"}
{"nick":"rescrv","message":"and it would prevent you from overwriting data that others wrote.","date":"2013-09-07T13:41:30.371Z","type":"message"}
{"nick":"rescrv","message":"if that's good enough for you, you can just call it that, and call it done","date":"2013-09-07T13:41:55.077Z","type":"message"}
{"nick":"tarruda","message":"for me its more important to have offline transactions than to have serializable transactions","date":"2013-09-07T13:42:36.663Z","type":"message"}
{"nick":"tarruda","message":"so its fine for now","date":"2013-09-07T13:42:43.621Z","type":"message"}
{"nick":"tarruda","message":"however the example you gave me","date":"2013-09-07T13:42:53.547Z","type":"message"}
{"nick":"tarruda","message":"raised a few questions in my head","date":"2013-09-07T13:43:00.499Z","type":"message"}
{"nick":"tarruda","message":"I might have trouble implementing the data-processing framework","date":"2013-09-07T13:43:16.272Z","type":"message"}
{"nick":"thlorenz","date":"2013-09-07T13:44:06.364Z","type":"join"}
{"nick":"tarruda","message":"databases like mongodb and couchdb provide mapreduce, I want to provide a better tool","date":"2013-09-07T13:44:29.432Z","type":"message"}
{"nick":"tarruda","message":"which uses the history index","date":"2013-09-07T13:44:43.763Z","type":"message"}
{"nick":"tarruda","message":"do you get how I might have problems?","date":"2013-09-07T13:45:06.420Z","type":"message"}
{"nick":"rescrv","message":"I don't know what a history index is, so I can imagine it might be tricky, but cannot enumerate specific problems.","date":"2013-09-07T13:47:02.112Z","type":"message"}
{"nick":"tarruda","message":"heres an example: https://github.com/tarruda/archdb/blob/master/test/acceptance/api.coffee#L325-L358","date":"2013-09-07T13:47:49.612Z","type":"message"}
{"nick":"tarruda","message":"basically the database logs every update made","date":"2013-09-07T13:48:03.868Z","type":"message"}
{"nick":"tarruda","message":"to a special read-only index called '$history'","date":"2013-09-07T13:48:19.319Z","type":"message"}
{"nick":"rescrv","message":"what guarantees does the kistory index make?","date":"2013-09-07T13:48:23.900Z","type":"message"}
{"nick":"tarruda","message":"I'm implementing another special index called '$hooks' which one can use to install procedures to be executed at database-specific events","date":"2013-09-07T13:49:11.656Z","type":"message"}
{"nick":"tarruda","message":"for example","date":"2013-09-07T13:49:16.425Z","type":"message"}
{"nick":"tarruda","message":"if one wants to index all customers by name","date":"2013-09-07T13:49:27.184Z","type":"message"}
{"nick":"Acconut","reason":"Quit: Acconut","date":"2013-09-07T13:49:56.748Z","type":"quit"}
{"nick":"tarruda","message":"it can be done by installing the following hook: 'for (let entry of db('$history') { db('customers_by_name').set(entry.value.name, entry.ref) }'","date":"2013-09-07T13:51:09.028Z","type":"message"}
{"nick":"tmcw","date":"2013-09-07T13:51:10.032Z","type":"join"}
{"nick":"tarruda","message":"there are a few more details like only processing new history entries","date":"2013-09-07T13:51:24.101Z","type":"message"}
{"nick":"tarruda","message":"but one can install a before-query 'customers_by_name' hook to build such a lazy index","date":"2013-09-07T13:51:52.475Z","type":"message"}
{"nick":"tarruda","message":"that can lead to inconsistencies if its done at transaction level","date":"2013-09-07T13:52:35.208Z","type":"message"}
{"nick":"tarruda","message":"one can add an index to calculate aggregate values like sum/count, which would be wrong like in the example you gave","date":"2013-09-07T13:53:11.375Z","type":"message"}
{"nick":"tarruda","message":"now that I think better, I think this problem can be solved by running these hooks in the same queue used to merge commits","date":"2013-09-07T13:55:45.392Z","type":"message"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T13:56:02.812Z","type":"quit"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T13:57:17.297Z","type":"quit"}
{"nick":"Acconut","date":"2013-09-07T14:07:45.975Z","type":"join"}
{"nick":"Acconut","reason":"Client Quit","date":"2013-09-07T14:08:39.481Z","type":"quit"}
{"nick":"eugeneware","message":"rvagg: I jotted down my ideas about some possible levelmeup exercises at https://github.com/rvagg/levelmeup/issues/1","date":"2013-09-07T14:12:17.390Z","type":"message"}
{"nick":"levelbot","message":"[npm] level-microblog@0.0.0 <http://npm.im/level-microblog>: A simple microblog app build on leveldb/levelup (@eugeneware)","date":"2013-09-07T14:13:43.562Z","type":"message"}
{"nick":"levelbot","message":"[npm] level-assoc@0.11.0 <http://npm.im/level-assoc>: relational foreign key associations (hasMany, belongsTo) for leveldb (@substack)","date":"2013-09-07T14:16:44.370Z","type":"message"}
{"nick":"thlorenz","date":"2013-09-07T14:21:37.221Z","type":"join"}
{"nick":"tmcw","date":"2013-09-07T14:21:54.631Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T14:26:16.330Z","type":"quit"}
{"nick":"eugeneware","reason":"Remote host closed the connection","date":"2013-09-07T14:41:14.276Z","type":"quit"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T14:54:43.734Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T15:00:47.688Z","type":"join"}
{"nick":"eugeneware","date":"2013-09-07T15:01:58.146Z","type":"join"}
{"nick":"levelbot","message":"[npm] hyperkey@0.0.0 <http://npm.im/hyperkey>: shared server+client rendering with live updates for key/value stores (@substack)","date":"2013-09-07T15:09:43.735Z","type":"message"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T15:11:05.576Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T15:17:28.215Z","type":"join"}
{"nick":"eugeneware","reason":"Remote host closed the connection","date":"2013-09-07T15:17:43.057Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T15:18:37.354Z","type":"join"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T15:20:32.193Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T15:30:58.081Z","type":"join"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T15:43:26.992Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T15:54:12.221Z","type":"join"}
{"nick":"levelbot","message":"[npm] hyperkey@0.0.1 <http://npm.im/hyperkey>: shared server+client rendering with live updates for key/value stores (@substack)","date":"2013-09-07T15:58:13.995Z","type":"message"}
{"nick":"timoxley","date":"2013-09-07T15:59:32.660Z","type":"join"}
{"nick":"eugeneware","date":"2013-09-07T16:03:47.283Z","type":"join"}
{"nick":"levelbot","message":"[npm] mosca@0.11.0 <http://npm.im/mosca>: The multi-transport MQTT broker for node.js. It supports AMQP, Redis, ZeroMQ, MongoDB or just MQTT. (@matteo.collina)","date":"2013-09-07T16:16:14.901Z","type":"message"}
{"nick":"levelbot","message":"[npm] consensus@0.0.2 <http://npm.im/consensus>: vote for topics for your next meeting (@ceejbot)","date":"2013-09-07T16:29:18.951Z","type":"message"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T16:35:29.146Z","type":"quit"}
{"nick":"levelbot","message":"[npm] bytewise@0.6.0 <http://npm.im/bytewise>: Binary serialization which sorts bytewise for arbirarily complex data structures (@deanlandolt)","date":"2013-09-07T16:42:14.062Z","type":"message"}
{"nick":"jjmalina","date":"2013-09-07T16:44:14.043Z","type":"join"}
{"nick":"rvagg","message":"eugeneware: thanks! great to get more input","date":"2013-09-07T16:54:25.004Z","type":"message"}
{"nick":"tmcw","date":"2013-09-07T16:54:31.459Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 260 seconds","date":"2013-09-07T16:58:55.407Z","type":"quit"}
{"nick":"kenansulayman","date":"2013-09-07T17:08:32.353Z","type":"join"}
{"nick":"esundahl","reason":"Remote host closed the connection","date":"2013-09-07T17:27:31.870Z","type":"quit"}
{"nick":"Acconut","date":"2013-09-07T17:32:21.497Z","type":"join"}
{"nick":"Acconut","reason":"Client Quit","date":"2013-09-07T17:32:46.805Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T17:35:49.336Z","type":"join"}
{"nick":"levelbot","message":"[npm] level-exists@0.0.0 <http://npm.im/level-exists>: Check if a datum exists without reading its value. (@juliangruber)","date":"2013-09-07T17:48:13.618Z","type":"message"}
{"nick":"mbalho","message":"oooh","date":"2013-09-07T17:48:33.704Z","type":"message"}
{"nick":"mbalho","message":"juliangruber: would be cool if that worked for the peek last use case too","date":"2013-09-07T17:49:14.554Z","type":"message"}
{"nick":"mbalho","message":"juliangruber: im guessing that createKeyStream in optimized in levelup/down then?","date":"2013-09-07T17:49:37.216Z","type":"message"}
{"nick":"levelbot","message":"[npm] level-exists@0.0.1 <http://npm.im/level-exists>: Check if a datum exists without reading its value. (@juliangruber)","date":"2013-09-07T17:51:43.333Z","type":"message"}
{"nick":"rvagg","message":"keystream is a readstream with keys:false so yes, optimised because while leveldb fetches the value from the store, it's not copied by leveldown so there's no JS-land conversion cost","date":"2013-09-07T17:57:34.238Z","type":"message"}
{"nick":"rvagg","message":"dominictarr: it's raining so I don't think I'll be coming over!","date":"2013-09-07T17:57:53.145Z","type":"message"}
{"nick":"jjmalina","reason":"Quit: Leaving.","date":"2013-09-07T18:05:34.608Z","type":"quit"}
{"nick":"jjmalina","date":"2013-09-07T18:08:28.214Z","type":"join"}
{"nick":"levelbot","message":"[npm] level-track@0.1.0 <http://npm.im/level-track>: receive updates from a set of keys and ranges in leveldb (@substack)","date":"2013-09-07T18:13:15.286Z","type":"message"}
{"nick":"jjmalina","reason":"Quit: Leaving.","date":"2013-09-07T18:14:19.845Z","type":"quit"}
{"nick":"jjmalina","date":"2013-09-07T18:14:29.022Z","type":"join"}
{"nick":"eugeneware","reason":"Ping timeout: 268 seconds","date":"2013-09-07T18:18:27.136Z","type":"quit"}
{"nick":"Acconut","date":"2013-09-07T18:25:14.204Z","type":"join"}
{"nick":"Acconut","reason":"Client Quit","date":"2013-09-07T18:25:31.051Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T18:26:49.648Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T18:31:40.330Z","type":"quit"}
{"nick":"gwenbell","date":"2013-09-07T18:45:08.263Z","type":"join"}
{"nick":"tmcw","date":"2013-09-07T18:57:44.546Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T19:02:16.398Z","type":"quit"}
{"nick":"gwenbell","reason":"Ping timeout: 260 seconds","date":"2013-09-07T19:05:59.948Z","type":"quit"}
{"nick":"esundahl","reason":"Remote host closed the connection","date":"2013-09-07T19:06:01.562Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T19:06:34.404Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 245 seconds","date":"2013-09-07T19:10:50.122Z","type":"quit"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-09-07T19:20:38.356Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T19:30:24.376Z","type":"join"}
{"nick":"esundahl","date":"2013-09-07T19:37:08.764Z","type":"join"}
{"nick":"jjmalina","reason":"Quit: Leaving.","date":"2013-09-07T19:40:30.037Z","type":"quit"}
{"nick":"jjmalina","date":"2013-09-07T19:43:17.464Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 260 seconds","date":"2013-09-07T19:45:31.459Z","type":"quit"}
{"nick":"timoxley","date":"2013-09-07T19:51:11.511Z","type":"join"}
{"nick":"tmcw","date":"2013-09-07T19:59:14.358Z","type":"join"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-09-07T20:03:00.799Z","type":"quit"}
{"nick":"tmcw","reason":"Ping timeout: 245 seconds","date":"2013-09-07T20:03:20.123Z","type":"quit"}
{"nick":"eugeneware","date":"2013-09-07T20:14:29.016Z","type":"join"}
{"nick":"dominictarr","date":"2013-09-07T20:14:56.672Z","type":"join"}
{"nick":"eugeneware","reason":"Ping timeout: 255 seconds","date":"2013-09-07T20:18:47.996Z","type":"quit"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T20:35:31.185Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T20:37:39.384Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 256 seconds","date":"2013-09-07T20:42:30.644Z","type":"quit"}
{"nick":"tarruda","date":"2013-09-07T20:53:47.422Z","type":"part"}
{"nick":"tarruda","date":"2013-09-07T21:01:33.146Z","type":"join"}
{"nick":"tarruda","message":"I wanna write a node-levelup plugin in the spirit of level-sublevel(a wrapper around a levelup object) is there any npm module that provides a class with all methods?","date":"2013-09-07T21:06:04.260Z","type":"message"}
{"nick":"gwenbell","date":"2013-09-07T21:06:54.625Z","type":"join"}
{"nick":"esundahl","date":"2013-09-07T21:09:26.201Z","type":"join"}
{"nick":"thlorenz_","date":"2013-09-07T21:27:44.945Z","type":"join"}
{"nick":"esundahl_","date":"2013-09-07T21:27:48.365Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 264 seconds","date":"2013-09-07T21:31:06.992Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T21:31:29.673Z","type":"join"}
{"nick":"tmcw","reason":"Ping timeout: 264 seconds","date":"2013-09-07T21:35:52.414Z","type":"quit"}
{"nick":"kenansulayman","message":"tarruda Object.keys(levelUp)","date":"2013-09-07T21:49:22.382Z","type":"message"}
{"nick":"esundahl_","reason":"Remote host closed the connection","date":"2013-09-07T21:50:43.033Z","type":"quit"}
{"nick":"Acconut","date":"2013-09-07T21:52:58.520Z","type":"join"}
{"nick":"Acconut","reason":"Remote host closed the connection","date":"2013-09-07T21:53:38.306Z","type":"quit"}
{"nick":"jjmalina","reason":"Quit: Leaving.","date":"2013-09-07T21:56:50.883Z","type":"quit"}
{"nick":"jcrugzz","date":"2013-09-07T21:58:27.564Z","type":"join"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-09-07T21:58:31.430Z","type":"quit"}
{"nick":"esundahl","date":"2013-09-07T22:19:53.276Z","type":"join"}
{"nick":"Acconut","date":"2013-09-07T22:26:45.438Z","type":"join"}
{"nick":"Acconut","reason":"Client Quit","date":"2013-09-07T22:26:59.659Z","type":"quit"}
{"nick":"ryan_ramage","date":"2013-09-07T22:43:16.947Z","type":"join"}
{"nick":"thlorenz_","reason":"Remote host closed the connection","date":"2013-09-07T22:45:00.615Z","type":"quit"}
{"nick":"Acconut","date":"2013-09-07T22:45:12.072Z","type":"join"}
{"nick":"Acconut","reason":"Client Quit","date":"2013-09-07T22:45:56.777Z","type":"quit"}
{"nick":"thlorenz","date":"2013-09-07T22:55:53.614Z","type":"join"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-09-07T22:57:06.158Z","type":"quit"}
{"nick":"tmcw","date":"2013-09-07T23:03:45.362Z","type":"join"}
{"nick":"gwenbell","reason":"Quit: Lost terminal","date":"2013-09-07T23:06:30.269Z","type":"quit"}
{"nick":"tmcw","reason":"Ping timeout: 245 seconds","date":"2013-09-07T23:07:55.124Z","type":"quit"}
{"nick":"ryan_ramage","reason":"Quit: ryan_ramage","date":"2013-09-07T23:08:19.414Z","type":"quit"}
{"nick":"ryan_ramage","date":"2013-09-07T23:09:37.675Z","type":"join"}
{"nick":"ryan_ramage","reason":"Client Quit","date":"2013-09-07T23:11:14.958Z","type":"quit"}
{"nick":"dominictarr","date":"2013-09-07T23:20:44.005Z","type":"join"}
{"nick":"dominictarr_","date":"2013-09-07T23:23:22.254Z","type":"join"}
{"nick":"dominictarr","reason":"Ping timeout: 264 seconds","date":"2013-09-07T23:25:26.983Z","type":"quit"}
{"nick":"dominictarr_","new_nick":"dominictarr","date":"2013-09-07T23:25:27.193Z","type":"nick"}
{"nick":"ryan_ramage","date":"2013-09-07T23:35:34.913Z","type":"join"}
{"nick":"rvagg","message":"tarruda: not yet, but we're planning on moving to a more public & classic prototypal system so you'll eventually be able to just take the LevelUP object and bend it to your will, or even just cherry pick methods off the prototype","date":"2013-09-07T23:43:46.925Z","type":"message"}
{"nick":"rvagg","message":"tarruda: we'll get there soon, cause the current very-private implementation is annoying some of us a little too much","date":"2013-09-07T23:44:16.184Z","type":"message"}
{"nick":"rvagg","message":"for now tho... just implement manually","date":"2013-09-07T23:44:59.250Z","type":"message"}
{"nick":"ryan_ramage","reason":"Quit: ryan_ramage","date":"2013-09-07T23:49:29.828Z","type":"quit"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-09-07T23:56:06.474Z","type":"quit"}
{"nick":"levelbot","message":"[npm] level-assoc@0.12.0 <http://npm.im/level-assoc>: relational foreign key associations (hasMany, belongsTo) for leveldb (@substack)","date":"2013-09-07T23:57:16.545Z","type":"message"}
