{"nick":"jxson","reason":"Remote host closed the connection","date":"2013-08-31T00:11:13.704Z","type":"quit"}
{"nick":"jxson","date":"2013-08-31T00:15:09.179Z","type":"join"}
{"nick":"ednapiranha","reason":"Remote host closed the connection","date":"2013-08-31T00:34:01.492Z","type":"quit"}
{"nick":"julianduque","reason":"Ping timeout: 245 seconds","date":"2013-08-31T00:35:51.668Z","type":"quit"}
{"nick":"jxson","reason":"Remote host closed the connection","date":"2013-08-31T00:38:31.663Z","type":"quit"}
{"nick":"julianduque","date":"2013-08-31T00:39:16.448Z","type":"join"}
{"nick":"missinglink","date":"2013-08-31T00:40:27.867Z","type":"join"}
{"nick":"levelbot","message":"[npm] level-subtree@1.0.0 <http://npm.im/level-subtree>: build and maintain a tree from the sublevels in a leveldb instance (@hij1nx)","date":"2013-08-31T00:54:16.820Z","type":"message"}
{"nick":"missinglink","reason":"Ping timeout: 245 seconds","date":"2013-08-31T01:20:51.624Z","type":"quit"}
{"nick":"levelbot","message":"[npm] valuepack-core@0.3.7 <http://npm.im/valuepack-core>: Core utils and configurations for valuepack, not at all useful by itself. (@thlorenz)","date":"2013-08-31T01:24:46.321Z","type":"message"}
{"nick":"dominictarr","reason":"Quit: dominictarr","date":"2013-08-31T01:34:44.059Z","type":"quit"}
{"nick":"jerrysv","reason":"Remote host closed the connection","date":"2013-08-31T01:50:49.307Z","type":"quit"}
{"nick":"fallsemo","reason":"Quit: Leaving.","date":"2013-08-31T02:06:10.904Z","type":"quit"}
{"nick":"esundahl","date":"2013-08-31T02:13:37.525Z","type":"join"}
{"nick":"timoxley","date":"2013-08-31T02:22:46.501Z","type":"join"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-08-31T02:26:24.735Z","type":"quit"}
{"nick":"thlorenz","date":"2013-08-31T02:27:40.050Z","type":"join"}
{"nick":"thlorenz","reason":"Remote host closed the connection","date":"2013-08-31T02:27:50.044Z","type":"quit"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-08-31T02:57:33.180Z","type":"quit"}
{"nick":"timoxley","date":"2013-08-31T02:59:16.629Z","type":"join"}
{"nick":"timoxley","reason":"Remote host closed the connection","date":"2013-08-31T03:26:37.385Z","type":"quit"}
{"nick":"werle","reason":"Ping timeout: 256 seconds","date":"2013-08-31T03:36:15.343Z","type":"quit"}
{"nick":"timoxley","date":"2013-08-31T04:02:16.447Z","type":"join"}
{"nick":"timoxley","reason":"Ping timeout: 245 seconds","date":"2013-08-31T04:06:40.246Z","type":"quit"}
{"nick":"tmcw","date":"2013-08-31T04:11:08.493Z","type":"join"}
{"nick":"tmcw","reason":"Remote host closed the connection","date":"2013-08-31T04:11:58.605Z","type":"quit"}
{"nick":"i_m_ca","date":"2013-08-31T04:32:05.455Z","type":"join"}
{"nick":"mbalho","message":"rvagg: https://github.com/maxogden/level-bulk-load","date":"2013-08-31T04:33:28.537Z","type":"message"}
{"nick":"mbalho","message":"OH CRAPPER wait i forgot to check in the batching version lol","date":"2013-08-31T04:40:45.187Z","type":"message"}
{"nick":"i_m_ca","reason":"Ping timeout: 245 seconds","date":"2013-08-31T04:45:25.223Z","type":"quit"}
{"nick":"mbalho","message":"ok fixed it","date":"2013-08-31T05:03:09.002Z","type":"message"}
{"nick":"julianduque","reason":"Quit: leaving","date":"2013-08-31T05:13:09.065Z","type":"quit"}
{"nick":"brycebaril","message":"mbalho: trying to figure out a couple details with level-bulk-load -- what's the significance of the bufferSize 16, and batch size of 1600?","date":"2013-08-31T05:27:33.640Z","type":"message"}
{"nick":"mbalho","message":"brycebaril: see comment in issue #1","date":"2013-08-31T05:28:05.528Z","type":"message"}
{"nick":"jcrugzz","date":"2013-08-31T05:39:16.029Z","type":"join"}
{"nick":"esundahl","reason":"Remote host closed the connection","date":"2013-08-31T05:41:35.703Z","type":"quit"}
{"nick":"brycebaril","message":"mbalho: pull request sent","date":"2013-08-31T06:02:56.985Z","type":"message"}
{"nick":"brycebaril","message":"I'm not sure how interesting the various tunables I added are, but this way I can at least play around with them more easily","date":"2013-08-31T06:03:32.382Z","type":"message"}
{"nick":"mbalho","message":"im pretty sure that small documents are wayyyy faster","date":"2013-08-31T06:08:30.766Z","type":"message"}
{"nick":"brycebaril","message":"Well, not if you fill the 16mb write buffer with them","date":"2013-08-31T06:08:50.281Z","type":"message"}
{"nick":"mbalho","message":"but 10kb isnt that big, but i wonder where the dropoff point is","date":"2013-08-31T06:08:56.715Z","type":"message"}
{"nick":"brycebaril","message":"that is actually much slower","date":"2013-08-31T06:08:58.829Z","type":"message"}
{"nick":"mbalho","message":"interesting","date":"2013-08-31T06:09:19.434Z","type":"message"}
{"nick":"brycebaril","message":"I am playing with 250k documents, which ends up about the same as 10k docs","date":"2013-08-31T06:09:26.278Z","type":"message"}
{"nick":"brycebaril","message":"You can totally set it to hit the memory leak really fast","date":"2013-08-31T06:09:51.514Z","type":"message"}
{"nick":"mbalho","message":"hah","date":"2013-08-31T06:10:01.896Z","type":"message"}
{"nick":"mbalho","message":"apparently the memory leak is fixed now with npm install level","date":"2013-08-31T06:10:09.705Z","type":"message"}
{"nick":"brycebaril","message":"This may actually be a different issue, it may just be pure v8 allocation limits","date":"2013-08-31T06:10:29.747Z","type":"message"}
{"nick":"brycebaril","message":"time node load-batches.js -b 10 -n 2000 -l 250000","date":"2013-08-31T06:10:38.310Z","type":"message"}
{"nick":"brycebaril","message":"loading 10 batches of 2000 records","date":"2013-08-31T06:10:38.525Z","type":"message"}
{"nick":"brycebaril","message":"500000000 bytes per batch","date":"2013-08-31T06:10:38.739Z","type":"message"}
{"nick":"brycebaril","message":"batch of 2000: 6891ms","date":"2013-08-31T06:10:38.739Z","type":"message"}
{"nick":"brycebaril","message":"FATAL ERROR: CALL_AND_RETRY_2 Allocation failed - process out of memory","date":"2013-08-31T06:10:38.739Z","type":"message"}
{"nick":"brycebaril","message":"500MB batches :)","date":"2013-08-31T06:10:45.698Z","type":"message"}
{"nick":"mbalho","message":"hah","date":"2013-08-31T06:10:50.391Z","type":"message"}
{"nick":"mbalho","message":"if you ue buffers it wont do that","date":"2013-08-31T06:10:55.604Z","type":"message"}
{"nick":"brycebaril","message":"doesn't even finish the second batch","date":"2013-08-31T06:10:58.037Z","type":"message"}
{"nick":"brycebaril","message":"So I switched it to use hyperlevel and i'm not seeing the occasional pauses that you see with the standard level","date":"2013-08-31T06:11:31.470Z","type":"message"}
{"nick":"mbalho","message":"oh cool","date":"2013-08-31T06:11:38.954Z","type":"message"}
{"nick":"mbalho","message":"gotta run, but you should definitely leave a comment","date":"2013-08-31T06:12:14.585Z","type":"message"}
{"nick":"brycebaril","message":"The average batch size isn't much different, but the slowest batch I've seen is 400ms vs 5000-10000ms","date":"2013-08-31T06:12:18.453Z","type":"message"}
{"nick":"esundahl","date":"2013-08-31T06:12:40.337Z","type":"join"}
{"nick":"esundahl","reason":"Ping timeout: 268 seconds","date":"2013-08-31T06:21:14.162Z","type":"quit"}
{"nick":"sveisvei_","date":"2013-08-31T06:58:23.562Z","type":"join"}
{"nick":"timoxley","date":"2013-08-31T07:00:27.822Z","type":"join"}
{"nick":"rescrv1","date":"2013-08-31T07:05:07.466Z","type":"join"}
{"nick":"alanhoff","reason":"Ping timeout: 260 seconds","date":"2013-08-31T07:05:47.218Z","type":"quit"}
{"nick":"alanhoff","date":"2013-08-31T07:06:02.274Z","type":"join"}
{"nick":"prettyrobots_","date":"2013-08-31T07:10:15.177Z","type":"join"}
{"nick":"rescrv","reason":"*.net *.split","date":"2013-08-31T07:11:25.707Z","type":"quit"}
{"nick":"prettyrobots","reason":"*.net *.split","date":"2013-08-31T07:11:26.127Z","type":"quit"}
{"nick":"sveisvei","reason":"*.net *.split","date":"2013-08-31T07:11:26.547Z","type":"quit"}
{"nick":"sveisvei_","new_nick":"sveisvei","date":"2013-08-31T07:11:51.270Z","type":"nick"}
