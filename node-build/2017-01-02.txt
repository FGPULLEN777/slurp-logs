{"nick":"sxa","reason":"Ping timeout: 258 seconds","date":"2017-01-02T07:20:31.845Z","type":"quit"}
{"nick":"sxa","date":"2017-01-02T07:25:45.913Z","type":"join"}
{"nick":"node-gh","date":"2017-01-02T07:36:18.624Z","type":"join"}
{"nick":"node-gh","date":"2017-01-02T07:36:18.790Z","type":"part"}
{"nick":"not-an-aardvark","reason":"Quit: Connection closed for inactivity","date":"2017-01-02T11:14:19.273Z","type":"quit"}
{"nick":"phillipj","message":"what's the usual fix when Jenkins slaves has permgen space issues? increase JVM args?","date":"2017-01-02T11:24:34.825Z","type":"message"}
{"nick":"phillipj","message":"https://ci.nodejs.org/job/node-test-commit-plinux/6073/nodes=ppcbe-ubuntu1404/console","date":"2017-01-02T11:24:37.220Z","type":"message"}
{"nick":"thealphanerd","reason":"Quit: farewell for now","date":"2017-01-02T11:25:09.276Z","type":"quit"}
{"nick":"thealphanerd","date":"2017-01-02T11:25:40.098Z","type":"join"}
{"nick":"phillipj","message":"there has been several build failures on that slave today cause of permgen :/","date":"2017-01-02T11:28:27.721Z","type":"message"}
{"nick":"node-gh","date":"2017-01-02T12:28:46.929Z","type":"join"}
{"nick":"node-gh","date":"2017-01-02T12:28:47.096Z","type":"part"}
{"nick":"jbergstroem","message":"phillipj: thinking it might be on the client end","date":"2017-01-02T12:39:30.213Z","type":"message"}
{"nick":"jbergstroem","message":"phillipj: did you log in to the machine","date":"2017-01-02T12:39:48.314Z","type":"message"}
{"nick":"phillipj","message":"jbergstroem: yupp","date":"2017-01-02T12:45:42.282Z","type":"message"}
{"nick":"phillipj","message":"the machine seemed to be okey to me","date":"2017-01-02T12:46:41.508Z","type":"message"}
{"nick":"phillipj","message":"didn't restart anything","date":"2017-01-02T12:46:50.171Z","type":"message"}
{"nick":"jbergstroem","message":"phillipj: no lingering processes?","date":"2017-01-02T13:03:14.972Z","type":"message"}
{"nick":"jbergstroem","message":"phillipj: perhaps try increasing the memory limit on the java process in the init script","date":"2017-01-02T13:03:27.638Z","type":"message"}
{"nick":"jbergstroem","message":"128 seems to do us well but some os'es might need more","date":"2017-01-02T13:03:35.426Z","type":"message"}
{"nick":"phillipj","message":"jbergstroem: processes looks alright, one single java process","date":"2017-01-02T13:12:19.802Z","type":"message"}
{"nick":"phillipj","message":"jbergstroem: it's already running 192mb limit, \"someone\" has already tried that trick I guess","date":"2017-01-02T13:14:15.510Z","type":"message"}
{"nick":"phillipj","message":"should I just restart the jenkins service then?","date":"2017-01-02T13:14:43.660Z","type":"message"}
{"nick":"jbergstroem","message":"try 256","date":"2017-01-02T13:21:12.696Z","type":"message"}
{"nick":"jbergstroem","message":"and retstart when idle?","date":"2017-01-02T13:21:21.341Z","type":"message"}
{"nick":"phillipj","message":"okey, done","date":"2017-01-02T13:33:58.583Z","type":"message"}
{"nick":"node-gh","date":"2017-01-02T13:43:15.666Z","type":"join"}
{"nick":"node-gh","date":"2017-01-02T13:43:15.869Z","type":"part"}
{"nick":"evanlucas","date":"2017-01-02T14:09:51.868Z","type":"join"}
{"nick":"jbergstroem","message":"what java version is it?","date":"2017-01-02T15:02:41.497Z","type":"message"}
{"nick":"jbergstroem","message":"perhaps we can force a gc periodically or something","date":"2017-01-02T15:02:55.420Z","type":"message"}
{"nick":"not-an-aardvark","date":"2017-01-02T16:27:56.436Z","type":"join"}
{"nick":"not-an-aardvark","reason":"Ping timeout: 240 seconds","date":"2017-01-02T17:51:37.155Z","type":"quit"}
{"nick":"mattloring","reason":"Ping timeout: 240 seconds","date":"2017-01-02T17:51:37.320Z","type":"quit"}
{"nick":"italoacasas","reason":"Ping timeout: 260 seconds","date":"2017-01-02T17:51:53.594Z","type":"quit"}
{"nick":"mattloring","date":"2017-01-02T17:52:14.801Z","type":"join"}
{"nick":"ofrobots","reason":"Ping timeout: 258 seconds","date":"2017-01-02T17:52:37.723Z","type":"quit"}
{"nick":"othiym23","reason":"Ping timeout: 245 seconds","date":"2017-01-02T17:52:59.033Z","type":"quit"}
{"nick":"orangemocha","reason":"Ping timeout: 258 seconds","date":"2017-01-02T17:53:01.848Z","type":"quit"}
{"nick":"mhdawson","reason":"Ping timeout: 246 seconds","date":"2017-01-02T17:53:12.181Z","type":"quit"}
{"nick":"Trott","reason":"Ping timeout: 258 seconds","date":"2017-01-02T17:53:23.854Z","type":"quit"}
{"nick":"not-an-aardvark","date":"2017-01-02T17:55:19.822Z","type":"join"}
{"nick":"mhdawson","date":"2017-01-02T17:56:57.707Z","type":"join"}
{"nick":"ofrobots","date":"2017-01-02T18:07:07.838Z","type":"join"}
{"nick":"italoacasas","date":"2017-01-02T18:08:00.836Z","type":"join"}
{"nick":"Trott","date":"2017-01-02T18:08:03.897Z","type":"join"}
{"nick":"orangemocha_","date":"2017-01-02T18:09:58.981Z","type":"join"}
{"nick":"phillipj","message":"jbergstroem: java7","date":"2017-01-02T19:27:48.354Z","type":"message"}
{"nick":"Trott","message":"Stalled test processes on test-osuosl-aix61-ppc64_be-1. Just terminated them. Should be back to normal now.","date":"2017-01-02T19:57:55.240Z","type":"message"}
{"nick":"Trott","message":"Same on test-digitalocean-freebsd11-x64-2 and test-digitalocean-freebsd10-x64-1","date":"2017-01-02T20:01:19.167Z","type":"message"}
{"nick":"Trott","message":"Must have been one bad commit somewhere that caused some cluster test to not exit and hog ports.","date":"2017-01-02T20:01:36.188Z","type":"message"}
{"nick":"othiym23","date":"2017-01-02T20:04:51.809Z","type":"join"}
{"nick":"jbergstroem","message":"perhaps the things you fixed in 7.x earlier but hasn't been ported to 6.x?","date":"2017-01-02T20:05:01.381Z","type":"message"}
